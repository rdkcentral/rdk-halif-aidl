{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RDK Hardware Porting Kit (HPK)","text":"<p>The RDK Hardware Porting Kit (HPK) provides a centralized resource for vendors integrating their hardware layer with the RDK stack.  It simplifies this process by providing a unified set of tools, documentation, and test suites.</p> <p>Specifically, the HPK includes:</p> <ul> <li>Hardware Abstraction Layer (HAL) API header files: These define the interfaces vendors must implement to ensure compatibility.</li> <li>Comprehensive software tests: These validate the vendor's HAL implementation against RDK middleware requirements.</li> <li>Standards &amp; Best Practices: Guidelines on coding standards, documentation, branching strategies, and interface development.</li> <li>Testing Methodologies: Outlines various testing levels and frameworks, including TDD and system interface testing.</li> <li>Code Examples &amp; Advanced Topics: Practical examples for dynamic library loading, plugin development, virtual device development, and control plane overviews.</li> <li>FAQ &amp; Troubleshooting: Addresses common challenges related to Git, Vagrant, C macros, testing, and RDK tools.</li> <li>Technology Overviews: Explains key technologies and frameworks like UT-Core and the RDK Docker toolchain.</li> <li>vDevice Support:  Provides the ability to develop and test vendor layers using virtualized hardware within a VM.  This \"vDevice\" approach simulates hardware components and drivers, enabling early testing, cost-effectiveness, reproducibility, and flexibility.  It allows developers to test against various hardware profiles without needing physical hardware.</li> </ul> <p>The HPK serves as a single point of reference, streamlining vendor integration, reducing redundant effort, and promoting consistency across RDK platforms. It accelerates hardware enablement and improves the quality of the RDK ecosystem.</p> <p></p>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/","title":"1. Standards & Development Process Flow","text":""},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#overview","title":"Overview","text":"<p>This document serves as a comprehensive guide and resource center for software development within the RDKCentral org, covering a wide range of topics from coding standards and testing methodologies to frequently asked questions and specific technology overviews.</p> <p>Here's a breakdown of the content:</p> <ul> <li>Standards &amp; Best Practices: This section provides detailed guidelines on coding standards, documentation practices, branching strategies, and interface development, ensuring consistency and quality across projects.</li> <li>Testing Methodologies:  It outlines various testing levels and frameworks, including Test-Driven Development (TDD) and system interface testing, emphasizing the importance of robust testing in the development life-cycle.</li> <li>Code Examples &amp; Advanced Topics:  This section offers practical code examples for dynamic library loading and plugin development, and delves into advanced concepts like virtual device development and control plane overviews.</li> <li>FAQ &amp; Troubleshooting:  A comprehensive FAQ section addresses common challenges and questions related to Git workflows, Vagrant setup,  C macros, testing techniques, and RDK-specific tools.</li> <li>Technology Overviews:  Provides concise explanations of key technologies and frameworks used within the organization, such as the UT-Core framework and RDK Docker tool-chain.</li> </ul> <p>By centralizing this information, the document aims to streamline development processes, reduce on boarding time for new developers, and promote best practices across the organization.</p>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#10-getting-started-with-contribution","title":"1.0 Getting Started with Contribution","text":"<p>To contribute to the RDK, you'll need to choose a delivery model:</p> <p>RDK Central Partners: If you're an RDK Central partner, you might be eligible to contribute as a Tier 1 developer. Please contact [RDK Support Team](mailto:support@rdkcentral.com) to confirm your eligibility.</p> <ul> <li>1.0. Standards: Tier 1 Operator Guide: Branching for Direct Contributions</li> <li>1.0.1 Standards: Tier 2 Operator Guide: Forking for External Contributions</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#11-coding-standards-useful-reading-on-coding-standards","title":"1.1 Coding Standards: Useful reading on coding standards","text":"<p>This section offers resources and guidelines on coding standards, including recommended reading, issue/milestone descriptions, commit message conventions, and semantic versioning.</p> <ul> <li>1.1. Standards: Principles from Code Complete</li> <li>1.2. Standards: Issue Description Guideline</li> <li>1.3. Standards: Milestone Description Guideline</li> <li>1.4. Standards: Commit Message: The 50-72 Rule: A Simple Guide</li> <li>1.5. Standards: Semantic Versioning and Testing Suite Alignment</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#2-general-information","title":"2. General Information","text":"<p>This section provides general information on key topics like documentation standards, branching strategies, interface modification procedures, and repository access policies.</p> <ul> <li>2 Single Source of Truth - HAL Interfaces and Testing Suites</li> <li>2.1. Doxygen: Crafting Excellent Documentation</li> <li>2.2. Standards: Forking And Branching</li> <li>2.3. Standards: Performing Changes to an interface</li> <li>2.4.-Standards:-Repository-Access-and-Branch-Protection-Policy</li> <li>2.5.-Standards:-Feature-Branch-Workflow</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#3-testing","title":"3. Testing","text":"<p>This section outlines testing standards and best practices, covering various levels and types of testing, including TDD and system interface testing.</p> <ul> <li>3.0.0 Standards: Levels of Test for Vendor Layer</li> <li>3.0.1 Standards: Testing Feedback Loops</li> <li>3.1.0 Standards: Overview of Test Driven Development (TDD)</li> <li>3.2.0 Standards: Requirements for building testing suites</li> <li>3.3.0 Standards: L4: System Interface Testing</li> <li>3.4.0 Standards: L4: Vendor Full Stack: Video Smoke Regression Test</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#4-code-examples","title":"4. Code Examples","text":"<p>This section provides code examples demonstrating key standards like dynamic library loading and plugin implementation.</p> <ul> <li>4. Standards: Dynamic Library Loading for Vendor Abstraction</li> <li>4.1 Standards: Dynamically Installable Plug-ins In C</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#5-virtual-device","title":"5. Virtual Device","text":"<p>This section provides an overview of the virtual device (vDevice) and its control plane.</p> <ul> <li>5.0: Standards:-vDevice Overview</li> <li>5.1: Standards: Control Plane Overview)</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#6-training-material","title":"6. Training Material","text":"<p>This section provides resources to help you get started with contributing to the project.</p> <p>Currently available training:</p> <ul> <li>T1: Training: CODEOWNERS: Ensuring Code Quality and Governance: This training explains the <code>CODEOWNERS</code> file and its role in ensuring code quality and proper governance within the project.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.-Standards-%26-Development-Process-Flow/#7-faq","title":"7. FAQ","text":"<p>The FAQ section provides quick answers to common questions, saving users time and effort. Organized by topic, it offers easy access to essential information. </p> <ul> <li>FAQ: Git Flow Support for Multiple mainlines</li> <li>FAQ: Git\u2010Flow: Developers Branching Model</li> <li>FAQ: Release Engineers: Performing a release with git flow</li> <li>FAQ:-Vagrant: Setting Up and Managing Your Vagrant-VM</li> <li>FAQ: Migrating Binaries to <code>Git-LFS</code></li> <li>FAQ: C macro that prints the function name, parameter names with values</li> <li>FAQ: C Macro that prints structure fields</li> <li>FAQ: Black-Box Testing and Code Coverage Metrics</li> <li>FAQ: RDK Docker Toolchain</li> <li>FAQ: Video and Audio Playback Performance Metrics</li> <li>FAQ: Choosing GHEC-ORG or RDKCentral</li> <li>FAQ: Comparing Python Development Platforms</li> <li>FAQ: UT-Core Framework Overview</li> <li>FAQ: Sign up for RDK Central Tier-1 Registration </li> <li>FAQ: Buildroot vs. Yocto Project vs. Bob the Builder</li> <li>FAQ: Software Post Release Development Cycle</li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/","title":"1.0. Standards: Tier 1 Operator Guide: Branching for Direct Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#tier-1-operator-guide-branching-for-direct-contributions","title":"Tier 1 Operator Guide: Branching for Direct Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#overview-of-contributions","title":"Overview of Contributions","text":"<p>We welcome contributions from all community members, both Tier 1 (direct access) and Tier 2 (forked workflow) contributors. Your participation is vital to the project's success. Here's how you can get involved:</p> <ul> <li>Code Contributions: We invite you to contribute code, whether it's new features or bug fixes. Please follow the detailed steps below to ensure your contributions align with our project standards.</li> <li>Issue Reporting: If you discover bugs or have enhancement suggestions, please raise an issue in the repository. Your reports help us improve the project efficiently.</li> <li>Discussions and Ideas: We encourage you to initiate discussions on various topics related to the project. Your insights and feedback drive continuous improvement and innovation.</li> </ul> <p>Access Levels and Workflows</p> <ul> <li> <p>Tier 1 Operators (Direct Access): You have direct write access to the main repository. Follow the branching workflow detailed below. see the Tier 1 Registration Process</p> </li> <li> <p>Tier 2 Operators (Forked Workflow): You don't have direct write access. Contribute by forking the repository, see the Tier 2 Guide Operator Guide for detailed instructions.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Before your contributions can be accepted into the project, you must sign the RDK Contributor License Agreement (CLA). This legal document ensures that you have the rights to contribute the code and that the community can use your contributions freely. First-time contributors will need to complete the license agreement before their code can be merged:</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#getting-started-with-git-collaboration","title":"Getting Started with Git Collaboration","text":""},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>To start, clone the repository to your local machine: <pre><code>git clone https://github.com/rdkcentral/ut-core.git\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#2-set-up-git-flow","title":"2. Set Up Git Flow","text":"<p>We use the Git Flow branching model for managing branches. If you're new to Git Flow, please review this guide:</p> <p>Example of initialising git flow:</p> <pre><code>git flow init -d\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#3-create-a-feature-branch","title":"3. Create a Feature Branch","text":"<p>Create a new feature branch from the 'develop' branch for both new features and bug fixes, adhering to the naming convention: feature/gh_. The  should briefly summarize the branch's purpose. <p>Example of creating a feature branch:</p> <pre><code>git flow feature start 123_add-logging-enhancements\n</code></pre> <p>Compliance Notice: All contributors must strictly follow our Git branching guidelines. Every branch must be accurately named using the corresponding issue ID from our issue tracker, ensuring traceability and upholding automated workflow integrity. Incorrectly named or untraceable branches will fall under a retention policy, allowing for correction within 30 days before removal. This policy is crucial for maintaining the clarity and reliability of our project management processes.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#4-implement-changes","title":"4. Implement Changes","text":"<p>Make changes according to the project\u2019s coding guidelines.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Ensure your commits are clear and adhere to the 50/72 rule:</p> <ul> <li>Summary: Start with an imperative verb, include the GitHub issue ID, and succinctly describe the change.</li> <li>Body: Optionally, provide a detailed explanation, keeping lines to 72 characters.</li> </ul> <p>Example of a Commit Message:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#6-push-changes","title":"6. Push Changes","text":"<p>Push your changes to the repository: <pre><code>git push origin feature/gh123_add-logging-enhancements\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Create a pull request from your branch to the <code>develop</code> branch. It will be automatically assigned for review based on the <code>CODEOWNERS</code> file.</p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#8-merge-the-pull-request","title":"8. Merge the Pull Request","text":"<p>Once approved, merge your branch using Git Flow: <pre><code>git flow feature finish gh123_add-logging-enhancements\n</code></pre></p>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#9-code-ownership-and-releases","title":"9. Code Ownership and Releases","text":"<p><code>CODEOWNERS</code> are responsible for reviewing and approving changes. They also manage the release and tagging of components according to the project\u2019s schedule.</p> <p>Example of the CODEOWNERS file:</p> <pre><code># Default owners for everything in the repo\n*       @rdkcentral/ut-core_codeowner\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.0.-Standards%3A-Tier-1-Operator-Guide%3A-Branching-for-Direct-Contributions/#requirements-for-contributions","title":"Requirements for Contributions","text":"<p>Please ensure your contributions meet the following: - Adherence to Git Flow - Clear and Concise Commit Messages - Peer Review Approval - Open Discussions and Contributions</p> <p>By following these guidelines, you help maintain the quality and integrity of the project while fostering an inclusive and collaborative community environment. We look forward to your contributions, and thank you for being part of our community-driven project.</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/","title":"1.0.1 Standards: Tier 2 Operator Guide: Forking for External Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#tier-2-operator-guide-forking-for-external-contributions","title":"Tier 2 Operator Guide: Forking for External Contributions","text":""},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#introduction","title":"Introduction","text":"<p>Welcome to the Tier 2 Operator Guide! This guide is tailored for engineers and third-party contributors who want to enhance the project but don't have direct write access to the main repository. Forking is your key tool, enabling you to experiment and contribute without impacting the original code base.</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#what-is-forking","title":"What is Forking?","text":"<p>Forking creates a personal copy of a repository on your own GitHub account. This copy is entirely independent, allowing you to modify the code freely without affecting the original project. It's like having your own sandbox to play in!</p>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#why-fork","title":"Why Fork?","text":"<ul> <li>Safe Experimentation:  Explore new ideas, fix bugs, or add features without the risk of breaking the main project.</li> <li>Contribution Pathway:  Once your changes are ready, you can submit them as a pull request to the original repository for consideration.</li> <li>Open Source Collaboration:  Forking is the cornerstone of open-source contribution, empowering individuals and teams to work together.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#step-by-step-forking-workflow","title":"Step-by-Step Forking Workflow","text":"<ol> <li>Find the Repository: Locate the project's repository on GitHub.</li> <li>Click \"Fork\":  You'll find this button at the top right corner of the repository page.</li> <li>Choose Destination: Select your GitHub account as the destination for the fork.</li> <li>Clone Your Fork: Clone your newly created fork to your local machine using Git.    <pre><code>git clone https://github.com/&lt;your-username&gt;/&lt;repository-name&gt;.git\n</code></pre></li> <li>Create a Branch: (Optional but recommended) Create a new branch for your specific changes. This keeps your work organized.    <pre><code>git checkout -b feature/my-new-feature\n</code></pre></li> <li>Make Changes: Edit, add, or remove files as needed.</li> <li>Commit Changes: Save your work regularly with clear and descriptive commit messages.    <pre><code>git commit -m \"Add new feature: &lt;description&gt;\"\n</code></pre></li> <li>Push Changes: Upload your commits to your forked repository on GitHub.    <pre><code>git push origin feature/my-new-feature\n</code></pre></li> <li>Create a Pull Request:  Navigate to the original repository and click \"New Pull Request.\" Select your fork and branch, then provide a detailed description of your changes.</li> <li>Collaboration &amp; Review: The maintainers of the original repository will review your pull request, offer feedback, and potentially merge your changes if they align with the project's goals.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.0.1-Standards%3A-Tier-2-Operator-Guide%3A-Forking-for-External-Contributions/#important-considerations","title":"Important Considerations","text":"<ul> <li>Keep Your Fork Up-to-Date:  Regularly sync your fork with the original repository to avoid conflicts.</li> <li>Clear Communication: In your pull request, clearly explain the purpose and benefits of your changes.</li> <li>Be Patient: The review process might take some time.  Be open to feedback and iterate as needed.</li> <li>Respect Project Guidelines: Follow the project's coding conventions and contribution guidelines.</li> </ul> <p>Refer to the RDK Documentation how_to_contribute</p>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/","title":"Standards: Principles from Code Complete (C/C++)","text":"<p>This coding standard is inspired by the principles in Steve McConnell's Code Complete, aiming for clarity, maintainability, and robustness:</p> <ul> <li>\"Effective software construction practices are crucial for maintaining code quality.\"</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#1-layout-and-formatting","title":"1. Layout and Formatting","text":"<ul> <li>Indentation: Use consistent indentation (spaces, not tabs) to clearly show code structure.</li> <li>Line Length: Keep lines to a reasonable length (around 80 characters).</li> <li>Whitespace: Use blank lines to separate logical sections.</li> <li>Braces: Always use braces for blocks, even for single-statement blocks. Place each brace on a new line.</li> </ul> <pre><code>// GOOD\nif (x &gt; 0)\n{\n    std::cout &lt;&lt; \"x is positive\\n\";\n}\nelse\n{\n    std::cout &lt;&lt; \"x is not positive\\n\";\n}\n\n// BAD (no braces for single-statement block)\nif (x &gt; 0)\n    std::cout &lt;&lt; \"x is positive\\n\";\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#2-naming-conventions","title":"2. Naming Conventions","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#function-naming-rules","title":"Function Naming Rules","text":"<ol> <li>Use Descriptive Names: Names should clearly convey function intent.</li> </ol> <pre><code>// GOOD\ndouble calculateInvoiceTotal();\nvoid sendEmailNotification();\n\n// BAD\ndouble process();\nvoid doTask();\n</code></pre> <ol> <li>Prefer Verbs: Functions perform actions, so use verbs.</li> </ol> <pre><code>// GOOD\nbool validateUser(int id);\nstd::string fetchCustomerData(int customerId);\n\n// BAD\nbool checkUser(int id);\nstd::string getData(int customerId);\n</code></pre> <ol> <li>Be Consistent: Stick to uniform naming conventions across the project.</li> </ol> <pre><code>// GOOD\nstd::string fetchUserInfo();\nvoid updateUserProfile();\n\n// BAD (Inconsistent naming)\nstd::string retrieveUserInfo();\nvoid modifyUserProfile();\n</code></pre> <ol> <li>Avoid Ambiguity: Names should be precise.</li> </ol> <pre><code>// GOOD\nvoid validateUserInput(std::string input);\n\n// BAD\nvoid handleInput(std::string input);\n</code></pre> <ol> <li>Concise but Clear: Function names should be long enough for clarity but not overly verbose.</li> </ol> <pre><code>// GOOD\nvoid loadUserPreferences();\n\n// BAD\nvoid loadUserPreferencesFromDatabaseIfPresentOtherwiseUseDefaults();\n</code></pre> <ol> <li>No Generic Words: Avoid vague terms like <code>data</code> or <code>info</code>.</li> </ol> <pre><code>// GOOD\nvoid saveUserSettings();\n\n// BAD\nvoid saveData();\n</code></pre> <ol> <li>Match Behavior to Name: Boolean functions should reflect expected values.</li> </ol> <pre><code>// GOOD\nbool isValid();\n\n// BAD\nbool checkValidity();\n</code></pre> <ol> <li>Avoid Negatives: Prefer positive naming conventions.</li> </ol> <pre><code>// GOOD\nbool isAvailable();\n\n// BAD\nbool isNotAvailable();\n</code></pre> <ol> <li>Easy to Pronounce: Clear naming improves communication.</li> </ol> <pre><code>// GOOD\ndouble computeAverage();\n\n// BAD\ndouble cmpAvg();\n</code></pre> <ol> <li>Reflect Expected Output: Ensure function names indicate return values.</li> </ol> <pre><code>// GOOD\nstd::string getUserName();\nint countActiveSessions();\n\n// BAD\nstd::string fetch();\nint sessions();\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#3-comments-and-documentation","title":"3. Comments and Documentation","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#clear-comments","title":"Clear Comments","text":"<p>Use comments to explain why a piece of code exists, rather than just describing what it does.</p> <pre><code>// Calculate average temperature to assess if heating is needed\nfloat avg_temperature = calculateAverage(temperatures, num_readings);\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#doxygen-comments-c","title":"Doxygen Comments (C++)","text":"<pre><code>/**\n * Calculates the area of a circle.\n * @param radius The radius of the circle.\n * @return The computed area.\n */\ndouble calculateCircleArea(double radius) \n{\n    return M_PI * radius * radius;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#4-functions-and-modules","title":"4. Functions and Modules","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#single-responsibility-principle-srp","title":"Single Responsibility Principle (SRP)","text":"<p>Each function should have a single well-defined responsibility.</p> <pre><code>// GOOD\ndouble calculateTax(double price, double tax_rate);\n\n// BAD (Multiple Responsibilities)\nvoid processOrder(Order* order);\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#guard-clauses-for-error-handling","title":"Guard Clauses for Error Handling","text":"<pre><code>int divide(int numerator, int denominator) \n{\n    if (denominator == 0) \n    {\n        throw std::runtime_error(\"Error: Division by zero\");\n    }\n    return numerator / denominator;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#5-error-handling-c","title":"5. Error Handling (C++)","text":"<pre><code>try \n{\n    int result = divide(10, 0);\n} \ncatch (const std::runtime_error&amp; e) \n{\n    std::cerr &lt;&lt; \"Error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#6-object-oriented-programming","title":"6. Object-Oriented Programming","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#encapsulation","title":"Encapsulation","text":"<pre><code>class BankAccount \n{\nprivate:\n    double balance;\npublic:\n    void deposit(double amount) \n    {\n        balance += amount;\n    }\n    double getBalance() const \n    {\n        return balance;\n    }\n};\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#inheritance-and-polymorphism","title":"Inheritance and Polymorphism","text":"<pre><code>class Animal \n{\npublic:\n    virtual void makeSound() const = 0; // Pure virtual function \n};\n\nclass Dog : public Animal \n{\npublic:\n    void makeSound() const override \n    {\n        std::cout &lt;&lt; \"Woof!\\n\";\n    }\n};\n\nclass Cat : public Animal \n{\npublic:\n    void makeSound() const override \n    {\n        std::cout &lt;&lt; \"Meow!\\n\";\n    }\n};\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#7-testing-and-quality-assurance","title":"7. Testing and Quality Assurance","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#unit-tests","title":"Unit Tests","text":"<pre><code>// Example (using Google Test framework)\nTEST(MathTest, Addition) \n{\n    EXPECT_EQ(add(2, 3), 5);\n    EXPECT_EQ(add(-1, 1), 0);\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#code-reviews-and-automated-testing","title":"Code Reviews and Automated Testing","text":"<ul> <li>Use linters like Clang-Tidy for code style.</li> <li>Use static analysis tools for bug detection.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#8-collaboration-and-communication","title":"8. Collaboration and Communication","text":""},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#clear-commit-messages-example","title":"Clear Commit Messages (Example)","text":"<pre><code>Added error handling for invalid file input in processData() function. \n</code></pre> <p>See also Commit Message: The 50/72 Rule</p>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#documentation","title":"Documentation:","text":"<ul> <li>Use comments within the code for complex logic.</li> <li>Maintain external documentation (README files, wikis, etc.).</li> </ul>"},{"location":"external_content/ut-core-wiki/1.1.-Standards%3A-Principles-from-Code-Complete/#references","title":"References","text":"<ul> <li>McConnell, S. (2004). Code Complete: A Practical Handbook of Software Construction (2nd ed.). Microsoft Press. Retrieved from GitHub Repository</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/","title":"GitHub Issue Best Practices: Writing Clear and Actionable Tasks/Bugs &amp; Feature Requests","text":""},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#why-issue-quality-matters","title":"Why Issue Quality Matters","text":"<ul> <li>Clear Communication: Well-written issues and feature requests ensure everyone understands the requirements and context within the project.</li> <li>Efficient Collaboration: Good documentation helps developers prioritise their efforts, leading to faster resolution times.</li> <li>Trackable Progress:  Clearly defined issues and features make it easier to track progress and assess project status.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#core-principles-for-effective-tasksbugs-feature-requests","title":"Core Principles for Effective Tasks/Bugs &amp; Feature Requests","text":"<ol> <li>Problem or Opportunity-Focused: Describe the specific problem you're facing or the opportunity for enhancement. Be detailed and provide relevant context.</li> <li>Concise and Actionable: Clearly state what needs to be fixed or implemented to address the problem/opportunity.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#bug-template-recommended","title":"Bug Template (Recommended)","text":"<ul> <li>GitHub Title: <code>Bug:&lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>BUG</code></li> <li>Set the GitHub Label: e.g. <code>Bug</code></li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n**Problem:** &lt;Clearly stating the problem upfront is crucial for understanding the issue..&gt;\n\n**Steps to Reproduce:** &lt;If applicable, This is essential for bugs, allowing others to replicate the problem and verify solutions.&gt;\n\n**Expected Behaviour:** &lt;Explain what should happen instead of the current behaviour.&gt;\n\n**Actual Behaviour:** &lt;Describe what is currently happening, highlighting the discrepancy with the expected behaviour.&gt;\n\n### Notes (Optional):\n\n* &lt;Any other helpful info, environment, links, screenshots, Error messages, console logs, relevant code snippets&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#task-template-recommended","title":"Task Template (Recommended)","text":"<ul> <li>GitHub Title: <code>Task:&lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>TASK</code></li> <li>Set the GitHub Label: e.g. <code>documentation</code> or <code>enhancement</code></li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n* Goal: &lt;Clearly stating the goal of the task is crucial for understanding the requirement..&gt;\n\n### Notes (Optional):\n\n* &lt;Any other helpful info, environment, links&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#feature-request-template-recommended","title":"Feature Request Template (Recommended):","text":"<ul> <li>GitHub Issue Title: <code>Feature: &lt;Short summary of the problem&gt;</code></li> <li>Set the GitHub Issue Type: <code>FEATURE</code></li> <li>Set the GitHub Label: <code>Documentation</code>, <code>Enhancement</code>, <code>Bug</code> etc.</li> <li>Set the GitHub Project Field: Engineering Workflow Project Template</li> </ul> <pre><code>### Description:\n\n**Problem/Opportunity:** &lt;Describe the user need or problem this feature solves/improves.&gt;\n\n**Proposed Solution:** &lt;Explain your idea for the feature and how it addresses the problem/opportunity.&gt;\n\n### Acceptance Criteria: (Optional)\n\n* &lt;Specific condition 1&gt;\n* &lt;Specific condition 2&gt;\n* ...\n\n### Additional Notes (Optional):\n* &lt;Mockups, sketches, wireframes, etc.&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#examples-of-good-and-bad-feature-requests","title":"Examples of Good and Bad Feature Requests","text":"Bad Feature Request Good Feature Request Title: \"Add more stuff\" Title: \"Add a \"Dark Mode\" toggle to the user interface\" Description: \"We need more features.\" Description:  Many users have requested a dark mode option to reduce eye strain, especially during nighttime usage. This feature would improve accessibility and user experience."},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#additional-tips","title":"Additional Tips","text":"<ul> <li>Prioritise: Not all features can be implemented at once. Discuss and prioritise requests based on their impact and feasibility.</li> <li>Collaborate: Encourage feedback and discussion from the team and stakeholders to refine feature requests.</li> <li>Keep it Updated: As development progresses, update feature requests with new information or changes in scope.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.2.-Standards%3A-Issue-Description-Guideline/#lets-write-better-issues-and-feature-requests-together","title":"Let's Write Better Issues and Feature Requests Together!","text":"<p>By following these guidelines, we can improve our communication and collaboration, leading to more focused development and successful project outcomes.  </p> <p>Questions? Feedback? Reach out to your team lead or project manager for assistance.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/","title":"GitHub Milestone Description Guideline","text":"<p>This guide exists to empower teams using GitHub to communicate project progress clearly and effectively.  By standardizing the way milestones are described, including the use of semantic versioning, it ensures that everyone involved (developers, project managers, stakeholders) has a shared understanding of the project's trajectory. This leads to better coordination, informed decision-making, and ultimately, a higher likelihood of successful project delivery.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#1-title-for-release-milestone-with-semantic-version-tag","title":"1. Title for Release Milestone (with Semantic Version Tag):","text":"<ul> <li>Use a brief, action-oriented title that summarizes the milestone's core purpose.</li> <li>Include a semantic version tag at the beginning of the title. This tag should follow the Major.Minor.Patch/Bugfix format (e.g., 1.2.0, 0.1.3).</li> <li>Include repository name in milestone titles to streamline planning.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#examples","title":"Examples:","text":"<pre><code>1.0.0 - ut_core: Initial Release\n</code></pre> <pre><code>0.3.1 - ut_core: Beta Testing\n</code></pre> <pre><code>2.5.0 - ut_core: Major Feature Upgrade.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#11-title-for-internal-milestone","title":"1.1 Title for Internal Milestone:","text":"<ul> <li>Use a brief, descriptive title that highlights the phased delivery nature of the milestone and its focus on progressively merging code into the main development branch.</li> <li>Include the repository name in the milestone title to streamline planning.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#examples_1","title":"Examples:","text":"<pre><code>ut_core: Phased Integration - Part 1\n</code></pre> <pre><code>ut_core: Rolling Integration - Feature X\n</code></pre> <pre><code>ut_core: Pre-Release Integration\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#2-goals-1-3-sentences","title":"2. Goals (1-3 sentences):","text":"<ul> <li>Explain the \"why\" behind the milestone. What overall goal does it serve within the project?</li> <li>Briefly mention the target audience or impact area if relevant.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example","title":"Example:","text":"<pre><code>## Goals\n\nThis milestone focuses on improving user retention by enhancing the on-boarding experience for new customers.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#3-key-deliverables-bulleted-list","title":"3. Key Deliverables (Bulleted List)","text":"<ul> <li>List the 3-5 most significant features, functionalities, or outcomes that define the milestone's success.</li> <li>Use <code>[ ]</code> - This allows in the github UI to click on tasks completed</li> <li>Use clear, specific language that aligns with your project's terminology, this should be the title of your task</li> <li>Optionally, link each deliverable to its corresponding GitHub issue or pull request (e.g., \"Implement user profile customization (#123)\").</li> <li>This information (including links), can be mirrored in Project Management Tracking tools, e.g. Jira as User Stores.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_1","title":"Example","text":"<pre><code>## Key Deliverables (Bulleted List)\n\n  * [ ] Implement basic user authentication and authorization (#45)\n  * [ ] Build core product functionality for content creation and sharing (#52)\n  * [ ] Design and launch initial user interface (#68)\n  * [ ] Set up analytics tracking for key user actions (#71)\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#4-exit-criteria","title":"4. Exit Criteria:","text":"<ul> <li>If applicable, mention measurable targets that will indicate whether the milestone is achieved.</li> <li>These could be quantitative (e.g., \"Reduce user churn by 15%\") or qualitative (e.g., \"Positive feedback from beta testers\").</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_2","title":"Example:","text":"<pre><code>## Exit Criteria\n\n * At least 50 beta users actively using the platform\n * Positive feedback on core features from at least 75% of beta users\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#5-timeline-or-due-date","title":"5. Timeline or Due Date:","text":"<ul> <li>Include a target completion date or a general timeframe if known.</li> <li>This helps communicate expectations and urgency.</li> <li>This should be reflected in the github meta data for the milestone.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_3","title":"Example","text":"<pre><code>## Due Date (GitHub MetaData)\n\nSeptember 30, 2024\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#6-additional-notes-optional","title":"6. Additional Notes (Optional):","text":"<ul> <li>Briefly mention any dependencies on external factors, other teams, or specific technologies.</li> <li>Highlight any known risks or challenges that might impact the milestone.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example_4","title":"Example","text":"<pre><code>## Additional Notes\n\n  * Dependent on completion of API backend by the development team.\n  * Potential risk: Limited resources for user testing and feedback collection.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#why-semantic-versioning-in-milestone-titles","title":"Why Semantic Versioning in Milestone Titles?","text":"<ul> <li>Clear Communication:  It instantly signals the stage and scale of the release (major, minor, or patch).</li> <li>Organized Tracking: It makes it easy to track the evolution of your project through milestones.</li> <li>Consistent Expectations:  It sets clear expectations for what kind of changes users can anticipate. </li> </ul>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#7-template-paste-able","title":"7. Template (Paste-able)","text":"<p>Below is the text that can be pasted in as a template.</p>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#github-metadata-fields","title":"GitHub Metadata Fields","text":"<ul> <li>Title: <code>&lt;Semantic Version Tag&gt; - &lt;GitHub Project&gt;: &lt;Milestone Title&gt;</code></li> <li>Due date (optional): <code>dd/mm/yyyy</code></li> <li>Description:</li> </ul> <pre><code>## Goals\n\n*Briefly describe the purpose of the milestone and its impact on the project.*\n\n## Key Deliverables\n\n* [ ] &lt;Deliverable 1&gt; (Issue/PR #)\n* [ ] &lt;Deliverable 2&gt; (Issue/PR #)\n* [ ] &lt;Deliverable 3&gt; (Issue/PR #)\n* [ ] ...\n\n## Exit Criteria\n\n* &lt;Metric 1&gt;\n* &lt;Metric 2&gt;\n* ...\n\n## Additional Notes (Optional)\n\n### Dependencies\n\n* &lt;Metric 1&gt;\n\n### Risks\n\n* &lt;Metric 1&gt;\n\n### Challenges\n\n* &lt;Metric 1&gt;\n\n### Up-link Data\n\n* **Jira:** &lt;project&gt;-&lt;id&gt;  \n    * This Jira issue details the user story that directly aligns with this milestone's goals and deliverables.\n    * Include the Jira ID for easy reference and tracking.\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#example-populated-template","title":"Example populated template","text":""},{"location":"external_content/ut-core-wiki/1.3.-Standards%3A-Milestone-Description-Guideline/#github-fields","title":"GitHub Fields","text":"<ul> <li>Title: <code>1.0.0 - ut-core: Initial Release</code></li> <li>Due date (optional): <code>30/10/2024</code></li> <li>Description:</li> </ul> <pre><code>## Goals\n\nThis milestone marks the official launch of our product, introducing core features and functionality to the market. \n\n### Key Deliverables\n\n* [ ] Implement basic user authentication and authorization (#45)\n* [ ] Build core product functionality for content creation and sharing (#52)\n* [ ] Design and launch initial user interface (#68)\n* [ ] Set up analytics tracking for key user actions (#71)\n\n## Exit Criteria\n\n* At least 50 beta users actively using the platform\n* Positive feedback on core features from at least 75% of beta users\n\n## Additional Notes:\n\n### Dependencies\n\n* Dependent on completion of API back-end by the development team.\n\n### Risks\n\n* Potential risk: Limited resources for user testing and feedback collection.\n\n### Up-link Data\n\n* **Jira:** RDK-1234\n</code></pre>"},{"location":"external_content/ut-core-wiki/1.4.-Standards%3A-Commit-Message%3A-The-50%E2%80%9072-Rule%3A-A-Simple-Guide/","title":"1.4. Standards: Commit Message: The 50\u201072 Rule: A Simple Guide","text":"<p>The 50/72 rule is a widely adopted convention for formatting Git commit messages. It provides a clear and concise structure that makes it easier to understand the changes made in each commit. The rule breaks down as follows:</p> <ol> <li>Subject Line (50 Characters or Less):</li> <li>Summarize the key change in a brief, imperative sentence (e.g., \"Fix typo in README,\" \"Add new user registration feature\").</li> <li>Use the present tense.</li> <li>Avoid vague or overly general messages.</li> <li> <p>Use imperative verbs:</p> <ul> <li>Add (e.g., \"Add a change to the code.\")</li> <li>Clean (e.g., \"Cleaned unwanted files\")</li> <li>Fix (e.g., \"Fix the broken build.\")</li> <li>Improve (e.g., \"Improve the code documentation.\")</li> <li>Merge (e.g., \"Merge the branch into develop.\")</li> <li>Refactor (e.g., \"Refactor the class for better readability.\")</li> <li>Remove (e.g., \"Remove the duplicate files.\")</li> <li>Test (e.g., \"Test the new feature thoroughly.\")</li> <li>Update (e.g., \"Update the dependencies.\")</li> </ul> </li> <li> <p>Body (72 Characters per Line, Optional):</p> </li> <li>Provide more context and details about the change. Explain the motivation behind the change, the problem it solves, and any relevant implementation details.</li> <li>Use complete sentences.</li> <li> <p>Wrap lines at 72 characters to ensure readability in various environments (e.g., terminals, code editors).</p> </li> <li> <p>Blank Line:</p> </li> <li>Separate the subject line and body with a single blank line.</li> </ol> <p>Example Overview:</p> <pre><code>Update user profile validation (50 characters)\n\nImplement stricter validation rules for user profile fields to prevent invalid data entry. Added checks for:\n\n* Minimum password length (8 characters)\n* Valid email format\n* Unique username\n\nUpdated the UI to display appropriate error messages. (72 characters)\n</code></pre> <p>Example Reality:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre> <p>Why the 50/72 Rule Matters:</p> <ul> <li>Readability: Makes commit history easier to scan and understand.</li> <li>Maintainability: Helps future developers (including yourself) grasp the reasoning behind past changes.</li> <li>Collaboration: Provides context for code reviews and discussions.</li> <li>Automation: Well-formatted commit messages can be used by tools for automated changelog generation or issue tracking integration.</li> </ul> <p>Tips for Writing Great Commit Messages:</p> <ul> <li>Be Specific: Avoid vague messages like \"Update code\" or \"Fix bug.\"</li> <li>Explain Why, Not Just What: Describe the problem the commit solves and the motivation behind the change.</li> <li>Focus on One Change: Each commit should ideally represent a single, logical change.</li> <li>Review Your Message: Before committing, double-check that your message is clear, concise, and accurately describes the change.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/","title":"1.5. Standards: Semantic Versioning and Testing Suite Alignment","text":""},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#semantic-versioning-and-testing-suite-alignment","title":"Semantic Versioning and Testing Suite Alignment","text":"<p>This document outlines how to use semantic versioning SemVer in conjunction with a the testing suite strategy. We'll follow the <code>major.minor.bugfix/doc</code> format and establish clear guidelines for versioning and testing.</p>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#semantic-versioning-semver","title":"Semantic Versioning (SemVer)","text":"<p>SemVer is a widely adopted versioning system that uses a three-part version number: <code>MAJOR.MINOR.BUGFIX</code>.</p> <ul> <li>MAJOR: Increased when you make incompatible API changes.</li> <li>MINOR: Increased when you add functionality in a backwards-compatible manner.</li> <li>BUGFIX/DOC: Increased when you make backwards-compatible bug fixes or documentation upgrades.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#versioning-guidelines","title":"Versioning Guidelines","text":"<ol> <li> <p>Interface Extension:</p> <ul> <li>If you extend an interface without requiring the caller to rebuild, it's a MINOR change.</li> <li>If the caller needs to rebuild due to the interface extension, it's a MAJOR change.</li> </ul> </li> <li> <p>Bug Fixes and Documentation:</p> <ul> <li>Bug fixes and documentation changes are considered BUGFIX or DOC changes, respectively.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#testing-suite-alignment","title":"Testing Suite Alignment","text":"<ol> <li> <p>Major and Minor Alignment:</p> <ul> <li>Testing suites should be aligned with MAJOR.MINOR versions.</li> <li>Each testing suite should comprehensively test all functions within that specific <code>MAJOR.MINOR</code> version.</li> </ul> </li> <li> <p>Bugfix/Doc Update Ingestion:</p> <ul> <li>BUGFIX and DOC upgrades should be automatically ingested into the testing suite to ensure compatibility with the existing interface.</li> </ul> </li> <li> <p>Minor Upgrade and Testing Suite:</p> <ul> <li>When a MINOR upgrade introduces new functionality, the corresponding testing suite must also be upgraded to support and test that new functionality.</li> </ul> </li> <li> <p>Testing Suite Cloning:</p> <ul> <li>Testing suites should be cloned and aligned with MAJOR.MINOR versions to maintain separate test coverage for each distinct interface.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#ut-core-template-scripts-and-version-selection","title":"UT-Core Template Scripts and Version Selection","text":"<p>UT-Core template scripts allow for selecting the new version before the testing suite is released. </p> <ul> <li>The HALIF <code>build_ut.sh</code> script automatically selects the next highest version number.</li> <li>This enables releases with a fixed tag ahead of testing suite implementation.</li> <li>Testing suites must be selected via tags, facilitating a streamlined release process.</li> </ul>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-hal-interface-upgrade","title":"Example Workflow: HAL Interface Upgrade","text":"<ol> <li>Development: You add a new backwards-compatible feature to your HAL interface.</li> <li>Versioning: Increment the MINOR version (e.g., from 1.2.5 to 1.3.0).</li> <li>Testing Suite:  Prepare the corresponding testing suite (e.g., <code>1.3.x</code>) to include tests for the new feature. This might involve creating a new branch or updating configuration files.  (The testing suite itself will be released later.)</li> <li>Release: <ul> <li>Release the new version (1.3.0) of your HAL interface. </li> <li>Update the <code>build_ut.sh</code> script in the HAL implementation to set <code>UT_PROJECT_VERSION=\"1.3.\"</code>. This ensures that when the 1.3.x testing suite is released, it will be automatically selected.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-hal-testing-suite-upgrade","title":"Example Workflow: HAL Testing Suite Upgrade","text":"<ol> <li>Development:  Develop new functions or upgrades for the testing suite to accommodate the new features in the released HAL interface (e.g., 1.3.0).</li> <li>Versioning: Increment the MINOR version of the testing suite (e.g., from 1.2.x to 1.3.0).</li> <li>Release: Release the new version of your testing suite (1.3.0). The <code>build_ut.sh</code> scripts in the HAL implementation, which were previously updated to <code>UT_PROJECT_VERSION=\"1.3.\"</code>, will now automatically select this new testing suite version.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#example-workflow-bug-fix-in-testing-suite","title":"Example Workflow: Bug Fix in Testing Suite","text":"<ol> <li>Bug Fix: You discover and fix a bug in the released testing suite.</li> <li>Versioning: Increment the BUGFIX version of the testing suite (e.g., from 1.3.0 to 1.3.1).</li> <li>Release: Release the bug fix version of the testing suite. The <code>build_ut.sh</code> scripts will automatically use this updated version.</li> </ol>"},{"location":"external_content/ut-core-wiki/1.5.-Standards%3A-Semantic-Versioning-and-Testing-Suite-Alignment/#benefits-of-this-approach","title":"Benefits of this Approach","text":"<ul> <li>Clear Versioning: Ensures consistent and predictable versioning practices.</li> <li>Comprehensive Testing: Guarantees thorough testing of all functionalities for each interface version.</li> <li>Streamlined Release Process: Facilitates efficient release cycles with automated version selection and testing suite alignment.</li> <li>Improved Code Quality: Reduces the risk of regressions and ensures compatibility across versions.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/","title":"2. Standards: Single Source of Truth \u2010 HAL Interfaces and Testing Suites","text":""},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#introduction","title":"Introduction","text":"<p>This document details our transition to a centralized, transparent approach for managing HAL interfaces and testing suites. This change aims to enhance development, boost collaboration, and resolve past issues with fragmented repositories and outdated practices.</p>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#challenges-of-the-previous-system","title":"Challenges of the Previous System","text":"<p>Our previous development landscape faced several challenges:</p> <ul> <li>Fragmented repositories: Interfaces and testing suites were scattered across different locations, making access and collaboration difficult.</li> <li>Outdated version control: Manual syncing and inconsistent branching led to discrepancies and errors.</li> <li>Limited accessibility: Vendors and third parties lacked proper access to essential resources.</li> <li>Multiple code locations: Internal, collaboration, and final code locations caused confusion and maintenance overhead.</li> <li>Rewritten commit histories: Login credential changes forced commit history rewrites, obscuring development history.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#introducing-the-single-source-of-truth-approach","title":"Introducing the Single Source of Truth Approach","text":"<p>To address the challenges of scattered documentation and inconsistent information, we're adopting a single source of truth model.</p> <p>This means:</p> <ul> <li>Centralised repository: All interfaces, testing suites, and documentation will be housed in a central repository, either publicly or privately on rdkcentral.</li> <li>High-Quality Documentation:  We are committed to providing comprehensive, up-to-date documentation, including:<ul> <li>Conceptual documentation:  Explaining the architecture, design principles, and key concepts.</li> <li>API Documentation with Doxygen:  Detailed API references generated with Doxygen, ensuring accuracy and consistency.</li> <li>Tutorials and Examples: Practical guides and examples to help developers get started quickly.</li> </ul> </li> <li>Transparent access: Vendors and third parties will have clear, consistent access to all resources, including all documentation.</li> <li>Semantic versioning: We'll use semantic versioning to ensure compatibility between old and new interfaces and keep documentation aligned with each version.</li> <li>Fixed version usage: Components will use fixed interface versions for stability, referencing the corresponding documentation version.</li> <li>Upgraded interfaces and testing suites: We'll upgrade the interfaces and the testing suites in the open, with documentation updated simultaneously.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#benefits-of-the-new-system","title":"Benefits of the New System","text":"<p>This new system provides numerous benefits:</p> <ul> <li>Simplified development process: Clear visibility and access to resources, including easy-to-find documentation, streamline workflows.</li> <li>Enhanced collaboration: Shared knowledge and resources, along with a common understanding fostered by consistent documentation, improve collaboration.</li> <li>Reduced errors and inconsistencies: A single reference point for code and documentation minimises discrepancies and errors.</li> <li>Improved efficiency and time savings: Streamlined workflows and readily available documentation increase efficiency and save time.</li> <li>Increased transparency and trust: Open access to information, including all documentation for all parties, fosters trust and transparency.</li> <li>Improved developer experience: High-quality documentation makes it easier for developers to understand, use, and integrate with our platform.</li> <li>Reduced support costs: Clear and comprehensive documentation reduces the need for support requests.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.-Standards%3A-Single-Source-of-Truth-%E2%80%90-HAL-Interfaces-and-Testing-Suites/#conclusion","title":"Conclusion","text":"<p>This transition to a single source of truth is a significant advancement in HAL interface development. We're dedicated to continuous improvement and welcome participation and feedback from all stakeholders. Through open communication and collaboration, we can ensure the success of this initiative and provide an enhanced development experience for everyone.</p>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/","title":"2.1. Standards: Doxygen: Crafting Excellent Documentation","text":""},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#doxygen-governance-manual-crafting-excellent-documentation","title":"Doxygen Governance Manual: Crafting Excellent Documentation","text":""},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#introduction","title":"Introduction","text":"<p>Clear and well-structured documentation is essential for code maintainability, readability, and collaboration. Doxygen is a powerful tool that generates documentation from source code comments. This manual aims to establish best practices and guidelines for writing Doxygen comments that enhance the understanding and usability of your codebase.</p>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#core-principles","title":"Core Principles","text":"<ul> <li>Clarity: Write comments that are easy to understand, even for developers who are not familiar with the specific codebase. Avoid jargon, ambiguity, and unnecessary technical details.</li> <li>Conciseness: Be brief and to the point. Avoid long, rambling sentences and paragraphs. Use clear, concise language to convey essential information.</li> <li>Consistency: Follow a consistent style and formatting throughout your Doxygen comments. This includes indentation, spacing, tag usage, and the level of detail provided.</li> <li>Completeness: Ensure your comments cover all the essential aspects of the code element being documented. Include information on the purpose, parameters, return values, possible errors, and any relevant side effects.</li> <li>Accuracy: Double-check your comments for technical correctness and ensure they accurately reflect the code's behavior and functionality.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>/**! */</code> for Single-Line Comments: This is the preferred format for brief descriptions, eliminating the need for the <code>@brief</code> tag:</li> </ul> <pre><code>/**! Retrieves the current Ethernet WAN interface name. */\n</code></pre> <ul> <li>Use <code>/** ... */</code> for Multi-Line Comments: For functions with parameters, return values, or more detailed explanations, use multi-line comments to maintain readability:</li> </ul> <pre><code>/**\n * @brief Initiates a firmware update and factory reset.\n * \n * This function updates the device's firmware (optionally from a specified URL) \n * and then performs a factory reset.\n *\n * ... (more details)\n */\n</code></pre> <ul> <li> <p>Focused <code>@brief</code> Tags:  Keep the <code>@brief</code> description concise and action-oriented, summarizing the core purpose of the function or data structure.</p> </li> <li> <p>Informative <code>@param</code> and <code>@returns</code>:</p> <ul> <li><code>@param</code>: Clearly state the parameter's purpose, expected type, and any constraints or valid values. Use <code>-</code> to separate the parameter name from its description.</li> <li><code>@returns</code>: Provide a general overview of the return value and its meaning.</li> </ul> </li> <li> <p>Detailed <code>@retval</code>s: List each possible return value, followed by a hyphen and a clear explanation.</p> </li> <li> <p>Use Additional Tags: Leverage other Doxygen tags like <code>@note</code>, <code>@warning</code>, <code>@see</code>, and <code>@deprecated</code> to provide supplementary information, warnings, references, or deprecation notices.</p> </li> <li> <p>Error Handling (TODO):  Prioritize moving away from generic <code>RETURN_ERR</code> values. Instead, define and use an enum for specific error codes to enhance debugging and clarity.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#example-well-documented-function","title":"Example: Well-Documented Function","text":"<pre><code>/**!\n * @brief Retrieves the current DOCSIS registration status.\n *\n * This function populates a provided `CMMGMT_CM_DOCSIS_INFO` structure with DOCSIS registration details. \n *\n * @param[out] pinfo - Pointer to a pre-allocated `CMMGMT_CM_DOCSIS_INFO` structure.\n *\n * @returns Status of the operation:\n * @retval RETURN_OK - On success.\n * @retval RETURN_ERR - On failure (e.g., retrieval error, invalid input).\n *\n * @note The caller is responsible for providing the `PCMMGMT_CM_DOCSIS_INFO` structure.\n */\nINT docsis_GetDOCSISInfo(PCMMGMT_CM_DOCSIS_INFO pinfo);\n</code></pre>"},{"location":"external_content/ut-core-wiki/2.1.-Standards%3A-Doxygen%3A-Crafting-Excellent-Documentation/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":"<ul> <li>Repetition: Avoid repeating information that is already clear from the code element's name or type.</li> <li>Vague Language: Be as specific as possible in your descriptions.</li> <li>Incorrect Information: Double-check your comments for technical accuracy.</li> <li>Overly Long Comments: Keep comments concise and focused on the most important details.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/","title":"2.2. Standards: Forking And Branching","text":"<p>Forking and branching in Git are distinct tools, each with its own purpose:</p> <ul> <li>Forking: Creating an independent copy of a repository on your own account, typically for personal experimentation or contributions to external projects.</li> <li>Branching: Creating parallel versions within the same repository, ideal for collaborative development and managing feature work.</li> </ul> <p>Importantly, forking and branching are not mutually exclusive. You can still fork a repository and create branches within your fork. However, it's crucial to choose the right collaboration model for the project's specific needs.</p>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#forking-vs-branching-choosing-the-right-path-for-collaboration","title":"Forking vs. Branching \u2013 Choosing the Right Path for Collaboration","text":"<p>GitHub defines forking and branching as follows:</p> <ul> <li>Fork: \"A fork is a personal copy of another user's repository that lives on your account. Forks allow you to freely make changes to a project without affecting the original upstream repository.\"</li> <li>Branch: \"A branch is a parallel version of a repository. It is contained within the repository, but does not affect the primary or main branch, allowing you to work freely without disrupting the 'live' version.\"</li> </ul> <p>Collaboration Models:</p> <ul> <li>Divergence (Forking): <ul> <li>Best suited for scenarios where you want to experiment, create your own variations, or contribute back to an open-source project where you don't have direct write access.</li> <li>Your fork is a completely separate entity from the original repository, allowing you to explore new ideas without risk.</li> </ul> </li> <li>Convergence (Branching):<ul> <li>Ideal for collaborative development within a single project or team.</li> <li>Branches allow multiple contributors to work on different features simultaneously, with the intention of merging their changes back into the main branch.</li> <li>Facilitates code review, testing, and controlled integration of changes.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#rdk-collaboration-a-case-for-branching","title":"RDK Collaboration: A Case for Branching","text":"<p>Given the collaborative nature of RDK development, the branching model aligns more closely with the goals:</p> <ol> <li>Shared Codebase: All contributors work on the same repository, ensuring everyone is on the same page.</li> <li>Controlled Contributions: Changes are made on branches, subjected to code reviews, and then merged into the main branch upon approval, maintaining quality and consistency.</li> <li>Streamlined Integration: Merging branches is less cumbersome than merging forks, making the integration process smoother.</li> </ol> <p>When Forking Might Be Useful in RDK:</p> <ul> <li>Initial Exploration: If you're new to a project and want to experiment without immediately contributing, you might fork the repository to get a feel for the codebase.</li> <li>Major Divergence: If you have a fundamentally different vision for a project, a fork can allow you to explore that path independently.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.2.-Standards%3A-Forking-And-Branching/#key-points","title":"Key Points:","text":"<ul> <li>Forking: Individual work, experimentation, contributing to external projects.</li> <li>Branching: Collaborative work within a team, controlled integration of changes.</li> <li>RDK Collaboration: Favours branching for its streamlined collaboration and code integration benefits.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/","title":"2.3. Standards: Performing Changes to an interface","text":""},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#scope","title":"Scope","text":"<p>This document outlines the procedures for making changes to the interface. </p> <p>Please also refer to the 2. Standards: Single Source of Truth - HAL Interfaces and Testing Suites document.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#executive-summary","title":"Executive Summary","text":"<p>Modifying the interface is a controlled process requiring collaboration, approval, and meticulous documentation. All changes must be proposed and tracked through GitHub issues, reviewed by the component owner and architecture team, and validated with updated testing suites.  This ensures alignment with architectural standards, maintains interface consistency, and preserves backward compatibility.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#introduction","title":"Introduction","text":"<p>Modifications to the interface should generally be avoided unless approved by the design and architecture teams. Pre-approved design changes are required before starting work, with final authorization granted upon completion.</p>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#architecture-discussions","title":"Architecture Discussions","text":"<ul> <li>Create an issue ticket in github on the goals &amp; requirements that need to be met with clear requirements</li> <li>Discuss any proposed code changes with the architecture team to ensure alignment with current and future needs.</li> <li>Document in the issue ticket, </li> <li>Maintain interface consistency across all components, as design decisions impact the entire interface, not just individual parts.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#change-process","title":"Change Process","text":"<p>Any interface modification involves the following steps, managed through GitHub:</p> <ol> <li> <p>Define and Discuss:</p> <ul> <li>Raise an issue ticket in GitHub to outline the goals and proposed changes to the interface. Clearly define the requirements and reasons for the modification.</li> <li>Discuss the proposed changes with the component owner and the architecture team within the issue ticket. This ensures alignment with current and future architectural needs and maintains interface consistency across all components.</li> </ul> </li> <li> <p>Develop and Document:</p> <ul> <li>Create a branch from <code>develop</code> based on the issue ticket ID (e.g., <code>issue-123-interface-update</code>). </li> <li>In this branch, implement the interface changes and update the corresponding documentation. Ensure the documentation accurately reflects the modified functionality.</li> </ul> </li> <li> <p>Review and Approve:</p> <ul> <li>Raise a Pull Request (PR) for the changes in your branch. </li> <li>Request review and sign-off from the component owner and the architecture team. Address any feedback or concerns raised during the review process.</li> <li>Once approved, merge the PR into <code>develop</code>.</li> </ul> </li> <li> <p>Update Testing Suite:</p> <ul> <li>Raise a separate issue ticket for any required changes or upgrades to the testing suite due to the interface modification. Define the new testing requirements within this ticket.</li> <li>Create a new branch (e.g., <code>issue-124-testing-update</code>) for modifying the testing suite.</li> <li>Implement the testing suite changes to validate the updated interface functionality. </li> <li>Raise a PR for the testing suite changes. Request review and sign-off from the architecture team and code owners.</li> <li>Merge the PR into <code>develop</code> after approval.</li> </ul> </li> <li> <p>Release:</p> </li> </ol> <p>The component owner manages the release of the updated interface and testing suite, adhering to the following guidelines:</p> <ul> <li>Release Cadence: Releases follow a defined cadence methodology to ensure regular updates.</li> <li>Semantic Versioning: Both the header file and testing suite utilize semantic versioning (MAJOR.MINOR.BUGFIX) to indicate the nature of changes.<ul> <li>Major interface changes require a major version bump in both the header file and the testing suite.</li> <li>Minor, binary-compatible interface changes result in a minor version bump for both.</li> <li>Bugfix, either in the testing suites or the header file, will have no effect on the binary</li> </ul> </li> <li>Version Alignment: The testing suite version is aligned with the header file version to ensure compatibility.</li> <li> <p>Automated Upgrades:  Consideration should be given to how the testing suite can automatically upgrade to accommodate minor interface changes, potentially through mechanisms provided by HALIF.</p> </li> <li> <p>Vendor Integration:</p> <ul> <li>Communicate the interface changes to vendors.  Vendors must adjust their code and ensure compliance with the updated testing suite.</li> </ul> </li> </ul> <p>Important Notes:</p> <ul> <li>Peer review will automatically fail if the GitHub process outlined above is not followed.</li> <li>Maintain backward compatibility with existing code whenever possible.</li> <li>Clearly document all changes and justifications within the relevant GitHub issues and PRs.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#testing","title":"Testing","text":"<ul> <li>All code must undergo manual testing before commitment.</li> <li>Engineering teams must perform iterative testing for validation and approval before merging changes.</li> <li>Code merges are gated by successful tests.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#requirements","title":"Requirements","text":"<ul> <li>Changes must maintain backward compatibility.</li> <li>All modifications should be controlled and documented meticulously.</li> <li>Legacy platforms may run older interface versions.</li> <li>Future changes will be managed through dynamic discovery.</li> </ul> <p>When functions or structures are updated, but the interface is deemed insufficient, upgrades are allowed but must be marked with a comment:</p> <pre><code>/* TODO: This &lt;functionality/structure/etc&gt; is deprecated, and future modifications will require a redesign. */\n</code></pre>"},{"location":"external_content/ut-core-wiki/2.3.-Standards%3A-Performing-Changes-to-an-interface/#conclusion","title":"Conclusion","text":"<p>Interface stability should be maintained across all platforms and versions. The architecture team has sole authority over change decisions, and any modifications require design approval and final sign-off.</p>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/","title":"2.4. Standards: Repository Access and Branch Protection Policy","text":""},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#purpose","title":"Purpose","text":"<p>This policy establishes a structured and secure workflow for code changes, defining distinct roles for the Layer Release Team, Contributors, and CodeOwners (typically architects). It utilises the GitFlow branching model to maintain code quality and control releases, with CodeOwners playing a key role in planning and release cadence.</p> <p>This project employs a layered architecture where the image assembly is divided into distinct functional components, each potentially managed by an independent layer release teams. Each component team is responsible for the development, testing, and release of their specific component.</p> <p>Where common functionality exists, the component team proposing a change will request review from the <code>CODEOWNERS</code>, once approved they will merge the change in accordance with an agreed process. <code>CODEOWNERS</code> will then perform the release process.</p> <ul> <li>Image Layers:</li> <li>Vendor Layer:  Contains vendor specific implementation and configurations.</li> <li>Middleware Layer: Provides core common services and functionality.</li> <li> <p>Application Layer: Implements the applications.</p> </li> <li> <p>Independent Release Teams:</p> </li> <li>Autonomy: Each team maintains a high degree of autonomy over their layer, allowing independent release cadence.</li> <li>Coordination: Teams collaborate and synchronise when changes affect shared functionalities or dependencies.</li> </ul>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#actors-and-roles","title":"Actors and Roles","text":"<ol> <li>Contributors Team (Engineers):</li> <li>Responsibilities:<ul> <li>Develop new features and bug fixes.</li> <li>Create feature branches from <code>develop</code>.<ul> <li>Can use the UI to create branches. </li> <li>Use CLI <code>git-flow feature start \"branch name\"</code></li> </ul> </li> <li>Submit pull requests (PRs) for code review.</li> <li>Merge from feature branches to <code>develop</code><ul> <li>Can use the UI to merge</li> <li>Use CLI <code>git-flow feature finish</code></li> </ul> </li> </ul> </li> <li> <p>Permissions:</p> <ul> <li>Write access to feature branches.</li> <li>Write access to <code>develop</code> for approved feature branches.</li> <li>Read access to <code>main</code></li> <li>No direct merge access to <code>main</code>.</li> </ul> </li> <li> <p>CodeOwners Team (Architects):</p> </li> <li>Responsibilities:<ul> <li>Review and approve PRs.</li> <li>Plan milestones and determine release cadence.</li> <li>Release authority (decide when to merge to <code>main</code>).</li> <li>Note: May not directly make code changes.</li> </ul> </li> <li>Permissions:<ul> <li>Write access to <code>develop</code> for approved feature branches.</li> <li>Read access to all branches.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li>Defined in the <code>./github/CODEOWNERS</code> file.</li> </ul> </li> <li> <p>Layer Release Team:</p> </li> <li>Responsibilities:<ul> <li>Release Content: Determine the specific versions of previously released components to be incorporated into the new layer release.</li> <li>Update Configuration: Modify configuration files to reference the selected component versions.</li> <li>Create the layer release branch from <code>develop</code><ul> <li>Use CLI <code>git-flow release start \"semantic version\"</code></li> </ul> </li> <li>Merge code from <code>release branch</code> to <code>main</code>.<ul> <li>Use CLI <code>git-flow release finish \"semantic version\"</code></li> </ul> </li> <li>Tag are created on <code>main</code> caused  by <code>git-flow</code></li> <li>Merge from <code>main</code> to <code>develop</code> caused by <code>git-flow</code></li> <li>Push changes to <code>main</code> and <code>develop</code>, including <code>tags</code>.</li> </ul> </li> <li>Permissions:<ul> <li>Write access to <code>main</code> &amp; <code>develop</code>.</li> <li>Read access to all branches.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#branch-protection","title":"Branch Protection","text":"<ul> <li> <p>main:</p> <ul> <li>Strictly protected.</li> <li>Only the Release Team can merge.</li> <li>Tags used to mark releases.</li> <li>Maintains a history of feature releases.</li> </ul> </li> <li> <p>develop:</p> <ul> <li>Protected.</li> <li>Requires a pull request from a feature branch with approval from CodeOwners to merge. </li> <li>Release team bypass this requirement</li> <li>Contributors and CodeOwners can merge.</li> <li>Maintains a history of feature integrations.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#workflow","title":"Workflow","text":"<ol> <li>Planning: CodeOwners plan milestones and determine the release cadence.</li> <li>Branching: Contributors create feature branches from <code>develop</code>.</li> <li>Development:  Contributors work on their feature branches.</li> <li>Pull Request: Contributors submit PRs for review, automatically assigning CodeOwners.</li> <li>Code Review: CodeOwners (architects) review code and provide feedback.</li> <li>Approval: CodeOwners approve PRs that meet quality standards.</li> <li>Merge to develop: Approved PRs are merged into <code>develop</code> (by Contributors or CodeOwners).</li> <li>Release: CodeOwners determine the release cadence.</li> <li>Release Team:: Create a release via a <code>release</code> branch and merges to <code>main</code> and <code>develop</code>.</li> </ol>"},{"location":"external_content/ut-core-wiki/2.4.-Standards%3A-Repository-Access-and-Branch-Protection-Policy/#appendix","title":"Appendix","text":"<ul> <li>FAQ: Release Engineers: Performing a release with git-flow</li> <li>FAQ: Git\u2010Flow: Developers Branching Model</li> </ul>"},{"location":"external_content/ut-core-wiki/2.5.-Standards%3A-Feature-Branch-Workflow/","title":"2.5. Standards: Feature Branch Workflow","text":"<p>Feature Branch Workflow</p> <ul> <li> <p>Core Principle:  All feature development occurs on separate branches (feature branches) that are isolated from the <code>develop</code> branch. Quality control is a priority at every stage of the process.</p> </li> <li> <p>Process:</p> <ol> <li>Branch Creation: A new short-lived branch is created from the <code>develop</code> branch for each feature.</li> <li>Requirements and Design:  Key requirements are clearly defined in an issue tracker. Rough solutions are discussed with architecture/engineering leads before implementation to align on design and approach.</li> <li>Development: Code changes are made on the feature branch.</li> <li>Testing: (Often Manual) The developer thoroughly tests their changes on the feature branch, ensuring quality standards are met.</li> <li>Early Pull Request (PR): A PR is created early in the development process to solicit feedback and facilitate early integration.</li> <li>Code Review: <code>CodeOwners</code>review the changes in the PR, ensuring adherence to coding standards, design principles, and overall quality.</li> <li>Merge: If approved and tests pass, the feature branch is merged into the <code>develop</code> branch. Merge conflicts are minimized through the use of git-flow branching strategies and short-lived branches.</li> </ol> </li> <li> <p>Benefits:</p> <ul> <li>Isolation: Protects the <code>develop</code> branch from unstable code.</li> <li>Clear History: Feature-specific changes are easily tracked.</li> <li>Easier Collaboration: Multiple developers can work on different features concurrently.</li> <li>Quality Assurance:  Prioritizing quality control at all stages minimizes the risk of introducing errors into the <code>develop</code> branch.</li> <li>Early Feedback: Early PRs and discussions with leads enable faster feedback and course correction if needed.</li> <li>Reduced Merge Conflicts: Git-flow and short-lived branches help mitigate merge conflicts.</li> <li>Controlled Integration: Slower, more deliberate integration ensures thorough testing and quality before merging into the <code>develop</code> branch.</li> </ul> </li> <li> <p>Drawbacks:</p> <ul> <li>Potential for Delays: If early PRs are not reviewed promptly or if extensive changes are required after review, the development cycle might be extended.</li> <li>Requires Discipline: The team needs to adhere to the defined workflow and prioritize quality control practices.</li> </ul> </li> </ul> <p>For more information on the commands to use see FAQ: Git-Flow: Developers Branching Model</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/","title":"Level of Test for the Vendor Layer","text":"<p>This document defines the testing requirements for the Vendor Layer, categorized into levels to facilitate phased delivery and vendor participation. These levels collectively form the Vendor Testing Suite (VTS).</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-1-component-function-testing-isolated-component-environment-pre-commit-vendor-testing","title":"Level 1: Component Function Testing (Isolated Component Environment, Pre-Commit) \u2013 Vendor Testing","text":"<ul> <li>Purpose: API Function testing of individual components + requirements documentation.</li> <li>Scope: Thorough testing of each function and parameter.</li> <li>Execution: Performed by component engineers during initial pre-commit interface development or when modifying existing components, before commit.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-2-component-unit-testing-no-upper-stack-layers-pre-commit-vendor-test","title":"Level 2: Component Unit Testing (No upper stack layers, Pre-Commit) - Vendor Test","text":"<ul> <li>Purpose: Focused testing of individual modules in a component, aligned with requirements documentation. Scope: Independent component testing.</li> <li>Scope: Verifies the functionality of the component.</li> <li>Execution: Performed by component engineers pre-commit during initial development or when implementing changes. </li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-3-component-stimulus-testing-no-upper-stack-layers-pre-commit-vendor-test","title":"Level 3: Component Stimulus Testing (No Upper Stack Layers, Pre-Commit) - Vendor Test","text":"<ul> <li>Purpose: Pre-commit testing using external stimuli to validate component responses and adherence to requirements.</li> <li>Scope:</li> <li>May trigger both Level 1 (Component Function) and Level 2 (Component Unit) tests for deeper verification.</li> <li>Includes specific tests designed to interact with external devices and evaluate component behavior.</li> <li>May involve interactions with other, pre-tested components to simulate real-world scenarios.</li> <li>Infrastructure: May require specialized setup, either on engineers' desks or in dedicated racks, and runs on vendor-provided equipment.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#level-4-layer-system-testing","title":"Level 4: Layer &amp; System Testing","text":"<p>Level 4 encompasses a comprehensive range of system-level tests focused on validating the performance, stability, and integration capabilities of the vendor layer within the ecosystem.</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-system-performance-profiling-vsp","title":"L4 - System Performance Profiling (VSP)","text":"<ul> <li>Purpose: To monitor and analyse system resource usage during key operations.</li> <li>Scope:</li> <li>CPU Load: Measure CPU utilization during activities like video playback, app launch, and channel switching. Continuous monitoring via a C application with logging capabilities.</li> <li>Memory Usage: Track memory consumption patterns to identify potential leaks or areas for optimization.</li> <li>Stress Testing: Push the device to its limits to identify bottlenecks and stability issues.</li> <li>Power Consumption: Testing: Measure power usage under different conditions.</li> <li>Tools/Methods: Utilize profiling tools like <code>perf</code>, <code>valgrind</code>, or other suitable frameworks for performance data collection.</li> <li>Metrics and Reporting:  Collect and analyse performance metrics (CPU usage, memory allocation, frame rates) and generate reports to pinpoint bottlenecks and areas for improvement.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-ad-hoc-analysis-vah","title":"L4 - Ad hoc Analysis (VAH)","text":"<ul> <li>Purpose: To conduct deep-dive investigations into specific issues or performance bottlenecks.</li> <li>Scope:</li> <li>Triggered by: Field issues, complex bugs, performance bottlenecks, or customer escalations.</li> <li>Methodology: Employ in-depth analysis using debugging tools (e.g., <code>gdb</code>), specialized logs, and code inspection.</li> <li>Collaboration: Work closely with development teams to identify root causes and implement solutions.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-system-interface-testing-vsi","title":"L4 - System Interface Testing (VSI)","text":"<ul> <li>Purpose: To validate interactions with external interfaces and devices.</li> <li>Scope:</li> <li>Key Interfaces:<ul> <li>Bluetooth (Bluez): Verify connectivity, pairing, and data transfer.</li> <li>WiFi (WPA-supplicant): Test connection stability, roaming, and security.</li> <li>OpenGLES, OpenGL, Graphics, Vulcan: Validate graphics rendering, performance, and compliance. (Video Only)</li> <li>Kernel Headers, SysFS: Verify kernel interface compatibility and system information access.</li> </ul> </li> <li>Testing Approach: Utilize unit tests, integration tests, and functional testing to ensure proper communication and data exchange.</li> </ul> <p>Related: 3.3. Standards: L4 \u2010 System Interface Testing</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-qa-layer-smoke-testing","title":"L4 - QA / Layer Smoke Testing","text":"<ul> <li>Purpose: To guard against regressions and ensure basic functionality before release.</li> <li>Scope:</li> <li>Release Checks: Prevent new L4 releases from breaking functionality in higher layers (MW and APP).</li> <li>Smoke Tests: Execute essential tests of the upper layer to quickly assess core functions.</li> <li>Application-Level Checks: Test video playback (if applicable) (e.g., Netflix) and full-stack scenarios to meet release criteria.</li> <li>Test Specification:  Reference the existing specification document for detailed test cases and expected results.</li> </ul> <p>Related: 3.4. Standards: L4: Vendor Full Stack \u2010 Video \u2010 Smoke Regression Test</p>"},{"location":"external_content/ut-core-wiki/3.-Standards%3A-Levels-of-Test-for-Vendor-Layer/#l4-deep-dive-testing","title":"L4 - Deep Dive Testing","text":"<ul> <li>Purpose: To perform comprehensive functional and performance validation.</li> <li>Scope: (Video)</li> <li>Audio Quality: Test audio playback across various output interfaces, measuring fidelity, latency, and synchronization.</li> <li>Video Quality: Evaluate video playback across supported codecs, assessing smoothness, artefacts, and colour accuracy.</li> <li>A/V Synchronization: Verify audio-video sync across different content and codecs.</li> <li>Graphics Performance: Conduct end-to-end testing, measuring frame rates, rendering quality, and resource usage.</li> <li>Mixing A/V + Display Scaling: Test scenarios like picture-in-picture to ensure correct scaling and display of multiple video planes.</li> <li>Trick Modes: Evaluate seeking accuracy and responsiveness, and test video plane scaling during trick modes.</li> </ul> <p>Related: (TBC)</p>"},{"location":"external_content/ut-core-wiki/3.0.1-Standards%3A-Testing-Feedback-Loops/","title":"Feedback Loops","text":""},{"location":"external_content/ut-core-wiki/3.0.1-Standards%3A-Testing-Feedback-Loops/#testing-feedback-loops-and-issue-reproduction","title":"Testing Feedback Loops and Issue Reproduction","text":"<p>This document outlines the process for handling issues detected in the field and emphasizes the importance of reproducing these issues at the lowest possible level for efficient investigation and resolution.</p> <p>Key Principles:</p> <ul> <li>Reproducibility:  Issues found in higher-level testing or in the field should be reproducible at lower layers using dedicated testing suites. This allows the responsible team to effectively investigate and resolve the issue.</li> <li>Collaboration:  Testing suites should be accessible to all relevant parties, including internal teams and third-party vendors, to facilitate collaborative debugging and resolution.</li> <li>Continuous Improvement:  Testing suites should be continuously updated to reflect new issues and fixes. This ensures comprehensive test coverage and prevents regressions.</li> </ul> <p>Feedback Loop Process:</p> <ol> <li>Issue Detection: Issues may be identified through Level 4 or Level 5 testing, or reported from the field.</li> <li>Initial Triage: Determine whether the issue originates from the assembled product or a specific component delivery.</li> <li>Investigation (Component Level):<ul> <li>Attempt to reproduce the issue in lower-level tests (L2, L3).</li> <li>Extend existing test scenarios or create new tests to reproduce the issue at the component level.</li> <li>Commit these new tests to the relevant testing suite.</li> <li>Provide the new test suite to the vendor for further investigation.</li> </ul> </li> <li>Investigation (System Level):<ul> <li>Extend L4 and L5 test cases to reproduce and narrow down the issue.</li> <li>Commit new tests to the suite.</li> <li>Provide the updated test suite to the appropriate team for investigation.</li> </ul> </li> <li>Extending Coverage:<ul> <li>Regularly review test coverage to identify gaps.</li> <li>Extend testing suites at any level as needed to address new features or potential problem areas.</li> </ul> </li> </ol> <p>Testing Suite Management:</p> <ul> <li>All parties can contribute to the improvement of testing suites by submitting new tests or updates.</li> <li>Component owners are responsible for reviewing and approving changes to their respective testing suites.</li> <li>Testing suites are maintained with independent cadence and versioning to ensure flexibility and avoid conflicts.</li> <li>Comprehensive documentation is required for all tests, outlining the test objectives, procedures, and expected results.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.1.-Standards%3A-Overview-of-Test%E2%80%90Driven-Development/","title":"Test Driven Development","text":"<p>What is Test-Driven Development?</p> <p>Test-Driven Development (TDD) is a software development approach where automated tests are written before the actual code that makes the tests pass. It's a cyclical process with these core steps:</p> <ol> <li>Red: Write a test that initially fails because the functionality it's testing doesn't exist yet.</li> <li>Green: Write the minimum amount of code necessary to make the test pass.</li> <li>Refactor: Improve the code's design and structure while ensuring the test remains green.</li> </ol> <p>The TDD Cycle</p> <p>This \"Red-Green-Refactor\" cycle is repeated continuously, with each iteration adding a small piece of functionality and its corresponding test.</p> <p>Why Use TDD?</p> <ul> <li>Confidence: TDD provides high confidence in your code's correctness. If all tests pass after changes, you're more assured the software is working as intended.</li> <li>Better Design:  Writing tests first forces you to think about how your code will be used and leads to cleaner, more modular designs.</li> <li>Living Documentation: The tests act as living documentation of the code's expected behavior.</li> <li>Reduced Debugging Time: When tests fail, you know exactly where to look for the problem, saving debugging effort.</li> <li>Faster Feedback Loop:  TDD gives quick feedback about the code's functionality, helping catch errors early.</li> </ul> <p>Key Concepts</p> <ul> <li>Unit Tests: TDD primarily focuses on unit tests, which test individual components of your software in isolation.</li> <li>Test Coverage:  TDD encourages high test coverage, meaning a large portion of your code is executed by tests.</li> <li>Refactoring: Refactoring is essential to maintain clean code and avoid accumulating technical debt.</li> </ul> <p>Benefits of TDD</p> <ul> <li>Higher Quality Code: TDD leads to more robust, reliable, and maintainable code.</li> <li>Reduced Defects:  Catching errors early in the development cycle saves time and money.</li> <li>Increased Productivity: While TDD might seem to slow down initial development, it can speed up the overall process by reducing debugging and rework.</li> <li>Improved Team Collaboration: TDD fosters collaboration between developers and testers as they work together to define test cases and ensure quality.</li> </ul> <p>Challenges of TDD</p> <ul> <li>Learning Curve: TDD requires a shift in mindset and may take time for developers to get comfortable with the process.</li> <li>Test Maintenance: Keeping tests up-to-date can be time-consuming, especially as code evolves.</li> <li>Not Always Suitable:  TDD might not be the best fit for every project or type of code.</li> </ul> <p>Is TDD Right for You?</p> <p>TDD is a valuable tool for many software development projects. Consider these factors to decide if it's suitable for your situation:</p> <ul> <li>Project Size: TDD shines in medium to large-sized projects where testing and maintenance are crucial.</li> <li>Team Experience: TDD is easier to adopt if your team has experience with testing or is open to learning new methodologies.</li> <li>Project Type: TDD is well-suited for projects with well-defined requirements and a focus on quality.</li> </ul>"},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/","title":"Framework Usage","text":""},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/#overview","title":"Overview","text":"<p>This details the requirements for generating and building testing suites for the RDK-E Project for the vendor layer</p> <ul> <li>L1 / L2 testing suites will use the <code>ut-core</code> testing framework</li> <li>L3/L4 levels will add the use <code>python-raft</code> infrastructure and the <code>ut-raft</code> framework and <code>ut-core</code> will still be expected to be used as required.</li> <li>It must adhere to the setup/layout guide provided here: https://github.com/rdkcentral/ut-raft/wiki/Guide-for-Setting-up-the-Python-RAFT-Testing-Suite</li> <li>Developers are expected to understand and utilize the <code>ut-raft</code> classes documented here: https://github.com/rdkcentral/ut-raft/wiki</li> <li>Examples of <code>python_raft</code> configuration and setup can be found in the aforementioned resources.</li> </ul> <p>A document outlining the tests for external interfaces will be created. This document will detail how to use the <code>python_raft</code> infrastructure to test the following:</p> <ul> <li>Selecting testing suite requirements from the platform-specific <code>deviceSettings.yaml</code>.</li> <li>Defining module-specific options for downloading assets required for testing.</li> <li>Building the necessary components for testing.</li> <li>Utilizing <code>sc docker</code> to access the toolchain.</li> <li>Tests should be designed to be platform independent, and driven by yaml configuration / profiles (see example: https://github.com/rdk-e/hal/wiki/Validation-Profiles).</li> </ul> <p>The module must be build-able and testable using the specified methods. A phased delivery model with collaboration between Tata and Sky teams is required.</p> <p>It should be noted that Vendor Layer testing is Black Box Testing.</p>"},{"location":"external_content/ut-core-wiki/3.2.-Standards%3A-Requirements-for-building-testing-suites/#levels-of-test","title":"Levels of Test","text":"<p>The levels of test to be implemented are defined here:</p> <p>https://github.com/rdkcentral/ut-core/wiki/3.-Standards:-Levels-of-Test-for-Vendor-Layer</p> <p>Testing Frameworks:</p> <ul> <li>L1/L2: <code>ut-core</code> wrapper for <code>gtest</code> (https://github.com/rdkcentral/ut-core) will be used for L1/L2 testing.</li> <li>L3: A combination of C++ and C, utilizing both <code>ut-core</code> and <code>python-raft</code> (https://github.com/rdkcentral/python-raft), will be used for L3 testing.</li> </ul> <p>See also FAQ:-UT-Core-Framework-Overview</p> <p>Phased Delivery:</p> <p>The team will follow the phased delivery which defines git tasks and review checkpoints.</p> <p>See also 3.2.1: Standards: Phased Delivery with Checkpoints</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/","title":"3.2.1: Standards: Phased Delivery with Checkpoints","text":""},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#rrdir-research-review-design-implement-releasereview","title":"RRDIR (Research, Review, Design, Implement, Release/Review)","text":"<p>The following phases will be followed for delivery, with checkpoints at each stage. Tasks will be grouped into GitHub features, which will coordinate the release of multiple phases of delivery. GitHub project plans should be used to track and update progress throughout the workflow.  </p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#1-research-github-task-for-researchdesigndocumentation","title":"1. Research (GitHub Task for Research/Design/Documentation)","text":"<ul> <li>A GitHub task will be created to track research activities.  </li> <li>Each component team will provide a list of suggested tests.  </li> <li>The team will research the requirements and document findings.  </li> <li>A proposal will be generated based on the research.  </li> </ul> <p>Checkpoint: Completed research and proposal documented in the GitHub task.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#2-review-discussion-documentation","title":"2. Review (Discussion &amp; Documentation)","text":"<ul> <li>The Architecture team will review the findings either in the GitHub task or the discussion forum, as required.  </li> <li>Feedback from the Architecture team will be used to revise and refine the proposal.  </li> <li>The revised proposal will be written up for formal review.  </li> </ul> <p>Checkpoint: Written-up and approved proposal, moving towards finalization.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#3-design-wiki-documentation-for-review","title":"3. Design (Wiki Documentation for Review)","text":"<ul> <li>Based on the initial discussions, the design will be created to solidify the requirements.  </li> <li>The design will be documented on a Wiki page for review.  </li> <li>The Architecture team will review, provide feedback, and approve the design.  </li> <li>Once the design is approved, the corresponding GitHub task for the design phase will be closed, as the task is now complete.  </li> </ul> <p>Checkpoint: Design approved, documented on the Wiki page, and the design task closed.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#4-implement-github-task-for-implementation","title":"4. Implement (GitHub Task for Implementation)","text":"<ul> <li>Once the design is approved, a new GitHub task will be created to track the implementation.  </li> <li>The task will refer to the finalised design Wiki, which provides clear requirements for implementation.  </li> <li>The new task will clearly define goals, acceptance criteria, and branch name.  </li> <li>The Engineering team will begin implementation based on the design and raise a Pull Request (PR) for review.  </li> <li>The Architecture team will review the PR, provide feedback, and ensure it meets the acceptance criteria.  </li> <li>Once approved, the PR will be merged into the <code>develop</code> branch, and the implementation ticket will be closed.  </li> </ul> <p>Checkpoint: Completed implementation in the GitHub task, with the PR merged to <code>develop</code> and the implementation ticket closed.</p>"},{"location":"external_content/ut-core-wiki/3.2.1%3A-Standards%3A-Phased-Delivery-with-Checkpoints/#5-review-and-release","title":"5. Review and Release","text":"<ul> <li>The Release Team will handle the release process during the release cadence.  </li> <li>The Release Team will review the final merged code, tag it as required, and follow the release process outlined in the FAQ: Release Engineers: Performing a release with git flow.  </li> </ul> <p>Checkpoint: Release tagged and ready for deployment.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/","title":"L4 System Interface (VSI)","text":""},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#overview-vsi","title":"Overview (VSI)","text":"<p>This document outlines the testing requirements and strategy for the Vendor System Interfaces (VSI) in the RDK framework.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#implementing-the-testing-suite-a-proposed-approach","title":"Implementing the Testing Suite: A Proposed Approach","text":"<p>This document outlines a proposed approach for implementing a comprehensive testing suite, leveraging the <code>raft</code> framework and adhering to the RRDI (Research, Review, Design, Implement) methodology.</p> <p>Current Status: This plan is currently a work in progress and will be further refined as more information becomes available.</p> <p>Target Environment Assumptions:</p> <ul> <li>Base Image: The testing suite can assume that the target device has been programmed with a valid vendor image.</li> <li>Driver Installation: All necessary drivers are fully installed and operational on the target device.</li> <li>Clean Slate: No middleware or application layer exists on the target device. This allows for testing the vendor layer in isolation and ensures that tests are not influenced by pre-existing software components.</li> </ul> <p>Proposed Steps:</p> <p>1. Research and Review:</p> <ul> <li>Identify and Evaluate: Conduct thorough research to identify suitable open-source testing suites that align with the module's testing requirements. Consider factors like:<ul> <li>Test Coverage: Does the suite cover the necessary protocols, functionalities, and edge cases?</li> <li>Maturity and Support: Is the suite actively maintained with a strong community or support channels?</li> <li>Licensing: Is the licensing compatible with the project?</li> <li>Integration: How easily can the suite be integrated with the <code>raft</code> framework and the target environment?</li> </ul> </li> <li>Deep Dive: Review the selected testing suite's documentation and codebase to understand its capabilities, limitations, and potential integration challenges.</li> <li>Best Practices: Refer to the RRDI guidelines provided in the https://github.com/rdkcentral/ut-core/wiki/3.2.-Standards:-Requirements-for-building-testing-suites document for best practices.</li> </ul> <p>2. Design:</p> <ul> <li>Test Strategy: Based on the research and review findings, design a comprehensive testing strategy, including:<ul> <li>Test Cases: Define specific test cases to be implemented, prioritizing \"big ticket\" checks for core functionality.</li> <li>Test Data:  Outline how test data will be generated and managed. Consider using pre-defined datasets or dynamic generation techniques.</li> <li>Validation Classes: Design L4-wide validation classes to abstract the validation mechanisms, allowing for phased automation (human-assisted initially, progressing to fully automated).</li> <li><code>raft</code> Integration: Detail how the testing suite will be integrated with the <code>raft</code> framework for test execution, result collection, and reporting.</li> </ul> </li> <li>Phased Automation:  Incorporate a plan for the gradual transition from human-assisted validation to automated checks within the validation classes.</li> </ul> <p>3. Implementation:</p> <ul> <li>Leverage <code>raft</code>: Utilize the <code>raft</code> framework throughout the implementation process:<ul> <li>Download: Download a specific version of the chosen open-source testing suite using <code>raft</code>.</li> <li>Build: Build the testing suite using the toolchain provided by the <code>sc docker</code> environment, ensuring compatibility with the target platform.</li> <li>Deploy: Copy the built testing suite to the target device/environment using <code>raft</code>.</li> <li>Orchestrate: Utilize <code>raft</code> to orchestrate the execution of the test suite on the target, including setup, execution, and teardown.</li> <li>Remote Execution: Enable the capability to download and execute the test suite on a running device/environment using <code>raft</code>.</li> <li>Result Collation: Utilize <code>raft</code> to collect and collate the test results for analysis and reporting.</li> </ul> </li> <li>Debugging Support: Ensure the implementation allows for easy debugging by enabling single-stepping through <code>raft</code> scripts and providing seamless access to the target device for engineers.</li> </ul> <p>Key Considerations:</p> <ul> <li>Module Requirements: Clearly define the testing requirements and goals for the module under test. This will guide the selection of the testing suite and the design of specific test cases.</li> <li><code>raft</code> Integration: Ensure seamless integration with the <code>raft</code> framework throughout the entire testing process, from downloading and building the suite to executing tests and collecting results.</li> <li>Target Environment: Consider the specific characteristics of the target environment (e.g., hardware limitations, operating system) when selecting and building the testing suite. These will be driven by platform-specific input profiles fed into <code>raft</code> and the build process.</li> <li>Scalability and Maintainability: Design the testing suite and its integration with <code>raft</code> for scalability and maintainability, allowing for easy expansion and updates in the future.</li> </ul> <p>By following this approach and incorporating the principles outlined in the previous document, we can create a robust and efficient testing suite that effectively validates the functionality and stability of the stack.</p>"},{"location":"external_content/ut-core-wiki/3.3.-Standards%3A-L4-%E2%80%90-System-Interface-Testing/#key-interfaces","title":"Key Interfaces","text":"<p>Here's the list of main modules that require dedicated testing:</p> <ul> <li> <p>Bluetooth (Bluez)</p> <ul> <li>Requirements Definition:  Clearly define the requirements for Bluetooth functionality within RDK.</li> <li>Collaboration:  Architecture experts need to review and confirm these requirements.</li> </ul> </li> <li> <p>WiFi (wpa-supplicant)</p> </li> <li>API Testing: Utilize an open-source testing suite to conduct comprehensive API testing of wpa-supplicant.</li> <li> <p>Clear set of requirements needs to be defined</p> </li> <li> <p>OpenGLES / EGL</p> <ul> <li>Compliance and Performance:<ol> <li>Gather Vendor Test Data: Obtain a detailed description of the testing performed by the SoC vendor, including compliance tests and performance benchmarks. Request evidence (test results, reports) to support.</li> <li>Performance Benchmarking:  Establish performance benchmarks using OpenGLES benchmarking tools (e.g., glbenchmark).</li> <li>Cross-Platform Comparison: It must be possible to run the same benchmarks across all supported platforms to establish a baseline and ensure new deliveries from vendors meet the minimum performance requirements. Therefore the data output will be in a format that can be used per platform to compare.</li> </ol> </li> </ul> </li> <li> <p>Kernel Testing</p> <ul> <li>Kernel Configuration Requirements: Define specific kernel configuration requirements for RDK in collaboration with the vendor team. These requirements will guide the selection of appropriate validation testing suites from LFS.</li> <li>LFS Testing System: Leverage the Linux Foundation System (LFS) testing infrastructure for kernel-level testing.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/","title":"L4 Smoke Test (VST)","text":""},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#overview-vst","title":"Overview (VST)","text":"<p>This document outlines the automated test plan for L4 (Vendor Full Stack) testing of RDK Video releases. These tests focus on verifying the stability and functionality of the RDK Video stack by testing the integration of the vendor, application (APP), and middleware (MW) layers.</p> <p>Goal: To automate the execution of smoke and regression tests that are currently performed manually, improving efficiency and reducing testing time.</p> <p>Scope: These tests are designed as \"big ticket\" checks, focusing on core functionality:</p> <ul> <li>Is video running?</li> <li>Is audio running?</li> <li>Is video/audio sync operating correctly?</li> <li>Are trick modes operational? (Including checks for black screens, display movement, and errors) </li> </ul> <p>These tests are not intended to be deep-dive device analysis tests. Those are covered by other testing activities. The focus here is on smoke testing to validate that main functionality is still operational after:</p> <ul> <li>Integrating a new vendor layer with the existing APP/MW.</li> <li>Integrating a new APP/MW layer with the existing vendor layer.</li> </ul> <p>This ensures that any new layer introduced does not break the core functionality of the stack.</p> <p>Framework: <code>python_raft</code> will be used to automate these tests, enabling engineers and Jenkins to trigger them as needed.</p> <p>Test Approach:</p> <ul> <li>Build: A full stack image is created using the relevant combination of\u00a0 APP/MW and Vendor layers.</li> <li>Automation: <code>python_raft</code> scripts will be developed to automate the test cases described below.</li> <li>Execution: Tests can be triggered by engineers or integrated into the Jenkins CI/CD pipeline.</li> <li>Reporting: <code>python_raft</code> will provide test results and logs for analysis.</li> </ul> <p>Important: These tests are designed as a pre-release quality gate, ensuring no regressions are introduced before a new layer (vendor, APP, or MW) is released.</p> <p>Target Environment Assumptions:</p> <ul> <li>Full Stack Image: The testing suite can assume that the target device has been programmed with a valid full stack image (vendor, middleware, and application layers).</li> <li>System Ready: Tests should wait for the system to be fully operational before commencing. <code>python_raft</code> already provides mechanisms to achieve this (e.g., by monitoring system logs or specific services, see <code>waitForBoot()</code> ).</li> </ul> <p>Configuration and Platform Independence:</p> <ul> <li>Configuration-driven: The testing suites will be driven by configuration information on the CPE and the image that's running. This includes details about the platform, software version, and available features. To be clear <code>python_raft</code> already supports this, and has methods to extend based on requirements.</li> <li>Platform Abstraction: Tests should prioritize launching applications from the command line whenever possible. This approach offers several advantages:<ul> <li>Consistency: Command-line interfaces tend to be more stable across platforms and software versions compared to graphical interfaces and remote control key sequences.</li> <li>Speed: Launching applications from the command line is generally faster than navigating through menus using a remote control.</li> <li>Reliability:  Command-line launching eliminates potential issues with IR/Bluetooth signal interference or key sequence misinterpretations.</li> </ul> </li> <li>Key Playback Classes (for specific scenarios): While command-line launching is preferred, there might be scenarios where using IR/Bluetooth keys is unavoidable. In such cases:<ul> <li>Wrap platform-specific key sequences in key playback classes. These classes will abstract the underlying key sequences, providing a consistent interface for test scripts.</li> <li>Drive the testing suites by <code>versioned profiles</code> based on the platform. These profiles will contain the necessary configuration data for each platform and software version, ensuring that the correct key sequences and navigation paths are used.</li> </ul> </li> </ul> <p>By prioritizing command-line application launching and utilizing key playback classes and versioned profiles when necessary, the testing suite can achieve a high degree of platform independence and resilience to changes in the user interface and remote control configurations.</p> <p>Requirements:</p> <ol> <li>Integration with L4-wide Validation Classes: The L4 testing suite shall integrate with common L4-wide classes that perform validation checks. These classes will abstract the underlying validation mechanisms, allowing for a phased approach to automation:</li> <li>Phase 1: Human-assisted Validation: Initially, these classes may prompt a human tester with a simple yes/no question to confirm the expected behaviour.</li> <li> <p>Phase 2: Automated Validation:\u00a0 These classes will be progressively upgraded to perform automated validation by directly interacting with the system, e.g., checking proc files for decoder activity, analysing log output, or querying system states. This allows for a gradual transition from manual to automated testing.</p> </li> <li> <p>Engineering-focused Debugging: This test suite is primarily intended for use by engineers. When test failures occur, the framework should facilitate debugging by:</p> </li> <li>Single-stepping through Python Orchestration:\u00a0 Engineers should be able to easily single-step through the <code>python_raft</code> scripts to understand the test flow and pinpoint the failing steps.</li> <li>Seamless Access to Target Device: The framework should provide mechanisms for engineers to readily access the target device (e.g., via SSH) for debugging purposes. This allows them to analyse C code, examine driver data, and inspect system logs in parallel with the test execution.</li> </ol> <p>By adhering to these requirements, the L4 automated testing suite will not only provide a robust quality gate but also empower engineers to efficiently identify and resolve issues across the entire stack.</p>"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#test-suites","title":"Test Suites","text":""},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#a-linear-channels-vod","title":"A. Linear Channels &amp; VOD","text":"Test Case Description Status (Pass/Fail) Remarks A1 General Sanity on APP Playchannels: Play channels for 5 minutes, changing channels via remote. A2 Sanity on Linear SDR Channel: Test channel 101/501. A3 Sanity on Linear UHD Channel: Test channel 406. A4 Sanity on Linear Channel Requiring PIN: Test channels 301, 302. A5 Sanity on VOD (SDR): Test SDR VOD content. A6 Sanity on VOD (UHD): Test UHD VOD content."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#b-apps-testing","title":"B. Apps Testing","text":"Test Case Description Status (Pass/Fail) Remarks B1 APPS - YouTube - SDR: Test YouTube with SDR content. B2 APPS - YouTube - HLG: Test YouTube with HLG content. B3 APPS - YouTube - HDR10: Test YouTube with HDR10 content. B4 APPS - Netflix - SDR: Test Netflix with SDR content. B5 APPS - Netflix - DV: Test Netflix with Dolby Vision content. B6 APPS - Disney+ - SDR: Test Disney+ with SDR content. B7 APPS - Disney+ - DV: Test Disney+ with Dolby Vision content. B8 APPS - Amazon Prime - SDR: Test Amazon Prime with SDR content. B9 APPS - Amazon Prime - HDR10: Test Amazon Prime with HDR10 content. B10 APPS - Amazon Prime - DV: Test Amazon Prime with Dolby Vision content. B11 APPS - Apple TV - DV: Test Apple TV with Dolby Vision content. B12 APPS - Paramount+ - SDR: Test Paramount+ with SDR content. B13 APPS - YouTube Kids - SDR: Test YouTube Kids with SDR content. B14 APPS - BBC iPlayer - SDR: Test BBC iPlayer with SDR content. B15 APP - Peacock: Test Peacock app."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#c-switching-between-apps","title":"C. Switching Between Apps","text":"Test Case Description Status Remarks C1 YouTube to: Netflix, Amazon Prime, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock. C2 Netflix to: YouTube, Amazon Prime, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock. C3 Disney+ to: YouTube, Amazon Prime, Netflix, Apple TV, Paramount+, YouTube Kids, Peacock. C4 Apple TV to: YouTube, Amazon Prime, Netflix, Disney+, Paramount+, YouTube Kids, Peacock. C5 Paramount+ to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, YouTube Kids, Peacock. C6 YouTube Kids to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, Paramount+, Peacock. C7 Peacock to: YouTube, Amazon Prime, Netflix, Disney+, Apple TV, Paramount+, YouTube Kids. C8 Amazon Prime to: YouTube, Netflix, Disney+, Apple TV, Paramount+, YouTube Kids, Peacock."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#d-wi-fi-ethernet-test","title":"D. Wi-Fi / Ethernet Test","text":"Test Case Description Status(Pass/Fail) Remarks D1 Factory Reset and Connect: Factory reset the panel and connect to 5GHz/2.4GHz SSID during setup. D2 Connect Ethernet: Connect Ethernet while the panel is on 5GHz/2.4GHz Wi-Fi. D3 Disconnect Ethernet: Disconnect Ethernet and check if it resumes the last Wi-Fi connection. D4 Verify IP Address: Check if the panel's IP address matches the one assigned by the router. D5 Play/Stream Videos: Play/stream 4K/HDR/UHD videos on 5GHz/2.4GHz network. D6 Soft Reboot (Wi-Fi): Soft reboot the panel while connected to 5GHz/2.4GHz and ensure reconnection. D7 Boot Up Time (Wi-Fi): Check boot-up time when connected to 5GHz/2.4GHz. D8 Hard Reboot (Wi-Fi): Hard reboot the panel while connected to 5GHz/2.4GHz and ensure reconnection. D9 Boot Up Time (Wi-Fi): Check boot-up time when connected to 5GHz/2.4GHz. D10 Reset Network: Reset the network while the panel is on 5GHz/2.4GHz. D11 Soft Reboot (No Internet): Soft reboot after network reset and ensure the panel boots with no internet. D12 Boot Up Time (No Internet): Check boot-up time with no internet. D13 Hard Reboot (No Internet): Hard reboot after network reset and ensure the panel boots with no internet. D14 Boot Up Time (No Internet): Check boot-up time with no internet. D15 Disable Wi-Fi: Disable Wi-Fi via settings and ensure the \"no internet\" screen appears. D16 Hard Reboot (No Internet): Hard reboot and ensure the panel boots with no internet. D17 Disable Wi-Fi: Disable Wi-Fi via settings and ensure the \"no internet\" screen appears. D18 Soft Reboot (No Internet): Soft reboot and ensure the panel boots with no internet. D19 Enable Wi-Fi: Enable Wi-Fi and ensure the panel connects to the last Wi-Fi connection. D20 Power Cycle Router: While connected to 5GHz/2.4GHz, power cycle the router and ensure the panel reconnects. ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#e-motion-deep-sleep-test","title":"E. Motion &amp; Deep Sleep Test","text":"Test Case Description Status (Pass/Fail) Remarks E1 Verify Motion Events: Verify motion events are detected. E2 HDMI Content and Motion: Play HDMI content and verify motion events. E3 Linear Channel and Motion: Play linear channels and verify motion events. E4 Apps and Motion: Play apps like YouTube/Netflix/Disney+ and verify motion events. E5 Power Cycle and Motion: Power cycle the panel and check motion events. E6 Standby and Motion: Put the panel in standby, wake it up, and check motion events. E7 Deepsleep and Motion: Put the panel in deep sleep, wake it up, and check motion events. E8 Auto-Standby: Ensure the panel enters standby mode after 50 minutes of inactivity. E9 Banner Removal: Check if the banner is removed by generating motion at the 51st minute. E10 Linear Channel and No Banner: Ensure no banner appears after 50 minutes of activity on linear channels. ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#f-led-behaviour-test","title":"F. LED Behaviour Test","text":"Test Case Description Status (Pass/Fail) Remarks F1 Checking LED behaviour on power cycle from ON state F2 Checking LED behaviour on power cycle from standby mode state F3 Checking LED behaviour on power cycle from Deepsleep mode state F4 Checking LED behaviour on Soft reboot the panel from ON state F5 Checking LED behaviour on Soft reboot the panel from standby state ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#g-remote-test","title":"G. Remote Test","text":"Test Case Description Status (Pass/Fail) Remarks G1 Wake panel via IR remote --HOME button G2 Wake panel via IR remote --Power button G3 Wake panel via IR remote --PRIME Button G4 Wake panel via IR remote -NETFLIX button G5 Navigate the EPG page, try trick modes &amp; different buttons on remote (IR) G6 Pair the remote on BT G7 Unpair the remote &amp; pair it again G8 Navigate the EPG page, try trick modes &amp; different buttons on remote (BT) G9 Wake panel from standby mode via BT remote --HOME button G10 Wake panel from standby mode via BT remote --Power button G11 Wake panel from deep sleep mode via BT remote --HOME button G12 Wake panel from deep sleep mode via BT remote --Power button"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#h-ffv-test","title":"H. FFV Test","text":"Test Case Description Status (Pass/Fail) Remarks H1 Mic enable via side button - Launch channel, apps, volume etc via FFV H2 Mic enable via side button - Put panel in standby via FFV H3 Mic enable via side button - Wake panel via FFV from standby H4 Mic enable via side button - Put panel in deep sleep &amp; wake it via FFV H5 Mic enable via side button - Soft reboot panel &amp; check if MIC status remains persistent H6 Mic enable via side button - Hard reboot panel &amp; check if MIC status remains persistent H7 Mic disable via side button - Launch channel, apps, volume etc via FFV H8 Mic disable via side button - Put panel in standby via FFV H9 Mic disable via side button - Wake panel via FFV from standby H10 Mic disable via side button - Put panel in deep sleep &amp; wake it via FFV H11 Mic disable via side button - Soft reboot panel &amp; check if MIC status remains persistent H12 Mic disable via side button - Hard reboot panel &amp; check if MIC status remains persistent ... ... ... ..."},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#i-hdmi-source-firetv-chromecast-appletv","title":"I. HDMI Source - FireTV / Chromecast / AppleTV","text":"Test Case Description Status (Pass/Fail) Remarks I1 Launch HDMI source via HDMI Source remote I2 Play any content on HDMI source &amp; check AV I3 Change different resolution on HDMI source I4 When panel is in standby, wake panel via HDMI source I5 When panel in deep sleep, wake panel via HDMI source I6 Hot plug HDMI source I7 Switch between HDMI source, APPS"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#j-hdmi-audio-device","title":"J. HDMI Audio Device","text":"Test Case Description Status (Pass/Fail) Remarks J1 Connect HDMI speaker on HDMI &amp; check sound coming from speakers J2 Hot plug HDMI speakers &amp; make sure Audio switches back properly J3 Check any AV sync issue J4 Check audio for contents on HDMI source when HDMI speakers connected J5 Put panel in standby &amp; wake it up, check the audio coming from HDMI speakers J6 Put panel in deep sleep &amp; wake it up, check the audio coming from HDMI speakers"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#k-bt-audio-device","title":"K. BT Audio Device","text":"Test Case Description Status (Pass/Fail) Remarks K1 Pair BT speakers &amp; check sound coming from speakers K2 Check any AV sync issue on BT speakers while playing apps, HDMI, linear channel K3 Check audio for contents on HDMI source when BT speakers connected K4 Change the output of audio via quick menu K5 Put panel in standby &amp; wake it up, check the audio coming from BT speakers K6 Put panel in deep sleep &amp; wake it up, check the audio coming from BT speakers"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#l-dtt-channels","title":"L. DTT Channels","text":"Test Case Description Status (Pass/Fail) Remarks L1 Checking AV of DTT channel (SD &amp; HD channels) L2 Scanning DTT channels L3 Switch between DTT channels &amp; HDMI source L4 Browsing TV guide, signal information, audio etc in DTT channels option"},{"location":"external_content/ut-core-wiki/3.4.-Standards%3A-L4%3A-Vendor-Full-Stack-%E2%80%90-Video-%E2%80%90-Smoke-Regression-Test/#m-boot-up-time","title":"M. Boot Up Time","text":"Test Case Description Status (Pass/Fail) Remarks M1 Hard reboot (power cycle) 1 M2 Hard reboot (power cycle) 2 M3 Hard reboot (power cycle) 3 M4 Soft reboot (/rebootNow.sh) 1 M5 Soft reboot (/rebootNow.sh) 2 M6 Soft reboot (/rebootNow.sh) 3"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/","title":"Dynamic Library Loading for Vendor Abstraction","text":""},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#description","title":"Description","text":"<p>This example demonstrates how to use dynamic library loading to abstract vendor-specific code in a Hardware Abstraction Layer (HAL). This approach allows you to:</p> <ul> <li>Remove build time dependancies isolating vendor specific library requirements into the wrapper.</li> <li>Maintain a consistent interface for interacting with hardware from different vendors.</li> <li>Improve code modularity and maintainability by separating vendor-specific code from the HAL.</li> </ul> <pre><code>// --- hal_interface.h ---\n\n#ifndef HAL_INTERFACE_H\n#define HAL_INTERFACE_H\n\n// Define the HAL interface (concrete functions). \n// These functions provide a consistent interface to the application, \n// regardless of the underlying vendor implementation.\nint hal_init(void);                      // Initialise the HAL\nint hal_read_sensor(int sensor_id);      // Read from a sensor using the HAL\nvoid hal_write_actuator(int actuator_id, int value); // Write to an actuator using the HAL\n\n#endif // HAL_INTERFACE_H\n\n// --- hal_impl.c ---\n\n#include \"hal_interface.h\"\n#include &lt;dlfcn.h&gt;\n#include &lt;stdio.h&gt;\n\n// Define the vendor interface. This structure holds function pointers\n// to functions that will be implemented in the vendor-specific library.\ntypedef struct \n{\n  int (*vendor_init)(void);              // Initialise the vendor hardware\n  int (*vendor_read_sensor)(int sensor_id);  // Read data from a sensor\n  void (*vendor_write_actuator)(int actuator_id, int value); // Write a value to an actuator\n} vendor_interface_t;\n\n// Function to load a shared library at runtime.\n// This function uses dlopen to load the specified library file.\nvoid* load_dependency(const char* dependency_path) \n{\n  void* handle = dlopen(dependency_path, RTLD_LAZY);\n  if (!handle) {\n    fprintf(stderr, \"Error loading dependency: %s\\n\", dlerror());\n    return NULL;\n  }\n  return handle;\n}\n\n// Global variable to hold the vendor interface. This variable will \n// store the function pointers loaded from the vendor library.\nvendor_interface_t vendor;\n\n// Function to initialize the HAL and load the vendor library.\n// This function is responsible for loading the vendor-specific \n// library and initializing the HAL with the vendor's functions.\nint hal_init(void) \n{\n  // Load the vendor library (e.g., vendor_lib.so)\n  void* vendor_lib_handle = load_dependency(\"./vendor_lib.so\");\n  if (!vendor_lib_handle) \n  {\n    return -1;\n  }\n\n  // Get the 'get_vendor_interface' function from the vendor library.\n  // This function will return a populated vendor_interface_t structure.\n  vendor_interface_t (*get_vendor_interface_fn)(void) = \n      (vendor_interface_t (*)(void))dlsym(vendor_lib_handle, \"get_vendor_interface\");\n  if (!get_vendor_interface_fn) \n  {\n    fprintf(stderr, \"Error getting symbol: %s\\n\", dlerror());\n    dlclose(vendor_lib_handle);\n    return -1;\n  }\n\n  // Get the vendor interface and store it in the global variable.\n  vendor = get_vendor_interface_fn();\n\n  // Initialize the vendor library using the loaded function.\n  if (vendor.vendor_init() != 0) \n  {\n    fprintf(stderr, \"Error initializing vendor library\\n\");\n    dlclose(vendor_lib_handle);\n    return -1;\n  }\n\n  return 0;\n}\n\n// HAL function implementations using the vendor interface.\n// These functions call the corresponding functions in the \n// dynamically loaded vendor library.\nint hal_read_sensor(int sensor_id) \n{\n  return vendor.vendor_read_sensor(sensor_id);\n}\n\nvoid hal_write_actuator(int actuator_id, int value) \n{\n  vendor.vendor_write_actuator(actuator_id, value);\n}\n\n// --- vendor_lib_a.c (Example vendor implementation) ---\n\n#include \"hal_interface.h\"\n\n// Vendor A specific implementations of the functions defined in vendor_interface_t\nint vendor_init(void) \n{\n  // ... vendor A initialization ...\n  printf(\"Vendor A initialized\\n\");\n  return 0;\n}\n\nint vendor_read_sensor(int sensor_id) \n{\n  // ... vendor A sensor reading ...\n  printf(\"Vendor A reading sensor %d\\n\", sensor_id);\n  return sensor_id * 10;\n}\n\nvoid vendor_write_actuator(int actuator_id, int value) \n{\n  // ... vendor A actuator writing ...\n  printf(\"Vendor A writing %d to actuator %d\\n\", value, actuator_id);\n}\n\n// Export the 'get_vendor_interface' function. This function returns \n// a vendor_interface_t structure populated with the vendor's function pointers.\nvendor_interface_t get_vendor_interface(void) \n{\n  static vendor_interface_t vendor = \n  {\n    .vendor_init = vendor_init,\n    .vendor_read_sensor = vendor_read_sensor,\n    .vendor_write_actuator = vendor_write_actuator\n  };\n  return vendor;\n}\n\n// --- main.c (Example application) ---\n\n#include \"hal_interface.h\"\n#include &lt;stdio.h&gt;\n\nint main() \n{\n  // Initialize the HAL. This will load the vendor library and initialize\n  // the vendor-specific hardware.\n  if (hal_init() != 0) \n  {\n    fprintf(stderr, \"HAL initialization failed\\n\");\n    return 1;\n  }\n\n  // Use the HAL functions to interact with the hardware.\n  printf(\"Sensor value: %d\\n\", hal_read_sensor(5));\n  hal_write_actuator(2, 100);\n\n  return 0;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#code-structure","title":"Code Structure","text":"<ul> <li> <p><code>hal_interface.h</code>: Defines the vendor and HAL interfaces.</p> <ul> <li><code>vendor_interface_t</code>: Structure holding function pointers for vendor-specific functions.</li> <li>HAL functions: Concrete functions providing a consistent interface to the application.</li> </ul> </li> <li> <p><code>hal_impl.c</code>: Implements the HAL and dynamically loads the vendor library.</p> <ul> <li><code>load_dependency()</code>: Loads a shared library at runtime using <code>dlopen</code>.</li> <li><code>hal_init()</code>: Initialises the HAL, loads the vendor library, and retrieves the vendor interface.</li> <li>HAL functions: Implementations using the loaded vendor functions.</li> </ul> </li> <li> <p><code>vendor_lib_a.c</code>: Example vendor library implementation.</p> <ul> <li>Vendor functions: Implementations of the functions defined in <code>vendor_interface_t</code>.</li> <li><code>get_vendor_interface()</code>: Returns a populated <code>vendor_interface_t</code> structure.</li> </ul> </li> <li> <p><code>main.c</code>: Example application using the HAL.</p> <ul> <li><code>hal_init()</code>: Initialises the HAL.</li> <li>HAL functions: Calls to interact with the hardware through the HAL.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#benefits","title":"Benefits","text":"<ul> <li>Abstraction: Provides a consistent HAL interface for different vendors.</li> <li>Modularity: Isolates vendor-specific code.</li> <li>Flexibility: Enables easy switching between vendors.</li> </ul>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#example-output","title":"Example Output:","text":"<pre><code>Vendor A initialised\nVendor A reading sensor 5\nVendor A writing 100 to actuator 2\nSensor value: 50\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.-Standards%3A-Dynamic-Library-Loading-for-Vendor-Abstraction/#faq-what-happens-if-the-library-thats-being-loaded-has-dependancies","title":"FAQ: What happens if the library that's being loaded has dependancies","text":"<p>When you use <code>dlopen</code> to load a shared library, the dynamic linker also takes care of loading any other shared libraries that the loaded library depends on. This process is called dependency resolution.</p> <p>Here's how it works:</p> <ol> <li> <p>Dependency List: Every shared library contains a list of its dependencies (other shared libraries it needs to function). This information is stored within the library file itself.</p> </li> <li> <p>Recursive Loading: When you load a library with <code>dlopen</code>, the dynamic linker examines its dependency list. For each dependency:</p> <ul> <li>It checks if the dependency is already loaded. If it is, it's reused.</li> <li>If not, it recursively loads the dependency using the same <code>dlopen</code> process, which may in turn load further dependencies.</li> </ul> </li> <li> <p>Symbol Resolution: Once all dependencies are loaded, the dynamic linker resolves symbols (function names, variables) between the libraries. This ensures that calls from one library to another are correctly linked.</p> </li> <li> <p>Search Path: The dynamic linker uses a search path to locate dependencies. This path is typically defined by the <code>LD_LIBRARY_PATH</code> environment variable and/or the <code>rpath</code> (runtime path) embedded in the library.</p> </li> </ol> <p>Example:</p> <p>If <code>libA.so</code> depends on <code>libB.so</code> and <code>libC.so</code>, and you call <code>dlopen(\"libA.so\", ...)</code>, the following will happen:</p> <ol> <li><code>libA.so</code> is loaded.</li> <li>The dynamic linker sees that <code>libA.so</code> needs <code>libB.so</code> and <code>libC.so</code>.</li> <li><code>libB.so</code> and <code>libC.so</code> are loaded (if they weren't already).</li> <li>Symbols between <code>libA.so</code>, <code>libB.so</code>, and <code>libC.so</code> are resolved.</li> </ol> <p>Important Considerations:</p> <ul> <li>Circular Dependencies: If you have circular dependencies (e.g., <code>libA.so</code> depends on <code>libB.so</code>, and <code>libB.so</code> depends on <code>libA.so</code>), the dynamic linker may not be able to resolve them, leading to errors.</li> <li>Versioning: Different versions of a library might exist. The dynamic linker needs to ensure that the correct versions are loaded to avoid compatibility issues. This is usually handled through sonames (e.g., <code>libmylib.so.1</code>).</li> <li>Error Handling: If a dependency cannot be found or loaded, <code>dlopen</code> will fail, and you should handle the error appropriately.</li> </ul> <p>In summary, <code>dlopen</code> not only loads the specified library but also automatically handles the loading and linking of its dependencies, ensuring that the library can function correctly. This makes it easier to manage complex applications with multiple shared libraries.</p>"},{"location":"external_content/ut-core-wiki/4.0.1%3A-Standards%3A-Dynamic-Library-Search-Order/","title":"4.0.1: Standards: Dynamic Library Search Order","text":"<p>The <code>dlopen</code> function in C is used to dynamically load shared libraries at runtime. Here's how it searches for libraries and how <code>LD_LIBRARY_PATH</code> plays a role:</p> <p>Search Order</p> <p>When you call <code>dlopen</code> with a library name, it follows a specific search order to locate the library:</p> <ol> <li> <p>Absolute Path: If the filename provided to <code>dlopen</code> includes a slash (\"/\"), it's treated as an absolute or relative path, and the dynamic linker will try to load the library directly from that location.</p> </li> <li> <p>RPATH: If the executable file contains a <code>DT_RPATH</code> tag (and no <code>DT_RUNPATH</code> tag), the directories listed in the <code>DT_RPATH</code> tag are searched. This allows embedding paths to dependencies within the executable itself.</p> </li> <li> <p>LD_LIBRARY_PATH: If the environment variable <code>LD_LIBRARY_PATH</code> is set when the program starts, the directories listed in it are searched. However, this is ignored for security reasons if the program has set-user-ID or set-group-ID permissions.</p> </li> <li> <p>RUNPATH: If the executable file contains a <code>DT_RUNPATH</code> tag, the directories listed in that tag are searched. This is similar to <code>DT_RPATH</code> but is often preferred because it allows more flexibility in how libraries are found.</p> </li> <li> <p>ld.so.cache: The dynamic linker checks the file <code>/etc/ld.so.cache</code> (maintained by <code>ldconfig</code>) to see if it contains an entry for the library. This cache speeds up library loading.</p> </li> <li> <p>Default Directories: Finally, the directories <code>/lib</code> and <code>/usr/lib</code> are searched.</p> </li> </ol> <p>LD_LIBRARY_PATH</p> <p><code>LD_LIBRARY_PATH</code> is an environment variable that can be used to specify additional directories where the dynamic linker should look for shared libraries. It can be useful for:</p> <ul> <li>Testing: You can temporarily add a directory with your test libraries to <code>LD_LIBRARY_PATH</code> without having to install them in the system directories.</li> <li>Development:  If you're working on a library that's not yet installed in a standard location, you can use <code>LD_LIBRARY_PATH</code> to tell your program where to find it.</li> <li>Deployment: In some cases, you might need to use <code>LD_LIBRARY_PATH</code> to point to libraries installed in non-standard locations.</li> </ul> <p>Security Considerations</p> <p>While <code>LD_LIBRARY_PATH</code> can be helpful, it's important to use it with caution:</p> <ul> <li>Security Risks: If <code>LD_LIBRARY_PATH</code> is set to include untrusted directories, it can make your program vulnerable to attacks where malicious libraries are loaded instead of the legitimate ones.</li> <li>Maintainability Issues: Overusing <code>LD_LIBRARY_PATH</code> can make your program harder to deploy and maintain, as it relies on a specific environment variable being set correctly.</li> </ul> <p>Best Practices</p> <ul> <li>Use RPATH or RUNPATH: Whenever possible, use <code>RPATH</code> or <code>RUNPATH</code> to encode the library search paths directly into your executable. This is generally a more secure and reliable approach than relying on <code>LD_LIBRARY_PATH</code>.</li> <li>Limit Use of LD_LIBRARY_PATH: If you must use <code>LD_LIBRARY_PATH</code>, try to limit its use to development and testing environments, and avoid setting it globally.</li> <li>Be Mindful of Security: Always be cautious about setting <code>LD_LIBRARY_PATH</code> to include directories that you don't fully trust.</li> </ul>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/","title":"4.1. Standards: Dynamically Installable Plugins In C","text":"<p>Here are some ideas on how to implement a modular C program that can load optional submodules or plugins at runtime or compile-time. The approach will ensure the main module can call these plugins conditionally based on their presence.</p>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Define Plugin Interface:    Define a common interface that all plugins must implement. This could be a set of function pointers within a struct.</li> </ol> <pre><code>// plugin.h\n#ifndef PLUGIN_H\n#define PLUGIN_H\n\ntypedef struct {\n    void (*initialize)(void);\n    void (*perform_action)(void);\n    void (*cleanup)(void);\n} PluginInterface;\n\n#endif // PLUGIN_H\n</code></pre> <ol> <li>Implement Plugin:    Implement a sample plugin following the defined interface.</li> </ol> <pre><code>// plugin_impl.c\n#include \"plugin.h\"\n#include &lt;stdio.h&gt;\n\nvoid plugin_initialize(void) {\n    printf(\"Plugin initialized.\\n\");\n}\n\nvoid plugin_perform_action(void) {\n    printf(\"Plugin action performed.\\n\");\n}\n\nvoid plugin_cleanup(void) {\n    printf(\"Plugin cleaned up.\\n\");\n}\n\nPluginInterface plugin = {\n    .initialize = plugin_initialize,\n    .perform_action = plugin_perform_action,\n    .cleanup = plugin_cleanup\n};\n</code></pre> <ol> <li>Dynamic Loading (Runtime):    Use dynamic loading to load the plugin at runtime. On Linux, you can use <code>dlopen</code> and <code>dlsym</code>.</li> </ol> <pre><code>// main.c\n#include &lt;stdio.h&gt;\n#include &lt;dlfcn.h&gt;\n#include \"plugin.h\"\n\nint main(void) {\n    void *handle;\n    PluginInterface *plugin = NULL;\n\n    // Attempt to load the plugin dynamically\n    handle = dlopen(\"./plugin_impl.so\", RTLD_LAZY);\n    if (handle) {\n        plugin = (PluginInterface *)dlsym(handle, \"plugin\");\n        if (plugin) {\n            plugin-&gt;initialize();\n            plugin-&gt;perform_action();\n            plugin-&gt;cleanup();\n        }\n        dlclose(handle);\n    } else {\n        printf(\"Plugin not found. Running without plugin.\\n\");\n    }\n\n    // Main module logic\n    printf(\"Main module running.\\n\");\n\n    return 0;\n}\n</code></pre> <ol> <li>Compile-Time Loading:    Alternatively, you can conditionally compile the plugin code based on a macro definition.</li> </ol> <pre><code>// main.c\n#include &lt;stdio.h&gt;\n#include \"plugin.h\"\n\n#ifdef USE_PLUGIN\nextern PluginInterface plugin;\n#endif\n\nint main(void) {\n    PluginInterface *plugin_ptr = NULL;\n\n#ifdef USE_PLUGIN\n    plugin_ptr = &amp;plugin;\n#endif\n\n    if (plugin_ptr) {\n        plugin_ptr-&gt;initialize();\n        plugin_ptr-&gt;perform_action();\n        plugin_ptr-&gt;cleanup();\n    } else {\n        printf(\"Plugin not included. Running without plugin.\\n\");\n    }\n\n    // Main module logic\n    printf(\"Main module running.\\n\");\n\n    return 0;\n}\n</code></pre> <ol> <li>Compiling the Code:    For dynamic loading, compile the plugin as a shared library.</li> </ol> <pre><code>gcc -shared -o plugin_impl.so -fPIC plugin_impl.c\ngcc -o main main.c -ldl\n</code></pre> <p>For compile-time loading, compile with a macro definition.</p> <pre><code>gcc -DUSE_PLUGIN -o main main.c plugin_impl.c\n</code></pre>"},{"location":"external_content/ut-core-wiki/4.1.-Standards%3A-Dynamically-Installable-Plugins-In-C/#key-points","title":"Key Points:","text":"<ul> <li>Plugin Interface: Clearly define the interface the plugins must adhere to.</li> <li>Dynamic Loading: Use <code>dlopen</code> and <code>dlsym</code> to load the plugin at runtime if it is available.</li> <li>Compile-Time Option: Use conditional compilation to include the plugin if it is available at compile-time.</li> <li>Null Check: Always check if the plugin function pointers are NULL before calling them to avoid crashes if the plugin is not available.</li> </ul> <p>By following these steps, you can create a flexible C module that can optionally load and use additional functionality from plugins, either at runtime or compile-time, ensuring robust and modular design.</p>"},{"location":"external_content/ut-core-wiki/5.0.1%3A-Standards%3A-vDevice-Architecture-Overview/","title":"Architecture Overview","text":""},{"location":"external_content/ut-core-wiki/5.0.1%3A-Standards%3A-vDevice-Architecture-Overview/#architecture-overview","title":"Architecture Overview","text":"<p>The vDevice enables flexible and efficient interaction with diverse hardware platforms. It acts as an abstraction layer, decoupling the software from the underlying hardware specifics. This approach offers several key advantages:</p> <ul> <li>Hardware Agnostic Software:  By interacting with a standardized HAL API, the software remains independent of the specific hardware implementation. This allows us to develop and deploy software across different platforms without modification.</li> <li>Modular and Adaptable: The use of vComponents provides a high degree of modularity.  Each vComponent represents a specific hardware function, allowing for easy customization and adaptation to new or evolving hardware.</li> <li>Dynamic Platform Mimicking: The vDevice can dynamically configure the vComponents at boot time to match the target platform's characteristics. This enables seamless switching between different platform configurations without code changes.</li> <li>Enhanced Testability:  The vDevice facilitates runtime testing control.  Testing suites can interact with the vDevice (or individual vComponents) through a REST API to modify system behaviour and simulate various scenarios.</li> </ul> <p>The diagram illustrates the key components and interactions within the vDevice architecture:</p> <pre><code>block-beta\n    block: modules\n        columns 2\n        vhal(\"Vendor Hal Interface(API)\")\n        vsi(\"Vendor System Interface - (VSI)\")\n        vc(\"vComponents\")\n        sl(\"vSystem Libraries\")\n        osl(\"Open Source Libraries &amp; utils \"):2\n        ub(\"Ubuntu+Binder\"):2\n    end\n  style vhal fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style vsi fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style sl fill:#FFA07A,stroke:#FA8072,stroke-width:4px;\n    style ub fill:#FFA07A,stroke:#FA8072,stroke-width:4px;\n    style vc fill:#87CEFA,stroke:#1E90FF,stroke-width:4px;\n    style osl fill:#FFA07A,stroke:#FA8072,stroke-width:4px;</code></pre> <ul> <li>Vendor HAL Interface (API): This standardised interface defines how the software interacts with the underlying hardware.</li> <li>Virtualized Components (vComponents): These modular components represent various hardware functions within the HAL implementation.</li> <li>Vendor System Interface (VSI):  A collection of vendor-provided libraries and tools used by the system (e.g., OpenGL, Bluetooth drivers).</li> <li>vSystem Libraries: These libraries organise and package the VSI components into functional groups for easier use.</li> <li>Open Source Libraries &amp; utils:  Common open-source libraries and utilities used within the system.</li> <li>Ubuntu+Binder: The underlying operating system and inter-process communication mechanism.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/","title":"vDevice Overview for TV and STB Development","text":"<p>This document explains the concept of vDevices and their role in developing software for TV and STB (Set-Top Box) platforms.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#what-is-a-virtual-machine","title":"What is a Virtual Machine?","text":"<p>A virtual machine (VM) is essentially a computer within a computer. It's a software-based replica of a physical machine, with its own virtual CPU, memory, storage, and network interfaces. This \"virtual hardware\" is managed by the hypervisor, a software layer that sits between the VM and the actual physical hardware. The hypervisor allows multiple VMs to share the physical resources of a single machine while keeping them isolated from one another.</p> <p>Think of it like this: the hypervisor is like a landlord who owns a building (the physical server). Each VM is like a tenant who rents an apartment (a portion of the server's resources). The landlord (hypervisor) controls how much space (CPU, memory, etc.) each tenant (VM) gets, but the tenants can decorate and use their apartments (VMs) however they like.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-characteristics-of-virtual-machines","title":"Key Characteristics of Virtual Machines:","text":"<ul> <li>Hardware Virtualization:  The number of virtual CPUs, their architecture, memory size, and even the availability of virtual hardware devices are all defined in software. These settings can be adjusted as required, providing flexibility and scalability.</li> <li>Software Transparency: From the perspective of the software running inside the VM, the underlying hardware is transparent. Applications and services operate as if they were running on a physical machine, unaware of the virtualization layer.</li> <li>Vendor Abstraction: While the software inside the VM interacts with virtual hardware, the vendor layer (e.g., device drivers) is responsible for abstracting the specific capabilities of the underlying physical hardware. This allows the same software to run on different virtualization platforms.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#booting-a-linux-image-from-emmc","title":"Booting a Linux Image from eMMC","text":"<p>In the world of TVs and STBs, the software that brings these devices to life is typically a Linux-based image stored on an eMMC (embedded MultiMediaCard). When the device powers on, it loads this image from the eMMC into memory and begins executing the instructions, similar to how a computer boots up its operating system.</p> <p>Development teams concentrate on building and optimizing these Linux images. They ensure the image includes all the necessary drivers, libraries, and configurations for the target device, whether it's a physical TV or STB or a VM. This allows the software to interact correctly with the hardware, regardless of its underlying implementation.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#why-simulation-is-essential-for-tv-and-stb-development","title":"Why Simulation is Essential for TV and STB Development","text":"<p>TVs and STBs often include specialized hardware components not typically found in standard computer systems. These components might include tuners for receiving broadcast signals, video decoders, and graphics processors optimized for displaying high-quality video.</p> <p>Since a virtual machine doesn't inherently support these TV-specific hardware components, they must be simulated in software. This is where simulators and vDevices come into play.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#understanding-software-layers-and-vdevices","title":"Understanding Software Layers and vDevices","text":"<p>It's important to distinguish between the different software layers within a TV or STB system:</p> <ul> <li>Application Layer: This layer comprises the software that end-users interact with directly (e.g., Electronic Program Guide (EPG), streaming apps).</li> <li>Middleware Layer: This layer provides services and functionalities to the application layer, such as multimedia frameworks, network communication, and security.</li> <li>Vendor Layer: This layer interacts directly with the hardware. It contains drivers and other software components that translate hardware-specific requirements into a format that the upper layers can understand.</li> </ul> <p>Platform Independence</p> <p>A key principle in software development is platform independence. This means that the application and middleware layers should be designed to run on any platform without modification. The vendor layer is responsible for handling the specific requirements of the underlying hardware, shielding the upper layers from these details.</p>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#vdevice-clarification","title":"vDevice Clarification","text":"<p>A vDevice is essentially a virtualized vendor layer running within a VM. It comprises:</p> <ul> <li>Simulated Hardware: The hypervisor creates virtual representations of the target hardware, such as a vTuner or vDecoder, mimicking the behaviour of their physical counterparts as Virtual Components (vComponents).</li> <li>Simulated Device Drivers: Instead of interacting with real hardware, the vendor layer utilizes simulated device drivers specifically designed for the virtual environment. These drivers translate commands and data between the virtual hardware and the upper software layers.</li> <li>Hardware Profiles: To further enhance the simulation, vDevices are started with a hardware profile. This profile defines the specific capabilities and configurations of the simulation device, such as tuner type, supported video formats, and memory capacity. This allows developers to simulate a wide range of TV or STB models with varying hardware configurations using a single vDevice implementation.</li> </ul> <p>By incorporating hardware profiles, developers can:</p> <ul> <li>Test compatibility: Ensure their software functions correctly across different device models with varying hardware capabilities.</li> <li>Simulate specific scenarios: Recreate specific hardware configurations to test edge cases and debug issues.</li> <li>Optimize performance:  Fine-tune their software for optimal performance on different hardware profiles.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>vDevice = Virtualized Vendor Layer: A vDevice primarily focuses on simulating the vendor layer's interaction with hardware within a VM.</li> <li>Simulation is Key: Simulated hardware and drivers are crucial for simulating TV-specific components not natively supported by VMs.</li> <li>Platform Independence is Preserved: The application and middleware layers remain platform-agnostic, unaware of the underlying hardware or virtualization.</li> <li>Swapping Between Environments is Seamless: Switching between simulation and real hardware involves simply rebuilding the image with the appropriate vendor layer.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#benefits-of-using-simulators-in-tv-and-stb-development","title":"Benefits of using Simulators in TV and STB Development","text":"<ul> <li>Early testing: Enables software testing early in the development cycle, even before hardware prototypes are available.</li> <li>Cost-effectiveness: Reduces the need for expensive hardware and lab setups.</li> <li>Reproducibility: Provides a controlled and consistent environment for testing, ensuring reproducible results.</li> <li>Flexibility: Allows for easy manipulation of the simulated environment to test various scenarios and corner cases.</li> <li>Hardware Abstraction: Allows developers to focus on the software logic without being bogged down by hardware specifics.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.0%3A-Standards%3A-vDevice-Overview/#key-components","title":"Key Components","text":"<p>The vDevice comprises of core components:</p> <ul> <li>vDevice Architecture Overview: Overview of the vDevice architecture and its role in enabling hardware abstraction and platform flexibility.</li> <li>vDevice Controller: The central orchestrator responsible for managing vComponents and the control plane.</li> <li>Control Plane: Enabling control and configuration of the running environment.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.0%3A-Standards%3A-vDevice-Controller/","title":"Controller","text":"<p>Purpose:</p> <p>Provides a software-based vDevice for simulating the environment of the target platform. Designed to be modular and flexible, allowing for the testing and development of various components.</p> <p>Key Components:</p> <ul> <li>vDevice Controller:<ul> <li>The central orchestrator of the virtualised system.</li> <li>Manages the lifecycle of vComponent instances (initialising, starting, and stopping).</li> <li>Handles the control plane socket, routing control messages to appropriate vComponent instances.</li> </ul> </li> <li>vComponent:<ul> <li>Represents a specific HAL / Operational module within the software stack.</li> <li>Receives and processes control plane messages and will extract information relevant to its specific domain.</li> <li>Can optionally run in standalone mode with their own control plane sockets.</li> </ul> </li> <li>Control Plane:<ul> <li>Provides a WebSocket interface for sending control messages to alter the behaviour of internal components.</li> <li>Allows external users or systems to control, configure, or trigger actions in vComponents.</li> <li>Supports communication across multiple modules using YAML-based messages, enabling flexible and scalable control.</li> </ul> </li> </ul> <p>Architecture:</p> <ul> <li>Modular Design: vComponent instances are packaged as component libraries, ideally moving towards <code>opkg</code> for easier integration.</li> <li>Centralized Control: The vDevice Controller acts as the main coordinator.</li> <li>Unified Control Plane: The vDevice Controller provides a common control plane socket for all modules.</li> </ul> <p>System Workflow (Boot Sequence)</p> <ol> <li>Initialization: vDevice Controller starts up and loads configuration.</li> <li>Component Registration: Initialization and exit functions of each vComponent instance are registered with the vDevice Controller.</li> <li>Control Plane Activation: vDevice Controller initiates the control plane socket.</li> <li>Component Startup: vDevice Controller triggers the initialization (<code>init()</code> function) of all registered vComponent instances based on the provided platform profile.</li> </ol> <p>Considerations:</p> <ul> <li>Platform Profile: Ensure that the <code>platformProfile.yaml</code> format is well-defined, enabling flexible configuration of vComponent instances during startup.</li> <li>Control Plane Messages: Clearly define the structure and types of control plane messages that the system will use.</li> <li>Documentation: Thoroughly document each vComponent instance's API, supported control messages, and configuration options.</li> </ul> <pre><code>graph TD\n    subgraph System\n        subgraph High Level Overview\n          EmulatorController[vDevice] --&gt; |Initializes/Terminates| ModuleEmulator1[vComponent 1]\n          EmulatorController --&gt; |Initializes/Terminates| ModuleEmulator2[vComponent 2] \n          EmulatorController --&gt; |Initializes/Terminates| ModuleEmulatorN[vComponent N]\n         end \n         subgraph Starting/Stopping\n          EmulatorController --&gt; |Starts/Stops| ModuleEmulator1\n          EmulatorController --&gt; |Starts/Stops| ModuleEmulator2 \n          EmulatorController --&gt; |Starts/Stops| ModuleEmulatorN\n         end \n        EmulatorController --&gt; |Control Plane Socket| ControlPlane[Control Plane]\n        subgraph MessageSending\n           ControlPlane -- Sends Messages --&gt; ModuleEmulator1\n           ControlPlane -- Sends Messages --&gt; ModuleEmulator2\n           ControlPlane -- Sends Messages --&gt; ModuleEmulatorN\n         end \n    end</code></pre>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/","title":"Control Plane","text":"<p>The Control Plane is a central component responsible for facilitating interaction between external users or systems and the internal behaviour of both virtual devices (vComponents) and physical rack setups. Control messages are used to configure and control devices, whether they're virtual or physically connected racks, depending on the platform configuration.\u00a0</p>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#key-points","title":"Key Points","text":"<ul> <li>WebSocket Interface (for vDevices):</li> <li>When dealing with virtual devices (vComponents), the Control Plane exposes a WebSocket server that provides a connection for external stimulus.</li> <li> <p>Test users, automation tools, or other systems use this WebSocket interface to send control messages to virtual components in real-time.</p> </li> <li> <p>Control for Physical Rack Setups:</p> </li> <li> <p>In a physical rack setup, the WebSocket is not used. Instead, the ControlPlaneClass interprets the control messages, determining whether they are intended for a virtual device or a physical rack, and converts them into commands that control the physical rack via python_raft control classes. \u00a0 - If the message involves controlling external hardware, the ControlPlaneClass uses the python_raft control classes to handle the necessary configurations and manage the rack\u2019s hardware interactions.</p> </li> <li> <p>Control Messages:</p> </li> <li>Control messages are structured using YAML format and are designed to control both virtual and physical setups based on the system configuration.</li> <li>The same message format can apply to both virtual and physical environments. For instance, a command to power on a device could either trigger an action on a virtual HDMI device or, if connected externally to a rack, control the actual hardware via python_raft.</li> <li> <p>The ControlPlaneClass interprets each message and routes it to the appropriate target\u2014either via a WebSocket to a virtual device or through python_raft to a physical rack.</p> </li> <li> <p>Unified Message Handling:</p> </li> <li> <p>The Control Plane seamlessly handles both virtual and physical environments by using the same control message structure. The ControlPlaneClass decides whether the message is targeting a virtual device or a physical rack, ensuring flexible and unified control. \u00a0 - For virtual devices, the control message is routed through a WebSocket to the relevant vComponent. \u00a0 - For physical racks, the control message is processed by the ControlPlaneClass, which converts it into commands for the python_raft control classes to configure and control the hardware directly.</p> </li> <li> <p>Python Raft Integration:</p> </li> <li>When using python_raft, the system sends control messages to the ControlPlaneClass, which interprets them and interacts with the python_raft control classes to manage the physical hardware. \u00a0 - If the system is configured for virtual devices, the ControlPlaneClass will instead forward the message via the WebSocket to the relevant vComponent.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#control-plane-workflow","title":"Control Plane Workflow","text":""},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#1-message-reception","title":"1. Message Reception","text":"<p>The ControlPlaneClass receives control messages. Depending on the nature of the message and the platform configuration, it determines whether the message is targeting a virtual device or an external rack setup.</p> <ul> <li>vDevice Setup: The control message is sent through the WebSocket and processed by the vDevice Controller, which forwards the message to the appropriate vComponent.</li> <li>Rack Setup: If the message requires controlling external hardware, the ControlPlaneClass converts the message into specific commands for the python_raft control classes, which then control the rack hardware.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#2-message-routing","title":"2. Message Routing","text":"<ul> <li>For virtual components, the message is routed through the WebSocket to the relevant vComponent, which processes the message and acts accordingly.</li> <li>For rack setups, the ControlPlaneClass uses the python_raft control classes to control the hardware directly, without the need for a WebSocket.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#3-component-or-rack-response","title":"3. Component or Rack Response","text":"<ul> <li> <p>vComponents interpret and execute the control message, triggering actions such as powering on a device, switching inputs, or sending callbacks.</p> </li> <li> <p>Rack setups receive the control commands from python_raft, and the hardware is configured or controlled based on the instructions in the message (e.g., powering on, connecting devices, etc.).</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#considerations-for-control-plane-messages","title":"Considerations for Control Plane Messages","text":"<ul> <li>Unified Message Structure: Control messages for both virtual and physical environments are unified and pre-defined. The ControlPlaneClass interprets these messages and determines the target (virtual or physical) based on the platform configuration.</li> <li>Platform Configuration: The ControlPlaneClass determines the appropriate actions based on the nature of the message and the system\u2019s platform configuration\u2014whether it's a virtual or physical (rack) environment.</li> <li>Logging and Debugging: Debugging tools will capture control messages and their processing outcomes to ensure smooth operation and easy diagnosis in both virtual and physical setups.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#advantages-of-using-the-control-plane","title":"Advantages of Using the Control Plane","text":"<ul> <li>Unified Control for Mixed Environments: The same control plane can manage both virtual devices and physical racks, ensuring seamless control across environments.</li> <li>Modular and Scalable: New vComponents or additional physical rack configurations can easily be integrated into the system using the same control message structure.</li> <li>Real-time Configuration: The WebSocket interface (for vDevices) and the python_raft control classes (for racks) allow real-time control of both virtual and physical systems.</li> <li>Platform-agnostic Flexibility: The Control Plane adapts to the environment, whether it\u2019s controlling virtual test environments or physical hardware, making it a versatile tool for a wide range of deployment scenarios.</li> </ul>"},{"location":"external_content/ut-core-wiki/5.1.1%3A-Standards%3A-vDevice-Control-Plane/#overview-of-expected-operation","title":"Overview of expected operation","text":"<pre><code>graph TD\n    subgraph ControlPlaneClass\n        A(Control Plane) --&gt;|Message Routing| B{Platform Configuration}\n    end\n\n    B --&gt;|vDevice| C[WebSocket Interface]\n    B --&gt;|Rack Setup| D[python_raft Control Classes]\n\n    subgraph vDevice Setup\n        C --&gt; E[vComponent 1]\n        C --&gt; F[vComponent 2]\n        C --&gt; G[vComponent N]\n    end\n\n    subgraph Rack Setup\n        D --&gt; M[Control Component 1]\n        D --&gt; N[Control Component 2]\n        D --&gt; O[Control Component N]\n        M --&gt; H[Rack Hardware 1]\n        N --&gt; I[Rack Hardware 2]\n        O --&gt; J[Rack Hardware N]\n    end\n\n    A -. External stimulus .-&gt; K[Test User]\n    K --&gt; A</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/","title":"When to Use QEMU","text":"<p>QEMU is a low-level virtualization tool that provides flexible control over virtual machines. It\u2019s best for situations where you need to: 1. Run custom configurations:    - Boot kernels directly (<code>uImage</code>, <code>zImage</code>, etc.).    - Simulate specific hardware architectures (ARM, x86, RISC-V, etc.).    - Configure low-level aspects like CPU type, machine type, or device emulation. 2. Support Embedded/IoT Development:    - QEMU is often used in embedded development for ARM-based or custom hardware simulations. 3. Run Lightweight Virtual Machines:    - You don\u2019t need Vagrant\u2019s higher-level management or provisioning capabilities. 4. Fine-Tuned Performance:    - QEMU allows advanced optimizations, especially with KVM for near-native speeds on x86 or Apple Silicon.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#pros-of-qemu","title":"Pros of QEMU:","text":"<ul> <li>Flexibility: Full control over the visualized hardware and kernel-level configuration.</li> <li>Architecture Support: Wide compatibility with architectures (ARMv7, ARM64, x86, RISC-V, etc.).</li> <li>Lightweight: No dependency on additional layers (like Vagrant) if you\u2019re scripting everything.</li> <li>Hardware Simulation: Emulates peripherals, GPUs, and devices, making it ideal for embedded development.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#cons-of-qemu","title":"Cons of QEMU:","text":"<ul> <li>Steeper Learning Curve: Requires manually configuring VM settings via CLI or scripts.</li> <li>Manual Management: Lacks built-in features for orchestrating multiple VMs or managing dependencies.</li> <li>No Provisioning Framework: You\u2019ll need custom scripts to install software/apps.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#best-use-cases-for-qemu","title":"Best Use Cases for QEMU:","text":"<ul> <li>You\u2019re working with custom hardware configurations (e.g., ARMv7, ARM64, or specific machine types).</li> <li>You need a lightweight, low-level VM without external tools.</li> <li>You\u2019re developing or testing embedded systems, kernels, or OS images.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#when-to-use-vagrant","title":"When to Use Vagrant","text":"<p>Vagrant is a higher-level tool designed to manage and automate virtual machine workflows. It abstracts much of the low-level VM setup and provides features like provisioning, networking, and multi-VM orchestration.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#pros-of-vagrant","title":"Pros of Vagrant:","text":"<ul> <li>Ease of Use: Automates VM creation and provisioning (installing apps, configuring environments).</li> <li>Provisioning: Built-in support for provisioning tools like Shell scripts, Ansible, Puppet, or Chef.</li> <li>Multi-VM Support: Easily define and manage multiple VMs in a single <code>Vagrantfile</code>.</li> <li>Cross-Provider Support: Works with VirtualBox, VMware, QEMU (via <code>libvirt</code>), and cloud providers like AWS.</li> <li>Portability: Shareable <code>Vagrantfile</code> makes it easy to replicate environments across systems.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#cons-of-vagrant","title":"Cons of Vagrant:","text":"<ul> <li>Resource Overhead: Adds an abstraction layer, which may slightly increase resource usage compared to QEMU alone.</li> <li>Dependency on Providers: Requires a supported provider like VirtualBox, libvirt, or VMware.</li> <li>Less Flexibility: While configurable, it abstracts many low-level options available in QEMU.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#best-use-cases-for-vagrant","title":"Best Use Cases for Vagrant:","text":"<ul> <li>You need to deploy multiple VMs with defined roles (e.g., database server, web server, etc.).</li> <li>You want to automate application installations and VM configuration.</li> <li>You need consistency across environments (e.g., development, testing, staging).</li> <li>You\u2019re working with a team and want a shareable, reproducible VM setup.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#comparison-table","title":"Comparison Table","text":"Feature QEMU Vagrant Ease of Use CLI or custom scripts required High-level abstraction, easy to use Multi-VM Management Manual setup via scripting Built-in support in <code>Vagrantfile</code> Provisioning Requires custom scripts Supports Shell, Ansible, Puppet, etc. Performance Lightweight, minimal overhead Slightly more overhead Architecture Support ARM, x86, RISC-V, custom hardware Depends on provider (e.g., libvirt, VirtualBox) Flexibility Full control over low-level config Less control, but easier to use Team Collaboration Requires sharing scripts manually Shareable, portable <code>Vagrantfile</code> Application Setup Manual installation/scripts Automates via provisioning"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#recommendations","title":"Recommendations","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#use-qemu-if","title":"Use QEMU if:","text":"<ol> <li>You\u2019re working with custom hardware architectures or embedded systems (e.g., ARMv7/ARM64 development).</li> <li>You want lightweight and fine-grained control over virtual machine setup.</li> <li>You\u2019re comfortable writing and maintaining custom scripts for managing VMs and provisioning.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#use-vagrant-if","title":"Use Vagrant if:","text":"<ol> <li>You need to manage multiple VMs with predefined roles and configurations (e.g., app server, database server).</li> <li>You want to automate application installation and environment setup via provisioning.</li> <li>You work in a team environment and need shareable, consistent VM setups.</li> <li>You value simplicity and portability for managing VMs.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#hybrid-approach-qemu-vagrant","title":"Hybrid Approach: QEMU + Vagrant","text":"<p>If you want the flexibility of QEMU and the automation capabilities of Vagrant, you can combine both: 1. Use QEMU as the virtualization backend with the <code>vagrant-libvirt</code> plugin. 2. Manage multiple VMs and application installations through Vagrant\u2019s provisioning system.</p> <p>Example: Vagrantfile for Multiple ARMv7 VMs Using QEMU</p> <pre><code>Vagrant.configure(\"2\") do |config|\n  # VM 1: Web Server\n  config.vm.define \"web\" do |web|\n    web.vm.provider \"libvirt\" do |libvirt|\n      libvirt.arch = \"arm\"\n      libvirt.machine_type = \"virt\"\n      libvirt.cpus = 2\n      libvirt.memory = 1024\n      libvirt.kernel = \"/path/to/web_kernel/zImage\"\n      libvirt.initrd = \"/path/to/web_initrd.img\"\n      libvirt.cmd_line = \"console=ttyAMA0 root=/dev/vda rw\"\n    end\n    web.vm.provision \"shell\", inline: \"sudo apt-get install -y nginx\"\n  end\n\n  # VM 2: Database Server\n  config.vm.define \"db\" do |db|\n    db.vm.provider \"libvirt\" do |libvirt|\n      libvirt.arch = \"arm\"\n      libvirt.machine_type = \"virt\"\n      libvirt.cpus = 2\n      libvirt.memory = 2048\n      libvirt.kernel = \"/path/to/db_kernel/zImage\"\n      libvirt.initrd = \"/path/to/db_initrd.img\"\n      libvirt.cmd_line = \"console=ttyAMA0 root=/dev/vda rw\"\n    end\n    db.vm.provision \"shell\", inline: \"sudo apt-get install -y mariadb-server\"\n  end\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A--QEMU-vs-Vagrant/#conclusion","title":"Conclusion","text":"<ul> <li>For low-level control, QEMU is better, but it requires more effort for multi-VM setups and application provisioning.</li> <li>For multi-VM orchestration and ease of app installation, Vagrant is a better choice.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/","title":"Video and Audio Playback Performance Metrics Overview","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#purpose","title":"Purpose","text":"<p>This document provides a standardized set of metrics for monitoring and evaluating playback performance across video and audio streams on various platforms. These metrics help assess synchronization between the display and audio pipelines, efficiency in frame and audio buffer handling, and overall playback quality. This approach enables consistent performance analysis and identification of playback issues for both video and audio-only playback.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#core-metrics-for-video-playback","title":"Core Metrics for Video Playback","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#1-vsync-frame-rate","title":"1. VSync Frame Rate","text":"<ul> <li>Definition: The frame rate of the display, representing the refresh rate at which frames are displayed.</li> <li>Use: Determines the frequency of display refreshes, crucial for synchronizing video playback.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#2-number-of-vsyncs","title":"2. Number of VSyncs","text":"<ul> <li>Definition: Total count of vertical synchronization (VSync) events during playback.</li> <li>Use: Tracks display refresh occurrences over a specific playback duration.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#3-number-of-displayed-frames","title":"3. Number of Displayed Frames","text":"<ul> <li>Definition: The count of decoded frames successfully displayed on the screen.</li> <li>Use: Indicates the number of frames processed and displayed, which should typically align with the number of VSyncs or half of them, depending on the playback rate.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#4-number-of-frame-rate-conversions-frc","title":"4. Number of Frame Rate Conversions (FRC)","text":"<ul> <li>Definition: Occurs when the encoded frame rate differs from the display refresh rate, necessitating frame rate adjustments.</li> <li>Use: Measures the proportion of frame rate conversions to displayed frames. For example:<ul> <li>A 24fps encoded stream shown at 48fps should maintain a 50:50 FRC-to-displayed frames ratio.</li> <li>A 60fps encoded stream displayed at 60fps should have an FRC-to-displayed frames ratio of 0:100.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#5-number-of-repeated-frames","title":"5. Number of Repeated Frames","text":"<ul> <li>Definition: Count of frames repeated due to the next frame\u2019s presentation timestamp (PTS) arriving too early, or video pause.</li> <li>Use: Indicates frame repetition instances, often due to timing issues where frames are displayed more than once because of early frame arrival or playback pauses.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#6-number-of-dropped-frames","title":"6. Number of Dropped Frames","text":"<ul> <li>Definition: Count of frames discarded because their PTS was behind the system\u2019s presentation clock (STC).</li> <li>Use: Indicates frame drops, often caused by performance lags, impacting playback smoothness.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#7-number-of-underruns-video","title":"7. Number of Underruns (Video)","text":"<ul> <li>Definition: Count of times the video pipeline was empty, meaning the display frame queue size was one frame or lower.</li> <li>Use: Tracks pipeline starvation, where playback cannot keep up with display demands, causing playback interruptions.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#expected-metric-behavior-for-video-playback","title":"Expected Metric Behavior for Video Playback","text":"<p>During playback, the following metric behaviors are expected:</p> <ul> <li> <p>VSync Events: The number of VSync events should match the playback duration when divided by the VSync frame rate.</p> </li> <li> <p>Displayed Frames: Should correspond to the encoded frame rate in relation to the VSync rate. For example, 10 seconds of playback at a 60Hz VSync rate should yield around 600 VSync events, with displayed frames aligning proportionally.</p> </li> <li> <p>Frame Rate Conversions: Frame rate conversions should match the ratio expected based on the encoded vs. display frame rates.</p> </li> <li> <p>Repeated, Dropped Frames, and Underruns: These values should remain at zero for optimal playback. Non-zero values highlight issues like timing (repeated frames), performance (dropped frames), or pipeline delays (underruns).</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#core-metrics-for-audio-playback","title":"Core Metrics for Audio Playback","text":"<p>For audio playback, where the stream is audio-only or audio is being decoded alongside video, the focus is on buffer management and pipeline stability:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#1-audio-underruns","title":"1. Audio Underruns","text":"<ul> <li>Definition: The count of times the audio buffer was empty, causing interruptions in audio playback.</li> <li>Use: Indicates situations where the audio playback pipeline fails to maintain a continuous stream, often due to decoding or buffer management issues, causing gaps or stutters in audio.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#2-audio-overruns","title":"2. Audio Overruns","text":"<ul> <li>Definition: The count of instances where the audio buffer exceeded its maximum capacity, typically causing delays or blocking further processing until the buffer is cleared.</li> <li>Use: Reveals audio buffer overflows, potentially indicating a blockage or backpressure within the pipeline. This may occur if the buffer fills up faster than it can be processed, leading to stalled playback or delayed audio.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#expected-metric-behavior-for-audio-playback","title":"Expected Metric Behavior for Audio Playback","text":"<ul> <li> <p>Free-Running Audio: Typically, in non-broadcast environments, audio is expected to be the master clock and run freely, without frame drops or repeats. Video playback adjusts to remain in sync with the audio, ideally by adjusting the display clock to align with the audio playback.</p> </li> <li> <p>Underruns and Overruns: For audio playback, underruns and overruns should ideally be zero. Frequent underruns indicate that the audio decoding process cannot supply data quickly enough, resulting in gaps or interruptions. Overruns suggest buffer management issues, possibly due to a backlog in audio processing or timing delays.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#regression-testing-for-playback-verification","title":"Regression Testing for Playback Verification","text":"<p>When using these metrics to validate playback performance and check for regressions, a set of standardized test streams should be used. For each test stream, baseline metrics (expected values for VSyncs, displayed frames, FRC, underruns, overruns, etc.) should be predefined. The measured values during playback can then be compared against these baselines to determine if the build passes or fails the playback test.</p> <p>By establishing known output values for these metrics, you can: - Quickly identify deviations from expected behavior, which may indicate performance or synchronization regressions. - Verify that the latest build maintains playback quality and stability across video and audio metrics.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A--Video-and-Audio-Playback-Performance-Metrics/#additional-considerations-for-implementation","title":"Additional Considerations for Implementation","text":"<p>The initial design for these generic hardware abstraction layer (HAL) metrics collection is intended to provide a unified approach for gathering video and audio playback performance metrics across platforms ensuring standardized collection across hardware could enhance cross-platform testing and optimization.</p> <p>Author: S.Webster</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Black%E2%80%90Box-Testing-and-Code-Coverage-Metrics/","title":"Black-box vs White-box","text":"<p>Black-box testing and white-box testing are two fundamental approaches to software testing. They differ primarily in their focus and the level of access to the internal workings of the system under test. Here's a breakdown of their key differences:</p> <p>Black-box Testing</p> <ul> <li>Focus: Functionality and external behaviour of the software.</li> <li>Internal knowledge: Testers do not need knowledge of the internal code, structure, or implementation details.</li> <li>Techniques:  Equivalence partitioning, boundary value analysis, decision table testing, state transition testing, use case testing.</li> <li>Advantages:<ul> <li>Simulates user perspective.</li> <li>Unbiased testing, as testers are not influenced by the code.</li> <li>Can be conducted by a separate testing team.</li> </ul> </li> <li>Disadvantages: <ul> <li>Potential for redundant testing.</li> <li>May miss certain code paths or logic errors.</li> <li>Difficult to design test cases without understanding the internal workings.</li> </ul> </li> </ul> <p>White-box Testing</p> <ul> <li>Focus: Internal structure, code, and logic of the software.</li> <li>Internal knowledge: Testers require detailed knowledge of the code base.</li> <li>Techniques: Statement coverage, branch coverage, path coverage, condition coverage, mutation testing.</li> <li>Advantages:<ul> <li>Thorough testing of all code paths and logic.</li> <li>Helps identify hidden errors and vulnerabilities.</li> <li>Can be performed early in the development cycle.</li> </ul> </li> <li>Disadvantages: <ul> <li>Requires programming skills and knowledge.</li> <li>Can be time-consuming and complex.</li> <li>May not identify issues related to user experience or usability.</li> </ul> </li> </ul> <p>In essence:</p> <ul> <li>Black-box testing treats the software as a \"black box,\" focusing on what it does rather than how it does it.</li> <li>White-box testing opens the \"black box,\" allowing testers to examine the internal workings and ensure that the code functions as intended.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Black%E2%80%90Box-Testing-and-Code-Coverage-Metrics/#black-box-testing-code-coverage","title":"Black Box Testing Code Coverage","text":"<p>In black-box testing, you don't have access to the internal code, so achieving complete code path coverage is not possible. </p> <p>Here's why:</p> <ul> <li>Lack of Visibility: Black-box testing focuses on the external behavior of the software. Testers provide inputs and observe outputs without knowing how the system processes those inputs internally. This means they can't directly target specific code paths.</li> <li>Input-Output Focus: Black-box testing relies on various techniques like equivalence partitioning, boundary value analysis, and state transition testing to design test cases. These techniques aim to cover a wide range of input scenarios and system behaviors, but they don't guarantee that all code paths will be executed.</li> <li>Complexity:  Software can have numerous code paths, including complex conditional statements and loops. Without code access, it's incredibly difficult to design test cases that guarantee the execution of every possible path.</li> </ul> <p>However, while full code path coverage isn't achievable, black-box testing can still provide good coverage in terms of:</p> <ul> <li>Functionality: Black-box testing can effectively uncover functional defects and ensure the software meets its requirements from a user perspective.</li> <li>Usability: It can help identify usability issues and ensure the software is user-friendly.</li> <li>Performance: Black-box testing can be used to assess performance characteristics like response time and resource usage.</li> <li>Security:  It can help uncover security vulnerabilities by testing different attack vectors.</li> </ul> <p>To maximize coverage in black-box testing, it's important to:</p> <ul> <li>Have clear and comprehensive requirements: This helps in designing effective test cases.</li> <li>Use a variety of testing techniques: Combining different black-box techniques can increase the chances of covering more scenarios.</li> <li>Prioritize critical functionalities: Focus on testing the most important and frequently used parts of the software.</li> </ul> <p>In summary: While black-box testing cannot guarantee full code path coverage, it remains a valuable approach for testing software from a user's perspective and uncovering a wide range of defects. To achieve broader coverage, it's often combined with white-box testing techniques that directly analyze the code.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/","title":"Building Code Modules for Embedded Linux: A Comparison of Build Systems","text":"<p>This comparison focuses exclusively on the best methods for developers to build a single code module (e.g., a library or application) for an embedded Linux system. We are not concerned with building complete system images. Instead, we'll examine how each tool helps a developer compile, link, and prepare code for an embedded target.</p> <p>Key Principle: The module's build system should be triggered independently and not rely on the framework itself to initiate the build. This ensures the module remains portable and can be built on different systems without depending on the specific framework.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#buildroot","title":"Buildroot","text":"<ul> <li>Relevance for module development:  Buildroot can be adapted to build individual modules, leveraging its cross-compilation toolchain and dependency management. However, it may require extra effort to separate module builds from the Buildroot build process.</li> <li>Developer Experience: Provides a pre-configured environment, but integration with external build systems might require workarounds.</li> <li>Customization: Limited flexibility for integrating with existing build systems.</li> <li>Learning Curve: Relatively easy for basic usage.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#yocto-project","title":"Yocto Project","text":"<ul> <li>Relevance for module development: While powerful for building components, Yocto should be used to configure existing build scripts (Makefiles, CMake) rather than directly building the module. This ensures the module remains independent.</li> <li>Developer Experience:  Can be complex to integrate with external build systems due to its layered structure and BitBake.</li> <li>Customization: Highly customizable, but this can add complexity when integrating with existing build scripts.</li> <li>Learning Curve: Steep.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#bob-the-builder","title":"Bob the Builder","text":"<ul> <li>Relevance for module development: Well-suited for building modules in isolated environments. You can define dependencies and trigger builds independently.</li> <li>Developer Experience:  Modern approach with declarative configuration and containerization. Aims for ease of use and reproducibility.</li> <li>Customization:  Offers a balance between flexibility and ease of use for integrating with existing build systems.</li> <li>Learning Curve: Moderate.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#cmakemakescripts","title":"CMake/Make/Scripts","text":"<ul> <li>Relevance for module development: The most direct and independent approach. You have full control over the build process and can easily integrate with any distribution.</li> <li>Developer Experience:  Familiar tools for many developers, but requires manual configuration and scripting.</li> <li>Customization:  Highly customizable.</li> <li>Learning Curve:  Can range from moderate to steep.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#bazel","title":"Bazel","text":"<ul> <li>Relevance for module development: Excellent for building complex projects with many dependencies. Strong support for hermetic builds and remote caching.</li> <li>Developer Experience: Can have a steeper learning curve, but offers powerful features and good performance.</li> <li>Customization: Highly customizable through <code>BUILD</code> files.</li> <li>Key Considerations: May require more effort to set up initially.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#meson","title":"Meson","text":"<ul> <li>Relevance for module development: Good for building C/C++ modules. Simpler syntax and faster build times compared to CMake.</li> <li>Developer Experience: Generally considered easier to learn and use than CMake.</li> <li>Customization: Provides good customization options.</li> <li>Key Considerations: Growing in popularity, but the community might not be as large as CMake's.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#scons","title":"SCons","text":"<ul> <li>Relevance for module development: Can be used to build C/C++ modules. Offers more flexibility than Make and integrates well with Python.</li> <li>Developer Experience: Python knowledge can be helpful.</li> <li>Customization: Highly customizable due to its Python foundation.</li> <li>Key Considerations: Not as widely used as CMake or Make.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#platformio","title":"PlatformIO","text":"<ul> <li>Relevance for module development: Provides a simplified way to build modules for various embedded platforms. Can handle cross-compilation and dependencies.</li> <li>Developer Experience: User-friendly with good IDE support.</li> <li>Customization: Offers a good level of customization for embedded projects.</li> <li>Key Considerations: More focused on microcontroller-based platforms.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#custom-shell-scripts","title":"Custom Shell Scripts","text":"<ul> <li>Relevance for module development: Provides maximum flexibility and control. You can use any tools and commands you need.</li> <li>Developer Experience: Requires good shell scripting knowledge.</li> <li>Customization: Completely customizable.</li> <li>Key Considerations: Best for simple modules or when you need very specific control.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#summary-table","title":"Summary Table","text":"Feature Buildroot Yocto Bob CMake/Make Bazel Meson SCons PlatformIO Custom Scripts Focus Root filesystem Component building Streamlined builds Code building Complex builds C/C++ modules Flexible builds Embedded ecosystem Maximum control Author/Origin Peter Korsgaard Yocto Project Sony Kitware (CMake) Google Jussi Pakkanen Steven Knight PlatformIO N/A Configuration <code>menuconfig</code> Layers/recipes YAML <code>CMakeLists.txt</code>, Makefiles <code>BUILD</code> files Meson files Python scripts PlatformIO config Shell scripts Build System Makefile-based BitBake Docker CMake/Make + custom Bazel Meson SCons PlatformIO Custom Customization Limited High Balanced High High Good High Good Complete Independent Builds Requires effort Configure, not build Well-suited Ideal Excellent Good Good Good Ideal Community Active Large Growing Massive Growing Growing Moderate Growing N/A Learning Curve Moderate Steep Moderate Moderate/Steep Steep Moderate Moderate Moderate Moderate/Steep Dev Experience Less flexible Complex Modern Familiar but manual Powerful but steep User-friendly Python-based User-friendly Requires scripting Strengths Pre-configured Dependency management Reproducible builds Flexibility Hermetic builds Speed, simplicity Flexibility Simplified workflow Maximum control Weaknesses Not for modules Overkill, integration Relatively new Can be complex Initial setup Community size Less widely used Microcontroller focus Can be complex"},{"location":"external_content/ut-core-wiki/FAQ%3A-Buildroot-vs.-Yocto-Project-vs.-Bob-the-Builder/#which-one-to-choose-for-developing-code-modules","title":"Which one to choose (for developing code modules)?","text":"<ul> <li>Quick cross-compilation with standard libraries: Buildroot (with adaptation)</li> <li>Manage complex dependencies, configure build scripts: Yocto (configure, not build)</li> <li>Modern, reproducible environment, good developer experience: Bob the Builder</li> <li>Flexibility, control, portability, comfortable with scripting: CMake/Make/Scripts</li> <li>Complex projects, hermetic builds, remote caching: Bazel</li> <li>User-friendly build system for C/C++ modules: Meson</li> <li>Flexibility and Python integration: SCons</li> <li>Simplified workflow for embedded platforms: PlatformIO</li> <li>Maximum control and customization: Custom Shell Scripts</li> </ul> <p>Choosing the right tool depends on your module's complexity, your team's expertise, and your desired level of customization. Prioritize independent module builds to ensure portability and avoid unnecessary dependencies on the build framework.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-C-Macro-that-prints-structure-fields/","title":"FAQ: C Macro that prints structure fields","text":"<p>This macro prints the structure name, field names, and their corresponding values:</p> <pre><code>#include &lt;stdio.h&gt;\n\n#define LOG_STRUCT(structVar) \\\n    do { \\\n        printf(\"Structure: %s\\n\", #structVar); \\\n        _log_struct_helper(structVar); \\\n    } while (0)\n\n#define _log_struct_helper(structVar) \\\n    _log_struct_fields_helper(structVar, _get_struct_fields(structVar))\n\n#define _get_struct_fields(structVar) \\\n    _get_struct_fields_helper(0, structVar)\n\n#define _get_struct_fields_helper(index, structVar) \\\n    _Generic((structVar), \\\n        default: _get_struct_fields_helper(index + 1, structVar), \\\n        char: #structVar.index, \\\n        int: #structVar.index, \\\n        float: #structVar.index, \\\n        double: #structVar.index, \\\n        char *: #structVar.index, \\\n        int *: #structVar.index, \\\n        float *: #structVar.index, \\\n        double *: #structVar.index \\\n    )\n\n#define _log_struct_fields_helper(structVar, fieldName, ...) \\\n    do { \\\n        printf(\"  %s = \", fieldName); \\\n        _print_field_value(structVar.index); \\\n        if (sizeof((int[]){__VA_ARGS__})/sizeof(int) &gt; 0) { \\\n            printf(\"\\n\"); \\\n            _log_struct_fields_helper(structVar, __VA_ARGS__); \\\n        } \\\n    } while (0)\n\n#define _print_field_value(fieldValue) \\\n    _Generic((fieldValue), \\\n        char: printf(\"%c\", fieldValue), \\\n        int: printf(\"%d\", fieldValue), \\\n        float: printf(\"%f\", fieldValue), \\\n        double: printf(\"%lf\", fieldValue), \\\n        char *: printf(\"%s\", fieldValue), \\\n        default: printf(\"%p\", (void*)fieldValue) \\\n    )\n</code></pre> <p>Explanation</p> <ul> <li><code>LOG_STRUCT</code>: This is the main macro that you'll use. It takes the structure variable as input and prints the structure's name.</li> <li><code>_log_struct_helper</code>: This helper function recursively processes the structure fields.</li> <li><code>_get_struct_fields</code>: This helper function uses <code>_Generic</code> to determine the types of fields in the structure and generates a list of field names.</li> <li><code>_log_struct_fields_helper</code>: This helper function iterates over the list of field names, prints each field name and its value using <code>_print_field_value</code>.</li> <li><code>_print_field_value</code>: This helper function uses <code>_Generic</code> to print the field value based on its type. It handles basic types like <code>char</code>, <code>int</code>, <code>float</code>, <code>double</code>, and pointers to these types. For other types, it prints the memory address.</li> </ul> <p>Example Usage</p> <pre><code>typedef struct {\n    int id;\n    char name[50];\n    float price;\n} Product;\n\nint main() {\n    Product p = {1, \"Sample Product\", 9.99};\n    LOG_STRUCT(p);\n    return 0;\n}\n</code></pre> <p>Output</p> <pre><code>Structure: p\n  id = 1\n  name = Sample Product\n  price = 9.990000\n</code></pre> <p>Key Points:</p> <ul> <li>Limited Type Support: The macro currently supports basic types (<code>char</code>, <code>int</code>, <code>float</code>, <code>double</code>) and pointers to these types. You can extend it to handle other types by adding more cases to the <code>_Generic</code> expressions in <code>_get_struct_fields_helper</code> and <code>_print_field_value</code>.</li> <li>Nested Structures: The macro does not currently handle nested structures. You would need to add more logic to recursively process nested structures if required.</li> <li>Arrays: The macro handles arrays of basic types by printing their memory address. To print the individual elements of an array, you'll need to add custom logic.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-C-macro-that-prints-the-function-name%2C-parameter-names-with-values/","title":"FAQ: C macro that prints the function name, parameter names with values","text":"<p>C macro that prints the function name, parameter names, and their corresponding values for debugging purposes. </p> <p>It uses the <code>__func__</code> identifier to get the function name and variadic macros to handle a variable number of parameters.</p> <pre><code>#include &lt;stdio.h&gt;\n\n#define LOG_PARAMS(...) \\\n    do { \\\n        printf(\"%s(\", __func__); \\\n        _log_params_helper(__VA_ARGS__); \\\n        printf(\")\\n\"); \\\n    } while (0)\n\n#define _log_params_helper(param, ...) \\\n    do { \\\n        printf(#param \" = %p\", (void*)param); \\\n        if (sizeof((int[]){__VA_ARGS__})/sizeof(int) &gt; 0) { \\\n            printf(\", \"); \\\n            _log_params_helper(__VA_ARGS__); \\\n        } \\\n    } while (0)\n</code></pre> <p>Explanation:</p> <ul> <li><code>LOG_PARAMS</code>: This is the main macro that you'll use in your functions. <ul> <li>It uses <code>__func__</code> to print the function name.</li> <li>It calls <code>_log_params_helper</code> to handle the actual parameter logging.</li> </ul> </li> <li><code>_log_params_helper</code>: This is a recursive helper macro.<ul> <li>It takes a parameter name and its value, prints them in the format <code>param = value</code>.</li> <li>It uses a clever trick with <code>sizeof</code> and an array to check if there are more parameters to log. If so, it recursively calls itself with the remaining parameters.</li> </ul> </li> </ul> <p>Example Usage:</p> <pre><code>void myFunction(int x, float y, char* z) {\n    LOG_PARAMS(x, y, z); \n    // ... rest of your function code\n}\n\nint main() {\n    myFunction(10, 3.14, \"hello\");\n    return 0;\n}\n</code></pre> <p>Output:</p> <pre><code>myFunction(x = 0x7ff... , y = 0x7ff..., z = 0x7ff...)\n</code></pre> <p>Key Points:</p> <ul> <li>Pointers: This macro prints the memory addresses (pointers) of the parameters. For basic types like <code>int</code> or <code>float</code>, you'll see their values directly. For more complex types (structs, arrays), you'll see their memory addresses. You might need to add custom logic within the macro to handle specific types if you want to print their contents directly.</li> <li>Error Handling: This macro doesn't include extensive error handling (e.g., checking for NULL pointers). You might want to add such checks if your code requires them.</li> <li>Portability: <code>__func__</code> is widely supported, but its exact behavior might vary slightly across compilers.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/","title":"FAQ: Choosing GHEC\u2010ORG or RDKCentral","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#choosing-the-right-github-organisation-and-access-level","title":"Choosing the Right GitHub Organisation and Access Level","text":"<p>This document outlines the decision-making process for selecting the appropriate GitHub organisation and repository access level for code storage and collaboration.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#github-organisations","title":"GitHub Organisations","text":"<ul> <li> <p>rdkcentral (Github Teams Plan):</p> <ul> <li>Primarily for open-source projects with public read access.</li> <li>Private repositories require a paid licence for write access.</li> <li>No Comcast login required for public access (Read Only)</li> <li>Cost: Free for public repositories. Paid licences for write access, or private repositories.<ul> <li>Teams plan costs $4 dollars per user per month.</li> </ul> </li> </ul> </li> <li> <p>ghec-org (GHEC - GitHub Enterprise Cloud):</p> <ul> <li>Controlled by Internal DevX.</li> <li>Designed for internal and private repositories.</li> <li>Offers \"private\" (team-based access) and \"internal\" (wider access) repository settings.</li> <li>Cost: Paid enterprise license <ul> <li>GHEC Plan costs $21 dollars per user per month. (Comcast may have a discounted rate due to volume)</li> </ul> </li> </ul> </li> </ul> <p>https://github.com/pricing</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#decision-tree","title":"Decision Tree","text":"<p>The flowchart below illustrates the decision-making process. Here's a breakdown of the key considerations:</p> <ul> <li>Public vs. Controlled Access: If the code needs to be publicly accessible or in the future will be publically accessible , <code>rdkcentral</code> is the appropriate choice. If controlled access is required, <code>ghec-org</code> is preferred.</li> <li> <p>rdkcentral Access Levels:</p> <ul> <li>Public:  Free, read-only access for everyone.</li> <li>Private: Paid licence for write access, restricted to team members.</li> <li>Write: Paid licence for write access, restricted to team members.</li> </ul> </li> <li> <p>ghec-org Access Levels:</p> <ul> <li>Internal: Visible to all users within the <code>ghec-org</code> domain.</li> <li>Private: High security, restricted to specific teams.</li> <li>Partner:  Access for external partners, requiring onboarding to Comcast enterprise.</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Choosing-GHEC%E2%80%90ORG-or-RDKCentral/#key-factors","title":"Key Factors","text":"<ul> <li>Open Source: For new/current or future, open-source projects, <code>rdkcentral</code> with public repositories is ideal.</li> <li>Collaboration with Partners:  If partners need write access, <code>rdkcentral</code> (private) offers a simpler and potentially more cost-effective solution compared to onboarding them to Comcast's GHEC.</li> <li>Security: For highly sensitive code, <code>ghec-org</code> (private) provides the highest level of security.</li> <li>Cost: Consider the costs associated with each option, including paid licences and potential onboarding expenses.</li> </ul> <p>By carefully evaluating these factors and following the decision tree, you can select the most suitable GitHub organisation and access level for your project.</p> <pre><code>graph TD\n    A[Start] --&gt; C{Public or Controlled Access?};\n    C -- Public --&gt; E{rdkcentral};\n    C -- Controlled --&gt; F{ghec-org};\n    E --&gt; G{Read-Only or Write Access?};\n    G -- Read-Only --&gt; H[rdkcentral-public - Tier 2 Engineers];\n    G -- Write Access --&gt; I{rdkcentral-private - Tier 1 Engineers};\n    F --&gt; J{Access Level?};\n    J -- Internal --&gt; K[ghec-org internal];\n    J -- Private --&gt; L[ghec-org private];\n    J -- Partner --&gt; M[ghec-org partner];\n\n    H --&gt; N(Can read all public repos&lt;br&gt;No paid license&lt;br&gt;Changes in personal forks&lt;br&gt;PRs from forks possible&lt;br&gt;Issues &amp; discussions allowed);\n    I --&gt; O(Future public release possible&lt;br&gt;Easy external sharing&lt;br&gt;Lower write access cost&lt;br&gt;No DevX onboarding&lt;br&gt;Branching &amp; PRs allowed&lt;br&gt;Read all public repos&lt;br&gt;Paid license for Tier 1 engineers&lt;br&gt;Issues &amp; discussions allowed);\n    K --&gt; P(Internal, not shared externally&lt;br&gt;All ghec-org users can see);\n    L --&gt; Q(High security&lt;br&gt;No vendor access by default);\n    M --&gt; R(Partner access possible with DevX onboarding&lt;br&gt;Internal DevX codebase access);\n\n    style N fill:#ccf,stroke:#333,stroke-width:2px\n    style O fill:#ccf,stroke:#333,stroke-width:2px\n    style P fill:#ccf,stroke:#333,stroke-width:2px\n    style Q fill:#ccf,stroke:#333,stroke-width:2px\n    style R fill:#ccf,stroke:#333,stroke-width:2px</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/","title":"Python Development","text":"<p>When developing Python applications, your choice of operating system\u2014Mac, Windows, or Linux\u2014can affect the development process in terms of setup, environment management, compatibility, and available tools. Here's a concise comparison of Python development across these three platforms:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#1-setup-and-installation","title":"1. Setup and Installation","text":"<ul> <li>Mac:</li> <li>macOS comes with Python 2.x pre-installed, but Python 3 needs to be installed separately.</li> <li>Installation via Homebrew is recommended for managing multiple versions of Python.</li> <li> <p>Smooth setup for most Python tools and libraries.</p> </li> <li> <p>Windows:</p> </li> <li>Python isn't pre-installed on Windows, so you need to download and install it from the official Python website.</li> <li>The installer now includes an option to add Python to your system's PATH, simplifying setup.</li> <li> <p>Use Windows Subsystem for Linux (WSL) to run Linux-based Python workflows within Windows.</p> </li> <li> <p>Linux:</p> </li> <li>Python is often pre-installed on most Linux distributions (typically Python 3.x).</li> <li>Package managers like apt, yum, or dnf can easily handle Python installation and version management.</li> <li>Linux is closely aligned with Unix-like systems, so Python libraries related to server and system programming often have fewer compatibility issues.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#2-environment-management","title":"2. Environment Management","text":"<ul> <li>Mac:</li> <li>Homebrew simplifies the installation of Python and related tools.</li> <li>Tools like pyenv and virtualenv are commonly used for managing multiple Python versions and virtual environments.</li> <li> <p>Most Python tools work seamlessly with macOS due to its Unix foundation.</p> </li> <li> <p>Windows:</p> </li> <li>Managing Python versions can be done using pyenv-win or Anaconda.</li> <li>Virtual environments are supported, but sometimes require extra configuration due to Windows path handling.</li> <li> <p>WSL can be used for Linux-like environment management if needed.</p> </li> <li> <p>Linux:</p> </li> <li>Environment management with pyenv, virtualenv, and Anaconda is straightforward due to Python's tight integration with Linux.</li> <li>Linux provides the most natural environment for Python development, especially for DevOps, web development, and system-level programming.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#3-development-tools-and-ides","title":"3. Development Tools and IDEs","text":"<ul> <li>Mac:</li> <li>Popular IDEs like PyCharm, Visual Studio Code, and Sublime Text work well.</li> <li>Mac also supports terminal-based development with tools like vim or Emacs.</li> <li> <p>Native support for tools like Docker and Kubernetes simplifies cloud and containerized development.</p> </li> <li> <p>Windows:</p> </li> <li>PyCharm and Visual Studio Code work well on Windows.</li> <li>Command-line tools are less consistent across environments, but PowerShell and WSL help.</li> <li> <p>GUI-based Python tools and IDEs are more commonly used on Windows due to its focus on GUI applications.</p> </li> <li> <p>Linux:</p> </li> <li>PyCharm, VS Code, and terminal-based editors like vim or Emacs are highly popular.</li> <li>Full compatibility with command-line development and system-level tools.</li> <li>Linux is ideal for server-side and cloud development, with Docker and containerization tools natively integrated.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#4-package-and-dependency-management","title":"4. Package and Dependency Management","text":"<ul> <li>Mac:</li> <li>pip and pipenv work smoothly.</li> <li>Some libraries with system-level dependencies may require additional installations via Homebrew (e.g., C libraries).</li> <li> <p>Fewer compatibility issues than Windows, but some packages may still need custom configurations.</p> </li> <li> <p>Windows:</p> </li> <li>pip works well for pure Python packages, but some libraries with C extensions (like NumPy or SciPy) may require pre-built binaries or additional configuration.</li> <li> <p>Package managers like Chocolatey or Conda can help with more complex dependencies.</p> </li> <li> <p>Linux:</p> </li> <li>Linux is ideal for managing Python packages with system-level dependencies due to easy integration with C/C++ compilers and package managers (like apt).</li> <li>pip, pipenv, and conda work seamlessly with native system dependencies.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#5-compatibility-with-python-libraries","title":"5. Compatibility with Python Libraries","text":"<ul> <li>Mac:</li> <li>Mac has good compatibility with most Python libraries, particularly those related to web development and data science.</li> <li> <p>Occasionally, there are issues with libraries that have system-level dependencies (e.g., requiring Xcode command-line tools).</p> </li> <li> <p>Windows:</p> </li> <li>Some Python libraries, especially those with C extensions or system-level dependencies, can be challenging to install or configure.</li> <li>Tools like Microsoft Visual C++ Build Tools are often required to compile C extensions.</li> <li> <p>WSL helps with Linux-native libraries, but native Windows compatibility can still be hit or miss.</p> </li> <li> <p>Linux:</p> </li> <li>Most libraries, especially system-level or server-oriented libraries, work out of the box on Linux.</li> <li>Linux is the default development environment for many Python projects, particularly in the open-source world, so compatibility is rarely an issue.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#6-performance-and-stability","title":"6. Performance and Stability","text":"<ul> <li>Mac:</li> <li>Generally offers good performance and stability for Python development.</li> <li> <p>macOS is Unix-based, so it provides a stable environment for Python development, especially for server and web-related tasks.</p> </li> <li> <p>Windows:</p> </li> <li>Python performance on Windows is solid for most tasks, but you may encounter occasional compatibility issues, especially with libraries that rely heavily on Unix-like behavior.</li> <li> <p>WSL can help with Linux-based workflows, but native Windows performance for Python remains slightly behind Linux.</p> </li> <li> <p>Linux:</p> </li> <li>Python development on Linux is highly stable and often provides the best performance, especially for system-level tasks and web development.</li> <li>Linux is the closest environment to production for many Python applications, particularly those deployed on cloud infrastructure.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#7-best-use-cases","title":"7. Best Use Cases","text":"<ul> <li> <p>Mac: Great for developers who need a Unix-like environment but also want access to mainstream software and development tools. Ideal for web development, data science, and mobile development.</p> </li> <li> <p>Windows: Best for developers who work primarily with desktop applications or GUI-based tools. WSL helps for more Linux-like development workflows.</p> </li> <li> <p>Linux: The go-to platform for server-side, DevOps, cloud, and system programming. Ideal for open-source projects and environments that closely match production.</p> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Comparing-Python-Development-Platforms/#summary-table","title":"Summary Table","text":"Feature Mac Windows Linux Installation Pre-installed (Python 2.x), Homebrew Requires manual install Pre-installed, easy package manager Environment Management Homebrew, pyenv pyenv-win, Anaconda, WSL pyenv, virtualenv, Anaconda Development Tools PyCharm, VS Code, Sublime, CLI tools PyCharm, VS Code, WSL, PowerShell PyCharm, VS Code, vim, Emacs Package Management Smooth with pip and Homebrew Challenges with C extensions Seamless with pip and apt/yum Library Compatibility Good, with minor system dependency issues Some challenges with certain packages Excellent, minimal compatibility issues Performance High performance, stable Good, but sometimes needs extra configuration High performance, best for system-level tasks Best For Web, data science, mobile GUI apps, general Python development Server, system programming, open-source development <p>Each platform has strengths depending on your project\u2019s requirements. Linux is ideal for server-side and system programming, macOS offers a balance with Unix-like tools and GUI development, and Windows is improving rapidly, especially with WSL.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/","title":"FAQ: Git Flow Support for Multiple mainlines","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#git-flow-supporting-for-multiple-mainlines","title":"Git Flow Supporting for Multiple mainlines","text":"<p>Git Flow enhances the Git workflow by standardizing branching conventions and providing helpful commands for managing features, releases, and hotfixes. This manual guides you through understanding and automating Git Flow configuration, where you can use this to re-configure your development mainline and have multiple configurations.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#understanding-git-flow-variables","title":"Understanding Git Flow Variables","text":"<p>Git Flow operates by storing configuration variables within each repository's Git configuration. When you initialize Git Flow using <code>git flow init -d</code> (with defaults), it sets up these variables in the <code>.git/config</code> file.</p> <p>Viewing Configuration:</p> <p>You can inspect the current configuration in two ways:</p> <ol> <li> <p>Using Git: <pre><code>git config --list | grep gitflow \n</code></pre>    This will output lines like:    <pre><code>gitflow.branch.master=main\ngitflow.branch.develop=develop\ngitflow.prefix.feature=feature/\n...\n</code></pre></p> </li> <li> <p>Using Git Flow: <pre><code>git flow config\n</code></pre>    This provides a more user-friendly display:    <pre><code>Branch name for production releases: main\nBranch name for \"next release\" development: develop\nFeature branch prefix: feature/\n...\n</code></pre></p> </li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#automating-configuration-with-shared-file","title":"Automating Configuration with Shared File","text":"<p>1. Create the Shared Configuration File (<code>&lt;project_root&gt;/.gitflowconfig</code>):</p> <p>This file defines your Git Flow settings. Here's an example supporting dual <code>main</code>/<code>develop</code> branches:</p> <p><code>&lt;project_root&gt;/.gitflowconfig</code></p> <pre><code>master=main  \ndevelop=develop \nfeature=feature/\nbugfix=bugfix/  \nrelease=release/\nhotfix=hotfix/\nsupport=support/ \nversiontag=\n</code></pre> <p><code>&lt;project_root&gt;/.gitflowconfig2</code></p> <pre><code>master=main2\ndevelop=develop2\nfeature=feature/\nbugfix=bugfix/  \nrelease=release/\nhotfix=hotfix/\nsupport=support/ \nversiontag=\n</code></pre> <p>2. Write the Automation Script (<code>init_gitflow.sh</code>):</p> <pre><code>#!/bin/bash\n\n# Optionally specify a custom Git Flow configuration file path\ncustom_config_file=\"\"\nif [[ $# -gt 0 ]]; then\n  custom_config_file=$1\nfi\n\n# Check if Git Flow is already initialized \nif [[ $(git config --get gitflow.branch.master) ]]; then\n  echo \"Git Flow is already initialized.\"\n  exit 0  # Exit successfully if already initialized\nfi\n\n# Load configuration from .gitflowconfig or the specified file\nif [[ -n \"$custom_config_file\" ]]; then\n  if [[ -f \"$custom_config_file\" ]]; then\n    source \"$custom_config_file\"\n    echo \"Using custom Git Flow configuration from $custom_config_file\"\n  else\n    echo \"Error: Custom configuration file not found: $custom_config_file\"\n    exit 1\n  fi\nelse\n  if [[ -f .gitflowconfig ]]; then\n    source .gitflowconfig\n    echo \"Using default Git Flow configuration from .gitflowconfig\"\n  else\n    echo \"Error: Neither default nor custom Git Flow configuration file found.\"\n    exit 1\n  fi\nfi\n\n# Initialize Git Flow using defaults (-d)\ngit flow init -d\n\n# Set the configuration parameters from .gitflowconfig or the specified file\ngit config gitflow.branch.master $master\ngit config gitflow.branch.develop $develop\ngit config gitflow.prefix.feature $feature\ngit config gitflow.prefix.bugfix $bugfix         # Set bugfix prefix\ngit config gitflow.prefix.release $release       # Set release prefix\ngit config gitflow.prefix.hotfix $hotfix         # Set hotfix prefix\ngit config gitflow.prefix.support $support       # Set support prefix\ngit config gitflow.prefix.versiontag $versiontag # Set versiontag prefix\n\necho \"Git Flow initialized successfully!\"\n</code></pre> <p>3. Make the Script Executable:</p> <pre><code>chmod +x init_gitflow.sh\n</code></pre> <p>4. Run the Script: (using default configuration)</p> <pre><code>./init_gitflow.sh\n</code></pre> <p>or specify a global / alternative configuration</p> <pre><code>./init_gitflow.sh ~/.gitflowconfig2\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#leveraging-git-flow-in-your-workflow","title":"Leveraging Git Flow in Your Workflow","text":"<p>The variables <code>develop</code> and <code>main</code> are setup based on configuration, allowing multiple mainlines to be supported.</p> <p>Using Feature Branches</p> <pre><code># Start a new feature branch from variable 'develop'\ngit checkout $(git config --get gitflow.branch.develop)\ngit flow feature start &lt;feature_name&gt; \n# ... (develop your feature)\n# Finish the feature branch, merging it into 'develop'\ngit flow feature finish &lt;feature_name&gt; \n</code></pre> <p>Release Branches:</p> <pre><code># Start a new release branch from variable 'develop'\ngit checkout $(git config --get gitflow.branch.develop)\ngit flow release start &lt;version_number&gt;\n# ... (perform final testing)\nautochange-log -v &lt;version_number&gt; # generates release notes\n# Finish the release branch, merging into both variable 'develop' AND variable 'main', and pushing changes\ngit flow release finish &lt;version_number&gt; \ngit push \ngit push --tags\ngit checkout $(git config --get gitflow.branch.main) # push to variable `main`\ngit push\ngit checkout $(git config --get gitflow.branch.develop) # push to variable `develop`\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git-Flow-Support-for-Multiple-mainlines/#scaling-git-flow-initialization-with-og-optional","title":"Scaling Git Flow Initialization with <code>og</code> (Optional)","text":"<p>If you have the <code>sc</code> (Source Control) scripts installed, you can leverage the <code>og</code> (Operate on Git) command to effortlessly initialize Git Flow across multiple repositories within your project's directory structure. </p> <p>Here's how it works:</p> <ol> <li>Prerequisites:</li> <li><code>sc</code> Scripts: Ensure you have the <code>sc</code> scripts installed. You can find them on GitHub or package managers for your system.</li> <li> <p><code>init_gitflow.sh</code> and <code>.gitflowconfig</code>: Make sure these files are located in your home directory (<code>~</code>).</p> </li> <li> <p>Run the <code>og</code> Command:</p> </li> </ol> <pre><code>og cmd \"~/init_gitflow.sh ~/.gitflowconfig\"\n</code></pre> <p>This command does the following:</p> <ul> <li>Starting Point: Begins at your current directory.</li> <li>Recursive Search: Looks for all Git repositories within the current directory and its subdirectories.</li> <li>Execution: In each found repository, it runs the <code>~/init_gitflow.sh</code> script.  The script will use the shared configuration file <code>~/.gitflowconfig</code> to set up Git Flow consistently.</li> </ul> <p>Example Usage:</p> <p>Let's say your project has the following structure:</p> <pre><code>my_project/\n\u251c\u2500\u2500 frontend/\n\u2502   \u2514\u2500\u2500 .git\n\u251c\u2500\u2500 backend/\n\u2502   \u2514\u2500\u2500 .git\n\u2514\u2500\u2500 docs/\n</code></pre> <p>By running <code>og cmd \"~/init_gitflow.sh ~/.gitflowconfig\"</code> from within <code>my_project/</code>, you'll initialize Git Flow in both the <code>frontend</code> and <code>backend</code> repositories, applying the settings from your shared configuration file.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/","title":"FAQ: Git\u2010Flow: Developers Branching Model","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>To start, clone the repository to your local machine:</p> <pre><code>git clone https://github.com/rdkcentral/ut-core.git\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#2-set-up-git-flow","title":"2. Set Up Git Flow","text":"<p>We use the Git Flow branching model for managing branches. If you're new to Git Flow, please review this guide:</p> <p>Example of initialising git flow:</p> <pre><code>git flow init -d\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#3-create-a-feature-branch","title":"3. Create a Feature Branch","text":"<p>Create a new feature branch from the 'develop' branch for both new features and bug fixes, adhering to the naming convention: </p> <pre><code>feature/gh&lt;issue-number&gt;_&lt;brief-description&gt;\n</code></pre> <p>or</p> <pre><code>feature/&lt;issue-number&gt;_&lt;brief-description&gt;\n</code></pre> <p>The  should briefly summarize the branch's purpose. <p>Example of creating a feature branch:</p> <pre><code>git flow feature start 123_add-logging-enhancements\n</code></pre> <p>GUI from github.com/rdkcentral: It's possible to create the branch from the GUI also.</p> <p>Compliance Notice: All contributors must strictly follow our Git branching guidelines. Every branch must be accurately named using the corresponding issue ID from our issue tracker, ensuring traceability and upholding automated workflow integrity. Incorrectly named or untraceable branches will fall under a retention policy, allowing for correction within 30 days before removal. This policy is crucial for maintaining the clarity and reliability of our project management processes.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#4-implement-changes","title":"4. Implement Changes","text":"<p>Make changes according to the project\u2019s coding guidelines.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Ensure your commits are clear and adhere to the 50/72 rule: - Summary: Start with an imperative verb (Fix, Update, Add, Improve, Merge, Refactor etc) include the GitHub issue ID, and succinctly describe the change. - Body: Optionally, provide a detailed explanation, keeping lines to 72 characters.</p> <p>Example of a Commit Message:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre> <p>For more detailed information on the 50/72 Rule: follow this link </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#6-push-changes","title":"6. Push Changes","text":"<p>Push your changes to the repository:</p> <pre><code>git push origin feature/123_add-logging-enhancements\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Create a pull request from your branch to the <code>develop</code> branch. It will be automatically assigned for review based on the <code>CODEOWNERS</code> file.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#8-testing-and-validation","title":"8. Testing and Validation","text":"<p>As part of the input and review requirements for the pull request, the engineer is responsible for:</p> <p>a. Execute Testing Suites: Run all applicable test suites provided by the interface. If necessary, upgrade test suites and documentation to support new use cases (following the standard process for upgrades).</p> <p>Note: Interface upgrades are outside the scope of this task and require a separate architecture change request. Any module changes are dependent on the successful release of updated test suites.</p> <p>b. Document &amp; Attach Results: Include comprehensive test results in the pull request, detailing any errors, warnings, or unexpected behaviour encountered during testing.</p> <p>c. Submit for Review (Upon Success): Once all tests pass, submit the code for review via a pull request.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#9-codeowner-review-and-approval","title":"9. CODEOWNER Review and Approval","text":"<p>The pull request must be reviewed and explicitly approved by the designated <code>CODEOWNERS</code>. This review should include:</p> <ul> <li>Verification of test results.</li> <li>Assessment of code quality and adherence to standards.</li> <li>Discussion and resolution of any concerns or questions.</li> </ul> <p>Only after <code>CODEOWNERS</code> approval can the pull request proceed to the merge stage.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#10-merge-the-pull-request","title":"10. Merge the Pull Request","text":"<p>Once the code has been tested and approved by reviewers, the engineer is free to merge the branch using Git Flow:</p> <pre><code>git flow feature finish gh123_add-logging-enhancements\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#11-code-ownership-and-releases","title":"11. Code Ownership and Releases","text":"<p><code>CODEOWNERS</code> are responsible for reviewing and approving changes. They also manage the release and tagging of components according to the project\u2019s schedule.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Git%E2%80%90Flow%3A-Developers-Branching-Model/#requirements-for-contributions","title":"Requirements for Contributions","text":"<p>Please ensure your contributions meet the following:</p> <ul> <li>Adherence to Git Flow</li> <li>Clear and Concise Commit Messages</li> <li>Peer Review Approval</li> <li>Open Discussions and Contributions</li> <li>Thorough Testing and Validation (including test results)</li> </ul> <p>By following these guidelines, you help maintain the quality and integrity of the project while fostering an inclusive and collaborative community environment. We look forward to your contributions, and thank you for being part of our community-driven project.</p> <p>Refer also to FAQ: Release Engineers: Performing a release with git-flow</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Migrating-Binaries-to-%60Git-LFS%60/","title":"FAQ: Migrating Binaries to `Git LFS`","text":"<p>Here's an overview of migrating binaries to Git LFS (Large File Storage) from the current tip of your branch, along with considerations and best practices:</p> <p>Understanding Git LFS</p> <p>Git LFS is a Git extension designed to handle large files more efficiently. Instead of storing the entire file contents directly in your Git repository (which can bloat it over time), LFS replaces large files with small text pointers. The actual file content is stored in a separate LFS store, typically on a remote server.</p> <p>Why Migrate to LFS?</p> <ul> <li>Smaller Repository Size:  LFS drastically reduces the size of your repository, making cloning, fetching, and pushing much faster.</li> <li>Improved Performance: Since Git only needs to manage lightweight pointers, common operations are more efficient.</li> <li>Storage Optimization: LFS servers often have storage optimizations specifically for large files.</li> </ul> <p>Migration Steps</p> <ol> <li> <p>Install Git LFS:  Ensure Git LFS is installed and set up on your system.</p> </li> <li> <p>Track File Types: Tell Git LFS which file types to track. Create or update your <code>.gitattributes</code> file in the root of your repository:</p> </li> </ol> <p><pre><code>*.jpg filter=lfs diff=lfs merge=lfs -text\n*.png filter=lfs diff=lfs merge=lfs -text\n*.zip filter=lfs diff=lfs merge=lfs -text\n</code></pre>    (Replace the examples with your specific binary file types)</p> <ol> <li>Migrate Existing Files: </li> </ol> <pre><code>git lfs migrate import --include=\"*.jpg\" --include=\"*.png\" --include=\"*.zip\"\n</code></pre> <p>(Replace the examples with the file types you want to migrate)</p> <ol> <li>Commit Changes: </li> </ol> <pre><code>git add .gitattributes\ngit commit -m \"Migrate binaries to LFS\"\n</code></pre> <ol> <li>Push to Remote: Push your changes, including the updated <code>.gitattributes</code> file, to your remote repository.</li> </ol> <p>Important Considerations</p> <ul> <li> <p>Existing Clones: Collaborators who have already cloned the repository will need to fetch the LFS pointers and the actual files from the LFS store after you've migrated. They might need to run <code>git lfs fetch</code> and <code>git lfs checkout</code>.</p> </li> <li> <p>Large Repositories: If you have a very large repository, the migration might take some time.  You can use the <code>--verbose</code> flag to see progress:</p> </li> </ul> <pre><code> git lfs migrate import --verbose --include=\"*.jpg\"\n</code></pre> <ul> <li> <p>File Locking: Consider using Git LFS file locking (<code>git lfs locks</code>) if you have large binary files that are often edited concurrently by multiple people. This can prevent merge conflicts.</p> </li> <li> <p>Bandwidth Considerations: Be mindful of the potential network traffic involved in transferring large files to the LFS store.</p> </li> </ul> <p>Example: Migrating a Single File</p> <p>If you only want to migrate a single file from the current tip of your branch, you can use:</p> <pre><code>git lfs track \"your_file.bin\" \ngit add your_file.bin\ngit commit -m \"Add your_file.bin to LFS\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/","title":"FAQ: RDK Docker Toolchain","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#launching-the-toolchain-docker-container","title":"Launching the Toolchain Docker Container","text":"<p>This manual guides you through the process of using the RDK Docker Toolchain to build projects targeted for ARM architecture, using Docker.</p> <p>Note: At the time of writing this has yet to be published opensource, but will be soon</p> <p>To start the Docker container and open a bash shell within it, use the following command:</p> <pre><code>sc docker run &lt;docker&gt; /bin/bash\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#expected-dockers","title":"Expected Dockers","text":"<ul> <li>rdk-dunfell</li> <li>rdk-kirkstone</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>Once inside the Docker container, follow these steps to set up the environment:</p> <ol> <li>Navigate to the toolchain directory:</li> </ol> <pre><code>cd /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/\n</code></pre> <ol> <li>Source &amp; Activate the environment setup for ARMv7:</li> </ol> <pre><code>. environment-setup-armv7at2hf-neon-oe-linux-gnueabi\n</code></pre> <ol> <li>To verify that the compiler (CC) is set correctly in the environment, execute:</li> </ol> <pre><code>echo $CC\n</code></pre> <p>The output should start with <code>arm-oe-linux-gnueabi-gcc</code> followed by various compiler switches.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#building-the-project","title":"Building the Project","text":"<p>To build your project using the ARM toolchain, follow these steps:</p> <ul> <li>Change to your project directory (replace  with your actual project directory name): <pre><code>cd &lt;project&gt;\n</code></pre> <ul> <li>Start the build process by specifying the target:</li> </ul> <pre><code>make TARGET=arm\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-RDK-Docker-Toolchain/#optional-single-command-execution","title":"Optional Single Command Execution","text":"<p>Alternatively, you can combine all the steps into a single command to set up the environment and build your project directly. Here\u2019s how:</p> <p>e.g.</p> <pre><code>sc docker run rdk-dunfell \"/bin/bash -c '. /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/environment-setup-armv7at2hf-neon-oe-linux-gnueabi; cd &lt;project&gt;; make TARGET=arm'\"\n</code></pre> <p>Make sure to replace  with your actual project directory. This command facilitates running everything in one go inside the Docker container."},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/","title":"FAQ: Release Engineers: Performing a release with git flow","text":"<p>Git Flow provides a structured branching model for managing software releases. Here's how you can use it to create a fixed tag release:</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#start-a-release-branch","title":"Start a Release Branch","text":"<ul> <li>Use <code>git flow release start &lt;release-name&gt;</code> (e.g., <code>git flow release start 1.2.0</code>)</li> <li>This creates a new branch (e.g., <code>release/1.2.0</code>) from the <code>develop</code> branch.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#work-on-the-release","title":"Work on the Release","text":"<ul> <li>This branch is dedicated to finalizing the release, fixing bugs, and preparing release notes.</li> <li>Do not add new features here; those should be targeted to <code>develop</code> for the next release.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#finish-the-release","title":"Finish the Release","text":"<ul> <li>When the release is ready, use <code>git flow release finish &lt;release-name&gt;</code>, (note:<code>&lt;release-name</code> is optional)</li> <li>This performs several actions:<ul> <li>Merges <code>release/1.2.0</code> into <code>main</code></li> <li>Tags the <code>main</code> commit with the release name (e.g., <code>1.2.0</code>)</li> <li>Merges <code>release/1.2.0</code> back into <code>develop</code> to keep it up-to-date</li> <li>Deletes the <code>release/1.2.0</code> branch</li> </ul> </li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#push-changes","title":"Push Changes","text":"<ul> <li>Assuming your default remote is <code>origin</code>, and you're on <code>main</code> branch</li> <li>Use <code>git push --tags</code> to push the tag and <code>main</code> branch to your remote repository.</li> <li>Use <code>git checkout develop</code> to check out the develop branch</li> <li>Use <code>git push</code> to push the develop branch</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#example","title":"Example","text":"<pre><code># Start the release\ngit flow release start 1.2.0 \n\n# Work on the release (fix bugs, update docs, etc.)\n# ...\n\n## Generate a change log see (https://github.com/cookpete/auto-changelog)\nautochange-log -v 1.2.0\ngit add CHANGELOG.md\ngit commit -m \"Bumped CHANGELOG.md for release\"\n\n# Finish the release\ngit flow release finish 1.2.0\n\n# Code should be merged to both develop &amp; main\n# If successful &amp; not merge errors the branch will be `develop`\n# If merge errors, follow instructions and re-run etc.\n\n# Merge has occurred to develop\ngit push  # pushes develop\ngit push --tags # pushes the tags\ngit checkout main # swaps branch to main\ngit push # pushes main\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#benefits-of-using-git-flow-release","title":"Benefits of Using Git Flow Release","text":"<ul> <li>Clear Structure: Provides a well-defined workflow for managing releases.</li> <li>Dedicated Branch:  The <code>release</code> branch isolates release-related work from ongoing development.</li> <li>Version Tracking:  Tags make it easy to identify and roll back to specific releases.</li> <li>Automation: Git Flow commands automate the merging and tagging process.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Release-Engineers%3A-Performing-a-release-with-git-flow/#additional-tips","title":"Additional Tips","text":"<ul> <li>Hotfixes: Use <code>git flow hotfix</code> to quickly address critical issues in production releases.</li> <li>Support Branches: Use <code>git flow support</code> to maintain older releases.</li> </ul> <p>By following this approach, you can streamline your release process, ensure consistent versioning, and maintain a clean Git history.</p> <p>Refer also to FAQ: Git-Flow: Developers Branching Model</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Sign-up-for-RDK-Central-%E2%80%90-Tier-1-Registration/","title":"FAQ: Sign up for RDK Central \u2010 Tier 1 Registration","text":"<p>In order to be able to access private repositories, you need to be added to teams in GitHub. For this, we will need to know your GitHub Public-ids and store them in LDAP on RDKCentral.</p> <p>So, please follow the following steps to maintain your access to migrated repos:</p> <ol> <li>If you already have a rdkcentral account, skip to step 4.</li> <li>Create a rdkcentral account. sign up here: https://wiki.rdkcentral.com/signup.action</li> <li>Wait at least 15 minutes for LDAP to be updated</li> <li>If you already have a Public GitHub account, skip to step 6</li> <li>Create a Public GitHub account, Navigate to https://github.com/ and click Sign up (Ensure you have logged out of your GitHub enterprise cloud account when performing these steps). Follow the prompts to create your personal account)</li> <li>Update your rdkcentral user profile to add your GitHub credentials (follow the instructions here: https://wiki.rdkcentral.com/display/CMF/RDK+Central+Github+Profile+Setup+for+Private+Repository+Access )</li> <li>Accept the rdkcentral GitHub team invite, sent to the email associated with your GitHub personal account.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/","title":"FAQ: Software Post Release Development Cycle","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#post-release-development-an-active-phase-of-software-evolution","title":"Post-Release Development: An Active Phase of Software Evolution","text":"<p>Post-Release Development refers to the continuous, active process of improving, adapting, and enhancing software after it has been deployed. It ensures that the software remains functional, secure, and aligned with evolving user needs and technological advancements. Far from being a passive stage, this phase involves ongoing development to maintain the software's value and relevance over time.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#types-of-post-release-development","title":"Types of Post-Release Development","text":"<ol> <li>Corrective Enhancements:</li> <li>Focus: Addressing bugs, defects, or errors discovered after deployment.</li> <li> <p>Example: Fixing an issue that causes unexpected behavior or crashes during specific user actions.</p> </li> <li> <p>Adaptive Changes:</p> </li> <li>Focus: Updating software to ensure compatibility with changing environments or technologies.</li> <li> <p>Example: Adjusting the software to work seamlessly with a new operating system or hardware platform.</p> </li> <li> <p>Perfective Improvements:</p> </li> <li>Focus: Enhancing existing features, performance, or usability based on user feedback and analytics.</li> <li> <p>Example: Adding new functionality or streamlining the user interface to improve the experience.</p> </li> <li> <p>Preventive Adjustments:</p> </li> <li>Focus: Proactively addressing potential future issues or improving code structure to enhance maintainability.</li> <li>Example: Refactoring legacy code to align with modern development practices.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#activities-involved-in-post-release-development","title":"Activities Involved in Post-Release Development","text":"<ul> <li>Bug Fixes: Resolving known issues to ensure stability and reliability.</li> <li>Performance Tuning: Optimizing speed, resource usage, and scalability.</li> <li>Feature Enhancements: Adding or upgrading functionality to meet changing user needs.</li> <li>Security Updates: Addressing vulnerabilities to safeguard data and operations.</li> <li>Compatibility Updates: Ensuring the software works with new devices, platforms, or standards.</li> <li>Code Refinement: Regularly reviewing and improving the codebase for clarity and efficiency.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#importance-of-post-release-development","title":"Importance of Post-Release Development","text":"<ol> <li>Ongoing Value Delivery: Ensures that the software continues to meet user expectations and business requirements.</li> <li>Adaptability to Change: Keeps the software relevant in the face of evolving technology and user demands.</li> <li>Enhanced User Satisfaction: Addresses user-reported issues and requests to improve the experience.</li> <li>Risk Mitigation: Proactively reduces the likelihood of security breaches or system failures.</li> <li>Longevity: Extends the lifecycle of the software by keeping it functional and up to date.</li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#challenges-of-post-release-development","title":"Challenges of Post-Release Development","text":"<ul> <li>Managing Technical Debt: Legacy code and shortcuts taken during initial development can complicate updates.</li> <li>Resource Allocation: Balancing efforts between new feature development and maintaining existing software.</li> <li>Compatibility Issues: Adapting software for new environments without disrupting functionality.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#best-practices-for-effective-post-release-development","title":"Best Practices for Effective Post-Release Development","text":"<ul> <li>Continuous Feedback Loop: Gather and act on user feedback to prioritize improvements.</li> <li>Automated Testing: Ensure new changes do not introduce regressions or bugs.</li> <li>Comprehensive Documentation: Maintain clear and up-to-date documentation to streamline future updates.</li> <li>Version Control: Track all changes to ensure transparency and accountability.</li> <li>Proactive Planning: Identify and address potential issues before they impact users.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Software-Post-Release-Development-Cycle/#conclusion","title":"Conclusion","text":"<p>Post-Release Development is a dynamic and ongoing phase of the software lifecycle, integral to ensuring that the software remains valuable and effective in the long term. By treating this stage as an active development process, teams can continually deliver improvements, address issues, and adapt to an ever-changing technological landscape. This commitment to evolution not only satisfies users but also protects the investment in the software over time. </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/","title":"Level Actors","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#excerpt-from-32-standards-requirements-for-building-testing-suites","title":"Excerpt from 3.2. Standards: Requirements for Building Testing Suites","text":"<ul> <li>L1/L2 testing suites will use the <code>ut-core</code> testing framework.</li> <li>L3/L4 testing suites will incorporate the <code>python-raft</code> infrastructure and the <code>ut-raft</code> framework while continuing to utilize <code>ut-core</code> as required.</li> <li>The testing system must adhere to the guidelines outlined in the Setup/Layout Guide.</li> <li>Developers are expected to familiarize themselves with the <code>ut-raft</code> classes, documented in the ut-raft wiki.</li> <li>Examples of <code>python-raft</code> configuration and setup can be found in the aforementioned resources.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#levels-of-test","title":"Levels of Test","text":"<p>The levels of testing to be implemented are described in detail here: Standards: Levels of Test for Vendor Layer</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#testing-frameworks","title":"Testing Frameworks","text":"<ul> <li>L1/L2: <code>ut-core</code> (ut-core repository)</li> <li>L3: Combination of C++ and C, utilizing both <code>ut-core</code> and <code>python-raft</code> (python-raft repository)</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#actors-involved","title":"Actors Involved","text":"<ul> <li>Automation</li> <li>QA Team</li> <li>Engineering Team</li> <li>DUT (Device Under Test)</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#engineering-testing","title":"Engineering Testing","text":"<ul> <li>Engineers and third-party developers will use Levels 1 to 3 to validate and test changes to individual components or groups of components.</li> <li>Level 4 testing expands to multi-component testing, ensuring end-to-end validation.</li> <li>Pre-commit testing is covered under Levels 1 - 3, requiring manual review of results but not necessarily automation.</li> </ul> Test Suite Actors Level 1 - 3 Component Tests Engineers L4 System Performance Engineers L4 Ad-hoc Analysis Engineers L4 Smoke Testing Layer Release Engineers, QA Team L4 System Interface Testing Engineers L4 Deep Dive Testing Engineers"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#qa-testing","title":"QA Testing","text":"<ul> <li>QA primarily focuses on L4 Smoke Testing to ensure compatibility throughout the layer release cycle.</li> <li>The full stack image includes Vendor, MW, and Application Layers, enabling test binaries to be run using previous versions to identify regressions.</li> </ul>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#system-architecture-overview","title":"System Architecture Overview","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#testing-system-flow","title":"Testing System Flow","text":"<pre><code>graph LR\n    subgraph Actors\n        subgraph \"Python Raft / UT-Raft\"\n            Python_Raft --&gt; device(DUT)\n        end\n        subgraph \"XTS Tools\"\n            xTS --&gt; Python_Raft\n            xTS &lt;--&gt; allocator[xTS Allocator]\n            allocator --&gt; rackConfig\n            rackConfig --&gt; Python_Raft\n        end\n        subgraph \"Automation\"\n            auto1[Github Actions / Review Approval] --&gt; xTS\n        end\n        subgraph \"QA Team\"\n            QASmoke[L4 Smoke Testing] --&gt; xTS\n        end\n        subgraph \"Engineer - Component / Layer / Vendor\"\n            L4Smoke[L4 Testing] --&gt; Python_Raft\n            EngineerComponentTesting[L3 Component Testing] --&gt; Python_Raft\n            EngineerComponentTesting --&gt; device\n            L4Smoke --&gt; localRackConfig\n            EngineerComponentTesting --&gt; localRackConfig\n            localRackConfig --&gt; Python_Raft\n        end\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#host-machine-high-level-tests","title":"Host Machine (High-Level Tests)","text":"<p>L3 Component Stimulus Testing and L4 System Testing are executed from the Host Machine, utilizing the <code>ut-raft</code> framework to extend <code>python-raft</code> capabilities.</p> <pre><code>graph LR\n    subgraph \"Host Machine (High Level Tests)\"\n        deviceConfig --&gt; Python_Test\n        rackConfig --&gt; Python_Test\n        Python_Test[Python Test] --&gt; ut_raft\n        ut_raft --&gt; python_raft\n        python_raft --&gt; console\n        console --&gt; DUT\n        python_raft --&gt; webPageControl --&gt; DUT\n        python_raft --&gt; OutboundClient --&gt; DUT\n    end\n    subgraph \"Rack Slot\"\n        python_raft --&gt; PowerSwitch --&gt; DUT\n        python_raft --&gt; IR --&gt; DUT\n        python_raft --&gt; CECAdaptor --&gt; DUT\n        python_raft --&gt; VideoCapture --&gt; DUT\n        VideoCapture --&gt; HostHDD\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#dut-target-architecture","title":"DUT Target Architecture","text":"<p><code>Python Raft</code> connects to the DUT via a console session, ensuring platform-independent testing with automated configurations.</p> <pre><code>graph LR\n    subgraph \"DUT (Target)\"\n        console &lt;--&gt; test_binary(Test Code)\n        platform_profile --&gt; test_binary\n        test_binary --&gt; state_machine\n        state_machine --&gt; code(Code Under Test)\n        test_binary --&gt; ut_core\n        ut_core --&gt; ut_control\n        webSocket --&gt; ut_control\n        ut_control --&gt; state_machine\n    end</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-UT-Core-Framework-Overview/#summary","title":"Summary","text":"<ul> <li>The testing system is divided into multiple levels, utilizing <code>ut-core</code>, <code>python-raft</code>, and <code>ut-raft</code> for different types of testing.</li> <li>Engineering Teams perform pre-commit testing at Levels 1 - 3, while QA Teams focus on L4 Smoke Testing.</li> <li>Automation integrates with testing through <code>GitHub Actions</code> and other tools.</li> <li>DUT Target Testing ensures platform-independent configuration and verification of vendor-layer compatibility.</li> </ul> <p>This document provides a graphical overview of the testing system, ensuring that all stakeholders have a clear understanding of the testing flow and responsibilities.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/","title":"FAQ: Vagrant: Setting Up and Managing Your Vagrant VM","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#setting-up-and-managing-your-vagrant-vm","title":"Setting Up and Managing Your Vagrant VM","text":"<p>Link to Vagrant </p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#overview","title":"Overview","text":"<p>This guide provides a comprehensive solution for managing a remote Vagrant image with a configuration file held in a Git repository. It includes steps for downloading and provisioning the VM, resetting it to its original state, and automatically detecting changes in provisioning.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#solution","title":"Solution","text":"<ol> <li> <p>Remote Vagrant Image and Configuration:</p> <ul> <li>The Vagrant configuration file (<code>Vagrantfile</code>) and necessary provisioning scripts are stored in a Git repository.</li> <li>When developers clone the repository, they get the <code>Vagrantfile</code> and provisioning scripts.</li> <li>The <code>Vagrantfile</code> includes instructions to download and provision the VM using <code>apt-get</code> and other necessary configurations.</li> </ul> </li> <li> <p>Resetting the VM:</p> <ul> <li>Developers can reset the VM back to its original state by destroying and recreating it using a provided script.</li> </ul> </li> <li> <p>Automatic Provisioning Detection:</p> <ul> <li>When developers pull the latest changes from the Git repository, the setup detects any changes in the provisioning scripts and prompts for a VM rebuild if needed.</li> </ul> </li> </ol>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#git-repository-structure","title":"Git Repository Structure","text":"<pre><code>&lt;repository-root&gt;\n\u251c\u2500\u2500 Vagrantfile\n\u251c\u2500\u2500 provision.sh\n\u251c\u2500\u2500 check_provisioning.sh\n\u251c\u2500\u2500 vm_reset.sh\n\u2514\u2500\u2500 vm_start.sh\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#scripts-and-configuration","title":"Scripts and Configuration","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vagrantfile","title":"Vagrantfile","text":"<pre><code>Vagrant.configure(\"2\") do |config|\n  config.vm.box = \"ubuntu/bionic64\"\n\n  # Run the provisioning check script before starting the VM\n  config.trigger.before :up do\n    run \"bash check_provisioning.sh\"\n  end\n\n  config.vm.provision \"shell\", path: \"provision.sh\"\n\n  config.vm.synced_folder \".\", \"/vagrant\"\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#provisionsh","title":"provision.sh","text":"<pre><code>#!/bin/bash\n\n# Update package lists\nsudo apt-get update\n\n# Install necessary packages\nsudo apt-get install -y git curl vim\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#check_provisioningsh","title":"check_provisioning.sh","text":"<pre><code>#!/bin/bash\n\n# Path to the stored hash file\nHASH_FILE=\".provision_hash\"\n\n# Generate a new hash for the provisioning script\nNEW_HASH=$(sha256sum provision.sh | awk '{ print $1 }')\n\n# Check if the hash file exists\nif [ -f \"$HASH_FILE\" ]; then\n  OLD_HASH=$(cat \"$HASH_FILE\")\n  if [ \"$NEW_HASH\" != \"$OLD_HASH\" ]; then\n    echo \"Provisioning script has changed. Please run './vm_reset.sh' to rebuild the VM.\"\n  fi\nfi\n\n# Store the new hash\necho \"$NEW_HASH\" &gt; \"$HASH_FILE\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vm_resetsh","title":"vm_reset.sh","text":"<pre><code>#!/bin/bash\n\n# Destroy the current VM\nvagrant destroy -f\n\n# Recreate and provision the VM\nvagrant up\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#vm_startsh","title":"vm_start.sh","text":"<pre><code>#!/bin/bash\n\n# Start the VM\nvagrant up\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#instructions-for-manual","title":"Instructions for Manual","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#setting-up-and-managing-your-vagrant-vm_1","title":"Setting Up and Managing Your Vagrant VM","text":""},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>First, clone the repository containing the Vagrant configuration and scripts:</p> <pre><code>git clone &lt;repository-url&gt;\ncd &lt;repository-directory&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#2-start-the-vm","title":"2. Start the VM","text":"<p>To start the VM, simply run the provided <code>vm_start.sh</code> script:</p> <pre><code>./vm_start.sh\n</code></pre> <p>This script will: - Check for changes in the provisioning script using <code>check_provisioning.sh</code>. - Start the VM and apply the provisioning defined in <code>provision.sh</code>.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#3-reset-the-vm","title":"3. Reset the VM","text":"<p>If you need to reset the VM to its original state, run the <code>vm_reset.sh</code> script:</p> <pre><code>./vm_reset.sh\n</code></pre> <p>This script will: - Destroy the current VM. - Recreate and re-provision the VM from scratch.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#4-pull-the-latest-changes","title":"4. Pull the Latest Changes","text":"<p>To update your local repository with the latest changes from the remote repository, run:</p> <pre><code>git pull\n</code></pre>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#5-check-for-provisioning-changes","title":"5. Check for Provisioning Changes","text":"<p>Before the VM starts, the <code>check_provisioning.sh</code> script will automatically run to detect any changes in the provisioning script. If changes are detected, you will see a message prompting you to reset the VM using <code>./reset.sh</code>.</p>"},{"location":"external_content/ut-core-wiki/FAQ%3A-Vagrant%3A-Setting-Up-and-Managing-Your-Vagrant-VM/#scripts-overview","title":"Scripts Overview","text":"<ul> <li>Vagrantfile: Defines the VM configuration and provisioning.</li> <li>provision.sh: Contains commands to install required packages and configurations.</li> <li>check_provisioning.sh: Checks if the provisioning script has changed and prompts for a VM reset if needed.</li> <li>vm_reset.sh: Destroys and recreates the VM.</li> <li>vm_start.sh: Starts the VM.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/","title":"UT-Core Framework","text":"<p>ut-core is a modular unit testing framework designed to streamline and simplify the process of developing and executing tests within the RDK Central ecosystem. It provides a collection of tools, utilities, and conventions to help you build robust and reliable tests for your software components.</p>"},{"location":"external_content/ut-core-wiki/Home/#objectives-for-the-framework","title":"Objectives for the framework","text":"<p>Testing suites serve as engineering tools that scrutinise individual components, groups or layers of components during the development and debugging process. Such tests ascertain quality by running multiple rounds on locally revised code before its final commit. </p>"},{"location":"external_content/ut-core-wiki/Home/#primary-objectives","title":"Primary Objectives:","text":"<ul> <li>Pre-commit: Validation of local changes, build and execute the relevant testing suite for the desired component group or layer </li> <li>Debugging: Tests must enable debugging for better variable examination and solitary step execution.</li> <li>Sharing: Enable sharing and execution of tests by third-party vendors, ensuring completion before their delivery.</li> <li>Independence: Permit deployment and execution on vendor boards and prototype hardware.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#secondary-objectives","title":"Secondary Objectives","text":"<p>To test the exposed low-level interfaces of components or groups of components - Initial Development: Develop &amp; perform testing of the component during its initial development. - Change Management: Allow engineers to validate code changes on the components. - Validation: To test and validate interface upgrades which will cause upgrades to the testing suites, and documentation.  - Isolated: Isolated components must run in clean environments and with minimised influences on the system. - Leverage: Leverage the low-level tests to build more complex requirements. - Repeatable: Provide a repeatable engineering environment for low-level control via a high-level language</p> <p>High-level Host Framework Compatible: ut-raft can be used to provide prerequisites, interpret logs, perform analysis of data, draw graphs, formulate, conclusions, trends and results these will adapt based on findings and engineering analysis and requirements. </p>"},{"location":"external_content/ut-core-wiki/Home/#key-features","title":"Key Features","text":"<ul> <li>Modular Design: ut-core is built with a modular architecture, allowing you to select and use the components that best suit your specific testing needs.</li> <li>Flexible Test Definition: Define test cases and configurations using human-readable formats like YAML or JSON, making it easy to create and manage your tests.</li> <li>Data-Driven Testing: Drive your tests with <code>yaml/json</code> input data to cover a wide range of scenarios and edge cases.</li> <li>Rich Assertion Library:  Validate your test results using a comprehensive set of built-in assertions, or create your own custom assertions.</li> <li>Test Reporting: Generate detailed test reports to easily identify and diagnose issues.</li> <li>Integration with CI/CD: Seamlessly integrate <code>ut-core</code> into your continuous integration and continuous delivery pipelines for automated testing.</li> <li>Extensibility: Extend <code>ut-core's</code> functionality by developing custom modules or plugins.</li> <li>Variants: Supports both C and C++ (as a direct swap for GTEST)</li> <li>Black Box Testing: Primary designed as a black box testing framework Black-Box vs White-Box</li> <li>Automatic Framework Generation: Engineers can Leverage the autogenerate.sh script to streamline framework generation, enabling rapid test setup and reducing manual configuration efforts.</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#documentation","title":"Documentation","text":"<p>Here are some of the key modules within ut-core that you can explore in more detail:</p> <ul> <li>Build System Integration: Useful to understand the overall concepts</li> <li>Core: Concept Overview: Core and Engineering Suites Integration</li> <li>Core: How to Build and Run a HAL Testing Suite </li> <li>Standards: Useful reading on coding standards used</li> <li>Standards &amp; Development Process Flow</li> <li>ut_kvp_profile: A flexible profile extension to check kvp values</li> <li>[ut_kvp_profile: Key\u2010Value Pair Profile for Unit Testing]</li> <li>FAQ: Frequently Asked Questions</li> <li>Question and Answers</li> </ul> <p>The ut-core unit testing framework incorporates features from the <code>ut-control</code> module. You can find detailed information about <code>ut-control</code> on its wiki page: ut-control</p>"},{"location":"external_content/ut-core-wiki/Home/#ut-control","title":"ut-control","text":"<p>Control features have moved to a separate repo ut-control</p> <ul> <li>ut_kvp  - [ut_kvp: A Flexible Key-Value Pair Framework]</li> <li>ut_control_plane - ut_control_plane: Overview (ut_control_plane.h)</li> <li>ut_log.h - ut-log: Overview: UT-Log</li> </ul>"},{"location":"external_content/ut-core-wiki/Home/#getting-started","title":"Getting Started","text":"<ol> <li>Installation: Follow the installation instructions in the ut-core repository to set up the framework in your development environment.</li> <li>Explore the Modules: Familiarize yourself with the different modules available in ut-core, each catering to specific testing needs.</li> <li>Define Your Tests:  Use YAML or JSON to create test case definitions, input data, and expected results.</li> <li>Execute Your Tests: Run your tests using the ut-core test runner.</li> <li>Analyse Results:  Review test reports to identify any failures or issues.</li> </ol>"},{"location":"external_content/ut-core-wiki/Home/#running-tests","title":"Running Tests","text":"<p>To execute your tests using the <code>ut-core</code> framework, the main argument features will be linked into your test. This executable provides various command-line switches to customize how your tests are run:</p>"},{"location":"external_content/ut-core-wiki/Home/#example-of-the-unit-test","title":"Example of the unit test","text":"<p>The unit tests are also a combined binary with ut-core, therefore it also has the switches.</p> <pre><code>./tests/bin/ut-test -h\nHelp\n-a - Automated Mode\n-b - Basic Mode\n-f - &lt;filename&gt; - set the output filename for automated mode\n-t - List all tests run to a file\n-l - Set the log Path\n-p - &lt;profile_filename&gt; - specify the profile to load YAML or JSON, also used by kvp_profile\n-h - Help\n</code></pre>"},{"location":"external_content/ut-core-wiki/Home/#using-the-p-profile_filename-switch","title":"Using the <code>-p profile_filename</code> switch","text":"<ul> <li> <p>hdmiProfile.yml <pre><code>hdmicec:\n  config:\n    extendedEnumsSupported: false\n</code></pre></p> </li> <li> <p>Passing a profile into the testing suite <pre><code>./hdmi_cec -p hdmiProfile.yml\n</code></pre></p> </li> </ul> <p>then in the testing code you would perform</p> <pre><code>bool extendedEnumsSupported = UT_KVP_PROFILE_GET_BOOL( \"hdmicec/config/extendedEnumsSupported\" ); \nif ( extendedEnumsSupported == false )\n{\n   /* Complete suite is disabled due to supportExtendedEnums == false */\n    pSuite = UT_add_suite(\"test extended functions \", NULL, NULL );\n\n    UT_add_test(pSuite, \"test extended bool\", test_bool);\n    UT_add_test(pSuite, \"test extended string\", test_string);\n    UT_add_test(pSuite, \"test extended uint32\", test_uint32);\n}\n</code></pre> <p>Refer to the documentation for more information ut_kvp_profile: Key Value Pair Assertions for Unit Testing</p>"},{"location":"external_content/ut-core-wiki/Home/#contributing","title":"Contributing","text":"<p>We welcome contributions to ut-core! If you have ideas for new features, bug fixes, or improvements to the documentation, please open an issue or submit a pull request on our GitHub repository.</p> <p>Let us know if you have any questions or feedback!</p>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/","title":"CODEOWNERS Training: Ensuring Code Quality and Governance","text":""},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#1-introduction","title":"1. Introduction","text":"<ul> <li>Objective of the Training</li> <li>Equip CODEOWNERS with a clear understanding of their responsibilities in maintaining code quality.</li> <li>Enable CODEOWNERS to effectively enforce coding standards during pull request (PR) reviews.</li> <li> <p>Provide a practical checklist to guide reviews and ensure compliance with standards.</p> </li> <li> <p>Why Standards Matter</p> </li> <li>Consistency across codebases improves maintainability and scalability.</li> <li>Standards promote readability and ease onboarding for new contributors.</li> <li>Clear processes streamline governance and ensure smooth project progress.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#2-standards-overview","title":"2. Standards Overview","text":"<ol> <li>Coding Standards: Principles from Code Complete</li> <li>Prioritize simplicity, clarity, and maintainability in code.</li> <li>Enforce meaningful naming conventions, modular design, and reusable code.</li> <li>Promote thorough testing and debugging.</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Issue Description Guidelines</li> <li>Ensure issues are clearly described with:<ul> <li>Summary of the problem.</li> <li>Steps to reproduce and expected outcomes.</li> <li>Labels, assignees, and related milestones.</li> </ul> </li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Milestone Description Guidelines</li> <li>Define SMART (Specific, Measurable, Achievable, Relevant, Time-bound) milestones.</li> <li>Outline scope and objectives clearly to align with project goals.</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Commit Messages: The 50-72 Rule</li> <li>Use concise, clear subject lines (50 characters).</li> <li>Wrap the body at 72 characters per line.</li> <li>Separate subject and body with a blank line.</li> <li>Use the imperative mood (e.g., \"Fix bug\" instead of \"Fixed bug\").</li> </ol> <p>\ud83d\udd17 Read More</p> <ol> <li>Semantic Versioning and Testing Suite Alignment</li> <li>Follow the <code>MAJOR.MINOR.PATCH</code> format:<ul> <li>MAJOR: Incompatible API changes.</li> <li>MINOR: Backward-compatible feature additions.</li> <li>PATCH: Backward-compatible bug fixes.</li> </ul> </li> <li>Ensure alignment between version updates and test suites.</li> </ol> <p>\ud83d\udd17 [Read More</p>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#3-codeowners-responsibilities","title":"3. CODEOWNERS Responsibilities","text":"<ul> <li>Primary Role</li> <li>Review PRs for compliance with standards and governance processes.</li> <li> <p>Act as gatekeepers for ensuring code quality and project integrity.</p> </li> <li> <p>Key Actions During PR Reviews</p> </li> <li>Validate adherence to coding standards and principles.</li> <li>Confirm issues, milestones, and commit messages meet guidelines.</li> <li>Ensure versioning aligns with the changes made and associated tests are updated.</li> <li>Provide clear and actionable feedback to contributors.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#4-pr-review-checklist","title":"4. PR Review Checklist","text":"<p>Use this checklist to enforce standards and ensure consistency during PR reviews:</p> <ol> <li>Code Quality</li> <li>Is the code simple, clear, and maintainable?</li> <li>Are naming conventions consistent and meaningful?</li> <li> <p>Is the code modular and reusable?</p> </li> <li> <p>Issue Descriptions</p> </li> <li>Are issues well-defined and labelled appropriately?</li> <li> <p>Do they include steps to reproduce and expected vs. actual outcomes?</p> </li> <li> <p>Milestones</p> </li> <li>Are milestones SMART and aligned with project goals?</li> <li> <p>Is the scope clearly outlined?</p> </li> <li> <p>Commit Messages</p> </li> <li>Do commit messages follow the 50-72 rule?</li> <li> <p>Are they written in the imperative mood and appropriately formatted?</p> </li> <li> <p>Semantic Versioning</p> </li> <li>Is the version number updated correctly (MAJOR, MINOR, PATCH)?</li> <li> <p>Are test suites updated to reflect new changes?</p> </li> <li> <p>Documentation</p> </li> <li>Is new functionality or significant change documented?</li> <li> <p>Are README files or wikis updated as necessary?</p> </li> <li> <p>Testing</p> </li> <li>Are new features covered with adequate tests?</li> <li> <p>Do all tests pass, including regression tests?</p> </li> <li> <p>Feedback</p> </li> <li>Is feedback constructive, actionable, and specific?</li> <li>Are necessary changes clearly communicated?</li> </ol>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#5-governance-in-pull-request-reviews","title":"5. Governance in Pull Request Reviews","text":"<ul> <li>Goals</li> <li>Maintain a collaborative and respectful review process.</li> <li>Encourage knowledge sharing and improvement across the team.</li> <li> <p>Build trust by ensuring high-quality and consistent contributions.</p> </li> <li> <p>Best Practices</p> </li> <li>Use comments to guide contributors on improving their code.</li> <li>Align reviews with project goals and technical roadmaps.</li> <li>Ensure that governance decisions are documented for future reference.</li> </ul>"},{"location":"external_content/ut-core-wiki/T1%3A-Training%3A-CODEOWNERS%3A-Ensuring-Code-Quality-and-Governance/#6-closing","title":"6. Closing","text":"<ul> <li>Key Takeaways</li> <li>CODEOWNERS play a critical role in maintaining code quality and enforcing standards.</li> <li>The checklist ensures a structured and thorough review process.</li> <li> <p>Consistent application of standards improves project quality and team collaboration.</p> </li> <li> <p>Resources for Continuous Learning</p> </li> <li>RDK Central Coding Standards</li> <li>Code Complete (Summary)</li> </ul>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/","title":"UT Core Building using Docker or Vagrant","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#problem","title":"Problem","text":"<p>It has been reported that the ut-core building process encounters a zstd dependency issue when configuring cURL. While this issue is commonly observed on Linux PCs, users can easily bypass it by using Docker or Vagrant to build ut-core in a controlled environment.</p> <p>This page provides detailed installation instructions for Docker and Vagrant, along with a basic script to install essential packages required for ut-core.</p>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-procedure-for-docker","title":"Install procedure for docker","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-docker","title":"Install Docker","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install -y ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\`\n`$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\nsudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\ndocker --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#pull-the-ubuntu-2204-docker-image","title":"Pull the Ubuntu 22.04 Docker Image","text":"<pre><code>sudo docker pull ubuntu:22.04\nsudo docker images\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#steps-to-access-files-from-docker-to-your-pc-and-vice-versa","title":"Steps to access Files from Docker to Your PC and vice versa","text":"<pre><code>mkdir -p /host/data\ncp install.sh to /host/data/.\nchmod +x /host/data/install.sh\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#run-docker","title":"Run Docker","text":"<pre><code>sudo docker run -it -v /host/data:/container/data ubuntu:22.04\n</code></pre> <p>once inside docker:</p> <pre><code>cd  /container/data\n</code></pre> <p>run install script:</p> <pre><code>./install.sh\n</code></pre> <p>generate ssh keys and add the public key to rdkcentral</p> <pre><code>git clone &lt;repo url&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#copy-the-binary-and-libraries-generated-to-containerdata-and-the-same-will-be-available","title":"copy the binary and libraries generated to /container/data and the same will be available","text":"<p>to you in /host/data of your PC.</p> <p>Note: Every time you will need to do this install and other procedure on docker unlike  vagrant, as vagrant is virtual box and docker isn't, its just a container to do your work and exit</p>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-procedure-for-vagrant","title":"Install procedure for vagrant","text":""},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-virtualbox-for-vagrant","title":"Install Virtualbox for vagrant","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install virtualbox -y\nVBoxManage --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#install-vagrant","title":"Install vagrant","text":"<pre><code>wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\nsudo apt update &amp;&amp; sudo apt install vagrant\nvagrant --help\nvagrant --version\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#create-vagrant-environment","title":"create vagrant environment","text":"<pre><code>mkdir vagrant-ubuntu2204\ncd vagrant-ubuntu2204\nvagrant init generic/ubuntu2204\nmv Vagrantfile Vagrantfile_orig\n\n\ncat Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"generic/ubuntu2204\"\n  config.vm.network \"private_network\", type: \"dhcp\"\n  config.vm.provider \"virtualbox\" do |vb|\n    vb.memory = \"1024\" # Reduce memory\n    vb.cpus = 1        # Use fewer CPUs\n  end\nend\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#start-using-vagrant","title":"start using vagrant","text":"<pre><code>vagrant up; vagrant ssh\n</code></pre> <p>=&gt; You should see the prompt like this:</p> <pre><code>Last login: Wed Jan 22 14:22:43 2025 from 10.0.2.2\nvagrant@ubuntu2204:~$\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT-Core-Building-using-Docker-or-Vagrant/#script-for-installing-basic-packages-for-ut-core","title":"Script for installing basic packages for ut-core","text":"<pre><code>cat install.sh \n</code></pre> <pre><code>#!/bin/bash\n\n# Update package list\necho \"Updating package list...\"\napt-get update -y\n\n# Install required packages\necho \"Installing required packages...\"\napt-get install -y \\\n    file \\\n    git \\\n    gcc \\\n    g++ \\\n    zip \\\n    bzip2 \\\n    tar \\\n    libssl-dev \\\n    cmake \\\n    make \\\n    wget\n\n# Verify installation of packages\necho \"Verifying installed packages...\"\nfile --version\ngit --version\ngcc --version\ng++ --version\nzip --version\nbzip2 --version\ntar --version\ncmake --version\nmake --version\nwget --version\n\necho \"All packages installed successfully!\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/","title":"Overview","text":"<p>Test suite grouping in UT Core enables efficient and targeted testing. It allows developers to organise tests by level enabling them to run only relevant tests, saving time and resources. This improves organisation, supports phased testing, simplifies regression testing, and facilitates test automation, ultimately leading to higher quality software and faster development.</p> <pre><code>typedef enum\n{\n    UT_TESTS_L1 = 1,     /*!&lt; Level 1 basic tests are expected to be in this group */\n    UT_TESTS_L2,         /*!&lt; Level 2 advanced tests are expected to be in this group */\n    UT_TESTS_L3,         /*!&lt; Level 3 module tests are expected to be in this group */\n    UT_TESTS_L4,         /*!&lt; Level 4 module control functions (e.g., start/stop module), not part of a testing suite */\n    UT_TESTS_HUMAN_L2,   /*!&lt; Level 2 suite requires human interaction */\n    UT_TESTS_HUMAN_L3,   /*!&lt; Level 3 suite requires human interaction */\n    UT_TESTS_HUMAN_L4,   /*!&lt; Level 4 suite requires human interaction */\n    UT_TESTS_VDEVICE,    /*!&lt; Level 3 suite for setup-specific tests, not runnable on a real device */\n    UT_TESTS_UNKNOWN,    /*!&lt; Placeholder for existing suites */\n    UT_TESTS_MAX         /*!&lt; Out-of-range marker (not a valid status) */\n} UT_groupID_t;\n</code></pre> <p>With this feature, users can register a suite under a specific group and enable/disable groups at runtime using command-line switches:</p> <pre><code>-d to disable a group\n-e to enable a group\n\nFor example, to disable a test group:\n\n&lt;binary&gt; -d 1\n</code></pre> <p>Since UT Core supports both C and C++ (CPP) variants, the registration process differs slightly for each. The details for both are provided below.</p>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#c-variant","title":"C Variant","text":"<p>Registering a Test Suite in C</p> <p>The following example demonstrates how to register a test suite with a group in the C variant:</p> <pre><code>#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;ut.h&gt;\n\nvoid test_l1_function1(void)\n{\n    UT_FAIL(\"Need to implement\");\n    /* Positive */\n    /* Negative */\n} \n\nvoid test_l1_function2(void)\n{\n    UT_FAIL(\"Need to implement\");\n    /* Positive */\n    /* Negative */\n} \n\nstatic UT_test_suite_t *pSuite = NULL;\n\n/**\n * @brief Register the main tests for this module\n * \n * @return int - 0 on success, otherwise failure\n */\nint main(int argc, char *argv[])\n{\n    UT_init(argc, argv);\n\n    /* Add a suite to the registry with a group ID */\n    pSuite = UT_add_suite_withGroupID(\"[L1 test_Example]\", NULL, NULL, UT_TESTS_L1);\n\n    if (pSuite == NULL) \n    {\n        return -1;\n    }\n\n    UT_add_test(pSuite, \"blah_level1_test_function\", test_l1_function1);\n    UT_add_test(pSuite, \"blah_level1_test_function\", test_l1_function2);\n\n    UT_run_tests();\n\n    return 0;\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#cpp-variant","title":"CPP Variant","text":"<p>Registering a Test Suite in C++</p> <p>The following example demonstrates how to register a test suite with a group in the C++ variant:</p> <pre><code>#include &lt;ut.h&gt;\n\nclass TestL1Example : public UTCore\n{\npublic:\n    TestL1Example() : UTCore() {}\n\n    ~TestL1Example() override = default;\n\n    void SetUp() override\n    {\n        // Code to set up resources before each test\n    }\n\n    void TearDown() override\n    {\n        // Code to clean up resources after each test\n    }\n};\n\n// Automatically register the test suite before execution\nUT_ADD_TEST_TO_GROUP(TestL1Example, UT_TESTS_L1)\n\nUT_ADD_TEST(TestL1Example, TestL1Equal)\n{\n    UT_ASSERT_EQUAL(1, 1); // Basic test case\n}\n\nUT_ADD_TEST(TestL1Example, TestL1NotEqual)\n{\n    UT_ASSERT_NOT_EQUAL(1, 2);\n}\n</code></pre>"},{"location":"external_content/ut-core-wiki/UTCore%3A-Test-Group-Support/#enablingdisabling-test-groups-at-runtime","title":"Enabling/Disabling Test Groups at Runtime","text":"<p>After compilation, users can enable or disable test groups using command-line arguments.</p> <p>For example, to disable a test group:</p> <pre><code>&lt;binary&gt; -d 1\n\nThis will disable:\n    \u2022   C Variant: [L1 test_Example] suite\n    \u2022   CPP Variant: TestL1Example suite\n</code></pre> <p>All other test suites will continue to run when the executable is launched.</p> <p>Note : by default all tests are enabled </p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/","title":"UT\u2010Core: Concept Overview: UT\u2010Core and Engineering Suites Integration","text":""},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#versioning-and-synchronization","title":"Versioning and Synchronization","text":"<p>UT-Core and UT-Control components are versioned using static releases and tags. This consistent versioning allows releases to be synchronized with UT-Core and UT-Control builds, ensuring compatibility across various environments. Version alignment can be managed either by directly integrating it into the component build system or through recipe files that maintain compatibility during builds</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#purpose-of-ut-core-dynamic-cloning-and-building","title":"Purpose of UT-Core Dynamic Cloning and Building","text":"<p>UT-Core dynamically clones and builds its dependencies based on the latest specifications. This process supports ongoing improvements, such as feature additions, while providing flexibility to meet the specific needs of each release. This approach allows UT-Core to remain responsive to evolving requirements without manual updates or dependency conflicts.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#engineering-suites-and-build-systems","title":"Engineering Suites and Build Systems","text":"<p>The engineering suites are designed to operate independently of framework build systems (e.g. Yocto, Buildroot). By keeping engineering suites separate, pre-commit testing can occur independently, enabling engineers to verify code locally in a controlled environment before it reaches a repository. This approach also allows vendors to test their components on development boards of their choosing, without dependence on specific hardware or build framework.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#testing-workflow-and-pre-commit-verification","title":"Testing Workflow and Pre-commit Verification","text":"<p>The intended testing workflow is pre-commit, meaning that all code undergoes thorough local testing before it is committed. This workflow ensures:    - Engineers verify and debug their code locally with full control over testing environments.    - Vendors have the flexibility to test their HAL components on any compatible development board, independent of platform requirements.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#multi-platform-compatibility-and-version-management","title":"Multi-platform Compatibility and Version Management","text":"<p>Managing different versions of vendor code across platforms can introduce complexity. To address this, each component, including testing suites, is designed with an independent release cadence, allowing updates without dependencies affecting other components. This independence allows for flexibility across environments and simplifies multi-platform compatibility.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#future-distribution-as-installable-binaries","title":"Future Distribution as Installable Binaries","text":"<p>Looking forward, the engineering suites are expected to be delivered as binaries, enabling installation via package managers such as <code>opkg</code>. This approach will allow teams to easily install specific versions of testing suites to match the version of each component, reducing manual dependency management and ensuring compatibility. </p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-Concept-Overview%3A-UT%E2%80%90Core-and-Engineering-Suites-Integration/#component-version-control-and-build-automation","title":"Component Version Control and Build Automation","text":"<p>Component versions are managed through automated builds. Engineers can clone the required header files and trigger the build with a simple command:</p> <pre><code> ./build_ut.sh TARGET=arm\n</code></pre> <p>This process automatically pulls the correct versions of dependencies and components, creating a consistent and compatible build environment without requiring manual version tracking.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/","title":"How to Build and Run a HAL Testing Suite","text":"<p>This guide shows you how to build and run a testing suite, using the <code>ut-core</code> framework.</p> <p>Think of <code>ut-core</code> as a set of tools for generating a framework for building your tests. This guide focuses on how to use those tools, but the underlying principles how to structure your tests, is defined by your own requirements.</p> <p>Essentially, we're using <code>ut-core</code> to demonstrate a general approach to testing. You can adapt this approach to your own needs and preferences, even if you're using a different testing framework. In this case we've created template scripts that use <code>ut-core</code> in a HAL interface testing scenario.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#1-navigate-to-the-header-file","title":"1. Navigate to the Header File","text":"<p>First, navigate to the directory containing the header file you want to test.</p> <p>For example:</p> <p>If you want to run the testing suite against the <code>rdk-halif-hdmi_cec</code> repository, you would first clone the repository and then navigate into the newly created directory:</p> <pre><code>git clone git@github.com:rdkcentral/rdk-halif-hdmi_cec.git\ncd rdk-halif-hdmi_cec \n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#2-build-the-testing-suite","title":"2. Build the Testing Suite","text":"<p>From this directory, execute the following command in your terminal:</p> <pre><code>build_ut.sh TARGET=arm\n</code></pre> <p>This script will create a new directory named <code>ut</code> where your testing suite will be created. </p> <p>Note: Running <code>build_ut.sh</code> without specifying a target will build a Linux version of the testing suite, which can be useful for debugging the structure of your tests.</p> <p>All binaries to be transferred to the platform will be created under <code>ut/bin</code></p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#3-build-environment-requirements","title":"3.  Build Environment Requirements","text":"<p>Building the testing suite requires a tool-chain. This can be a vendor-independent tool-chain, an SDK, or any other tool-chain as required.</p> <p>Requirements for building </p> <p>The <code>unitTest(ut)</code> for a module is triggered from scripts, which inturn that clone the <code>ut-core</code> framework (at a fixed version) and builds the defined tests. This allows for independent upgrades to the <code>ut-core</code> framework if desired.</p> <p>Script templates are provided in the <code>template</code> directory to illustrate the necessary files for each layer, starting from the HAL. See template/README.md</p> <p>The testing relationship is as follows:</p> <pre><code>erDiagram\n\u00a0 \u00a0 \u00a0 \u00a0 HAL }|..|{ hal_ut: triggers\n\u00a0 \u00a0 \u00a0 \u00a0 hal_ut }|--o{ ut_core: uses</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#4-core-ut-framework","title":"4. Core UT Framework","text":"<p>The unit testing core subsystem can be cloned from:</p> <pre><code>git clone git@github.com:rdkcentral/ut-core\n</code></pre> <p>Recommended Reading:</p> <ul> <li>https://github.com/rdkcentral/ut-core/blob/master/README.md</li> <li>https://github.com/rdkcentral/ut-core/blob/master/docs/pages/hal_unit_testing_requirements.md</li> </ul> <p>Note: C++ Support is available after Version 4.0.0</p> <p>The <code>ut-core</code> directory structure is as follows:</p> <pre><code>.\n\u251c\u2500\u2500 docs\n\u2502   \u2514\u2500\u2500 pages\n\u2502       \u2514\u2500\u2500 images\n\u251c\u2500\u2500 framework\n\u2502   \u2514\u2500\u2500 cunit\n\u2502       \u251c\u2500\u2500 arm-rdk-linux-gnueabi -&gt; Arm prebuild version of cunit.so\n\u2502       \u2514\u2500\u2500 i686-pc-linux-gnu -&gt; -&gt; Linux prebuild version of cunit.so\n\u2502   \u2514\u2500\u2500 xxx -&gt; Other framework as required\n\u251c\u2500\u2500 include -&gt; ut-core header files\n\u251c\u2500\u2500 src     -&gt; ut-core source files\n\u251c\u2500\u2500 template\n\u2502   \u251c\u2500\u2500 hal_template -&gt; example files for the top level hal directories\n\u2502   \u2514\u2500\u2500 ut_template -&gt; example files for the ut directories\n\u2514\u2500\u2500 tools\n    \u251c\u2500\u2500 libs -&gt; (Vendor .so)\n    \u2514\u2500\u2500 Makefile\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#5-vendor-or-developer-requirements","title":"5.  Vendor or Developer Requirements","text":"<p>Vendors or developers must provide one of the following:</p> <ol> <li>Prebuilt libraries included in the SDK.</li> <li>Prebuilt libraries in the <code>libs</code> directory to link against.</li> <li>Link the <code>libs</code> directory to libraries being worked on in the RDK tree.</li> </ol> <p>The <code>libs</code> directory can be linked to prebuilt libraries generated by the vendor or the RDK build system. Symbolic links can be used to set up these directories.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#7-toolchain","title":"7. Toolchain","text":"<p>The toolchain is provided by the vendor or through an SDK built with the Yocto build system. It's recommended to install the toolchain in the <code>./tools/2.0</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#71-how-to-use-the-sdk-toolchain","title":"7.1. How to Use the SDK Toolchain","text":"<pre><code>./rdk-glibc-x86_64-arm-toolchain-2.0.sh\n</code></pre> <p>This script installs the toolchain and <code>sysroots</code> (typically in <code>/opt/rdk/2.0</code>, but it's recommended to change this to <code>${PWD}../2.0</code>).</p> <p>To use the cross-development toolchain, source the environment setup script:</p> <pre><code>chmod +x /opt/rdk/2.0/environment-setup-cortexa9t2-vfp-rdk-linux-gnueabi\nsource /opt/rdk/2.0/environment-setup-cortexa9t2-vfp-rdk-linux-gnueabi\necho $CC\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#72-docker-based-toolchain","title":"7.2. Docker Based Toolchain","text":"<p>The tool-chain and common environment can be launched by the following <code>sc</code> commands see :- FAQ:-RDK-Docker-Toolchain</p> <pre><code>sc docker rdk-dunfell /bin/bash\n. /opt/toolchains/rdk-glibc-x86_64-arm-toolchain/environment-setup-armv7at2hf-neon-oe-linux-gnueabi\n</code></pre> <pre><code>sc docker list\n</code></pre> <p>will list out the environments available (from outside the docker).</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#8-testing-environment-and-making-the-code","title":"8. Testing Environment and Making the Code","text":"<p>There are two platform targets:</p> <ul> <li><code>linux</code> (default): Builds all tests, the test application, and stubs.</li> <li><code>arm</code> (<code>TARGET=arm</code>): Builds all tests and the test application for the target.</li> </ul>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#9-build-the-linux-environment-with-c-language","title":"9. Build the <code>linux</code> environment with C language","text":"<pre><code>make\n</code></pre> <p>This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/c_source</code>, and links against libraries in <code>ut-core/framework</code>. The <code>skeletons/src</code> directory is included for stub compilation.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#10-build-the-target-arm-environment-with-c-language","title":"10. Build the target <code>arm</code> environment with C language","text":"<p>Ensure the toolchain is sourced.</p> <pre><code>make TARGET=arm\n</code></pre> <p>This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/c_source</code>, links against libraries in <code>ut-core/framework</code>, and links against libraries in the <code>libs</code> directory or the SDK <code>sysroot</code>. The final binary (<code>hal_test</code>) is located in the <code>bin</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#11-build-the-linux-environment-with-cpp-language","title":"11. Build the <code>linux</code> environment with CPP language","text":"<p><pre><code>make VARIANT=CPP\n</code></pre> This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/cpp_source</code>, and links against libraries in <code>ut-core/framework</code>. The <code>skeletons/src</code> directory is included for stub compilation.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#12-build-the-target-arm-environment-with-cpp-language","title":"12. Build the target <code>arm</code> environment with CPP language","text":"<p>Ensure the toolchain is sourced.</p> <p><pre><code>make VARIANT=CPP TARGET=arm\n</code></pre> This builds the <code>src/*.c</code> files, core functions from <code>ut-core/src/cpp_source</code>, links against libraries in <code>ut-core/framework</code>, and links against libraries in the <code>libs</code> directory or the SDK <code>sysroot</code>. The final binary (<code>hal_test</code>) is located in the <code>bin</code> directory.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#13-running-on-the-target","title":"13. Running on the Target","text":"<p>Copy the files from the <code>bin</code> directory to the target.</p> <p>On the target, set the <code>LD_LIBRARY_PATH</code> environment variable:</p> <pre><code>export LD_LIBRARY_PATH=/usr/lib:/lib:/home/root:./\n</code></pre> <p>Alternatively, use the <code>run.sh</code> script in the <code>bin</code> directory.</p> <p>Execute the <code>hal_test</code> application:</p> <pre><code>./hal_test -h \n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#14-modes-of-operation","title":"14. Modes of Operation","text":"<p>The following flags will only work in C Mode</p> <ul> <li>Console Mode (<code>-c</code>): Opens an interactive console.</li> <li>Automated Mode (<code>-a</code>): Outputs results in xUnit format as an XML file.</li> <li>Basic Mode (<code>-b</code>): Runs all tests and redirects output to the shell.</li> </ul>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#15-source-tree-ut-unit-test-directory","title":"15. Source Tree <code>UT</code> Unit Test Directory","text":"<p>The tests follow the structure defined in <code>template/ut_template/</code>:</p> <pre><code>\u251c\u2500\u2500 bin\n\u2502   \u2514\u2500\u2500 run.sh\n\u251c\u2500\u2500 build.sh\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 generate_docs.sh\n\u2502   \u2514\u2500\u2500 pages\n\u2502       \u251c\u2500\u2500 L1_TestSpecification.md\n\u2502       \u251c\u2500\u2500 L2_TestSpecification.md\n\u2502       \u2514\u2500\u2500 README.md -&gt; ../../README.md\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 skeletons\n\u2502   \u2514\u2500\u2500 src\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 main.c\n\u2502   \u251c\u2500\u2500 test_l1_test_example.c\n\u2502   \u2514\u2500\u2500 test_l2_tests_example.c\n\u2514\u2500\u2500 tools\n</code></pre> <p>The <code>main.c</code> file in the <code>src</code> directory is the main launch point for the test application.</p>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#16-choosing-a-major-version-of-the-ut-core","title":"16. Choosing a Major Version of the UT-Core","text":"<p>Since the ut-core interfaces will change over time, and in order to be consistant when creating tests engineers should select the major release they wish to fixed too. (Although it's recommended to periodically upgrade to a later revision )</p> <p>The interface will not change between minor versions, but the most recent bugfix version should be selected.</p> <p>The versioning format for the testing suites is therefore <code>&lt;major.minor.bugfix/patch/documentation&gt;</code></p> <p>In the file <code>ut_template/build.sh</code> you can see the template version of the script.</p> <p>This is selected via <code>UT_CORE_PROJECT_VERSION</code> variable as an input in the default build script for the tests suite e.g. <code>ut/build.sh UT_CORE_PROJECT_VERSION=2.0.0</code> or by changing the fixed version set in your unit testing <code>build.sh</code> trigger script.</p> <p>For best practice and receive bug fixes define <code>UT_PROJECT_MAJOR_VERSION</code> in <code>ut/build.sh</code> to choose the major revision that the testing suite should compile against. <code>ut-core</code> will assure backwards compatibility in major versions. This means that the bugfixes and minor changes you will automatically acquire on the next test run.</p> <pre><code># Change this to upgrade your UT-Core Major versions. Non ABI Changes 1.x.x are supported, between major revisions\nUT_PROJECT_MAJOR_VERSION=\"1.\"\n</code></pre>"},{"location":"external_content/ut-core-wiki/UT%E2%80%90Core%3A-How-to-Build-and-Run-a-HAL-Testing-Suite/#17-example-of-registering-test-functions","title":"17. Example of Registering Test Functions","text":"<p>The main test app will register all the tests and kick off the framework.</p> <pre><code>#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n\n#include &lt;ut.h&gt;\n\nvoid test_l1_function1(void)\n{\n  UT_FAIL(\"Need to implement\");\n  /* Positive */\n  /* Negative */\n} \n\nvoid test_l1_function2(void)\n{\n  UT_FAIL(\"Need to implement\");\n  /* Positive */\n  /* Negative */\n} \n\nstatic UT_test_suite_t *pSuite = NULL;\n\n/**\n * @brief Register the main tests for this module\n * \n * @return int - 0 on success, otherwise failure\n */\nint test_l1_register( void )\n{\n    /* add a suite to the registry */\n    pSuite = UT_add_suite(\"[L1 test_Example]\", NULL, NULL);\n    if (NULL == pSuite) \n    {\n        return -1;\n    }\n\n    UT_add_test( pSuite, \"blah_level1_test_function\", test_l1_function1);\n    UT_add_test( pSuite, \"blah_level1_test_function\", test_l1_function2);\n\n    return 0;\n}\n</code></pre> <p>Each module has a optional <code>init</code> and <code>clean</code> function, which can be setup via UT_add_suite(), in the above example these are defaulted to <code>NULL</code>, since in this example case they are not used.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/","title":"autogenerate.sh: Running the Framework Generation Script","text":""},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#instructions-running-the-framework-generation-script","title":"Instructions: Running the Framework Generation Script","text":""},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#overview","title":"Overview","text":"<p>These instructions guide engineering teams on using the <code>autogenerate.sh</code> script to automatically generate Level 1 (L1) and Level 2 (L2) testing suite frameworks.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#purpose-of-the-autogen-script","title":"Purpose of the Autogen Script","text":"<p>The primary purpose of the <code>autogenerate.sh</code> script is to streamline the initial setup and integration of unit tests for API definitions, allowing engineers to quickly build a complete and fully integrated testing framework with the <code>ut-core</code> testing structure. The script takes input header files and generates all necessary components to create a Linux-compatible, buildable test suite, including:</p> <ul> <li>Directory Structure: Automatically creates subdirectories and organizes files as required by the <code>ut-core</code> framework for a seamless integration.</li> <li>Stub Generation: Generates all necessary stubs for functions referenced in the headers, allowing immediate compilation and functionality within the test suite.</li> <li>Usable Testing Suite: Provides engineers with a ready-to-use test framework that can be customized and expanded to meet specific testing requirements.</li> </ul> <p>This tool accelerates the creation of a complete testing framework from scratch, enabling engineers to go from 0% to a fully functional, buildable test suite. Engineers can then fill out this framework to test individual functions or groups of functions according to their testing needs.</p>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#autogen-command","title":"Autogen Command","text":"<p>To run the autogen script, use:</p> <pre><code>./autogenerate.sh &lt;api-def-repo-url/-c/-clean/-b/-branch/-h/-help&gt;\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#autogen-options-explained","title":"Autogen Options Explained","text":"Argument Optional? Description Examples <code>api-def-repo-url</code> No URL of the API definitions repo to be cloned or the directory path to be copied <code>git@github.com:rdkcentral/hal-deepsleepmanager.git</code> or <code>/home/user/workspace/RdkWanManager</code> <code>-clean</code> or <code>-c</code> Yes Deletes the workspace directory (including cloned repos) <code>-clean</code>, <code>-c</code> <code>-branch</code> or <code>-b</code> Yes Checks out a specific branch in the API definitions repo, applicable only with urls <code>-branch hal-review</code>, <code>-b main</code> <code>-help</code> or <code>-h</code> Yes Shows usage information for the script <code>-help</code>, <code>-h</code> <p>Note: To include debug statements, set the environment variable <code>AGT_DEBUG</code> before running the script:</p> <pre><code>export AGT_DEBUG=1\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#use-cases-supported-by-autogeneratesh","title":"Use Cases Supported by autogenerate.sh","text":"<p>The <code>autogenerate.sh</code> script supports various use cases for generating test frameworks, providing flexibility for repository URLs, user-specified directories, and custom header file locations.</p> <ol> <li> <p>API Definition Repository URL    The API definition URL can be any accessible Git repository URL or directory path. Example commands:    <pre><code>./autogenerate.sh git@github.com:rdkcentral/rdk-halif-device_settings.git\n./autogenerate.sh https://github.com/rdkcentral/RdkWanManager.git\n./autogenerate.sh /home/user/workspace/RdkWanManager\n</code></pre></p> </li> <li> <p>Unit Test Directory    The unit test directory can be either:</p> </li> <li>Cloned from a user-provided URL.</li> <li>Specified as an absolute directory path by the user.  </li> </ol> <p>When prompted, enter the URL or absolute path, or leave blank to skip:    <pre><code># URL input example\nPlease input the URL (or leave blank to skip): https://github.com/comcast-sky/skysr213-platform-hal.git\n\n# Absolute path input example\nPlease input the directory (absolute) path (or leave blank to skip):    /home/user/workspace/RdkWanManager\n</code></pre></p> <ol> <li>Header File Location    The script can generate tests for header files located within the <code>include</code> folder or any other location within the API Definition directory cloned or copied by the script.</li> </ol>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#example-commands","title":"Example Commands","text":"<ol> <li>Generate Test Framework    Generates L1 and L2 test frameworks for the <code>deepsleepmanager</code> repo, including template directories and files in the API definition and <code>ut</code> directories, and skeletons if needed:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-deepsleepmanager.git\n</code></pre> <ol> <li>Generate Test Framework on Specific Branch    Generates the L1 and L2 test frameworks for <code>deepsleepmanager</code> on the <code>hal-review</code> branch of the API definition repo:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-deepsleepmanager.git -b hal-review\n</code></pre> <ol> <li>Delete Workspace Directory    Deletes the workspace directory if it exists:</li> </ol> <pre><code>./autogenerate.sh git@github.com:rdkcentral/hal-powermanager.git -c\n</code></pre> <ol> <li>Display Script Usage    Shows the usage information for the autogen script:</li> </ol> <pre><code>./autogenerate.sh -h\n</code></pre>"},{"location":"external_content/ut-core-wiki/autogenerate.sh%3A-Running-the-Framework-Generation-Script/#terminology-index","title":"Terminology Index","text":"Term Definition Relative Location Created Workspace Directory created to clone repos and build the test framework <code>[ut-core-dir]/workspace</code> API Definitions Main repo where header files (e.g., HAL repo) reside <code>[ut-core-dir]/workspace/[API-definitions-dir]</code> UT Directory under API definition in <code>workspace</code> for Unit Tests (e.g., HALTest repo) <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut</code> Skeletons Generated skeleton code for header files in the API Definition <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/skeletons/src</code> Tests L1 and L2 tests generated for header files in the API Definition <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src</code> L1 Tests Functional tests for each function in header files <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src/test_L1_*</code> L2 Tests Operational tests for module functionality <code>[ut-core-dir]/workspace/[API-definitions-dir]/ut/src/test_L2_*</code>"},{"location":"external_content/ut-core-wiki/ut_kvp%3A-A-Flexible-Key%E2%80%90Value-Pair-Framework/","title":"ut kvp: A Flexible Key\u2010Value Pair Framework","text":"<p>This page has moved to ut_control ut_kvp:-A-Flexible-KeyValue-Pair-Framework</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/","title":"ut kvp profile: Key\u2010Value Pair Assertions for Unit Testing","text":"<p>The <code>ut_kvp_profile.h</code> header is an extension of the <code>ut_kvp</code> framework, specifically designed for streamlined assertions within unit tests. It leverages the key-value pair (KVP) structure to simplify the validation of test results against expected outcomes.</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#key-features","title":"Key Features","text":"<ul> <li>Simplified Assertions: Provides a concise syntax for common assertions (equality checks, string comparisons, etc.) using KVPs.</li> <li>Test Case Configuration: Enables loading of expected test results from YAML/JSON files for easy management and maintenance.</li> <li>Error Reporting: Integrates with the <code>ut_log</code> module to provide clear and informative error messages upon assertion failures.</li> <li>Integration with ut-core: ut_kvp_profile support is provided by default when using ut-core via the <code>-p</code> switch.</li> </ul>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#example-usage","title":"Example Usage","text":"<ol> <li>Create a Configuration File:</li> </ol> <pre><code>test_case_1:\n  expected_result: true\ntest_case_2:\n  expected_result: 12345\n</code></pre> <ol> <li> <p>Start the test and specify the profile file</p> </li> <li> <p>Passing a profile into the testing suite, will automatically open the profile</p> </li> </ol> <pre><code>./hdmi_cec -p hdmi_one_port_no_extendedEnums.yml\n</code></pre> <ol> <li>Use Assertions:</li> </ol> <p>Macro's are now active and available for use in the test suite.</p> <pre><code>bool result = my_function();\nUT_ASSERT_EQUAL_KVP_PROFILE_BOOL(result, \"test_case_1/expected_result\");\n</code></pre>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#detail-on-how-it-works","title":"Detail on how it works.","text":""},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#integration-with-ut_log","title":"Integration with ut_log","text":"<p>The <code>ut_kvp_profile</code> module seamlessly integrates with the <code>ut_log</code> module to provide informative logging upon assertion failures. For example, the following code:</p> <pre><code>UT_ASSERT_EQUAL_KVP_PROFILE_BOOL(false, \"test_case_1/expected_result\");\n</code></pre> <p>would result in a log message similar to:</p> <pre><code>Assertion failed: test_case_1/expected_result (expected: true, actual: false)\n</code></pre>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#assertion-macros","title":"Assertion Macros","text":"<p>The header defines several macros for common assertion types:</p> <ul> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_BOOL(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT8(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT16(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT32(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_UINT64(checkValue, key)</code></li> <li><code>UT_ASSERT_EQUAL_KVP_PROFILE_STRING(checkValue, key)</code></li> </ul> <p>These macros compare a given <code>checkValue</code> against the value associated with the specified <code>key</code> in the KVP data structure. If the values don't match, an assertion failure is triggered.</p>"},{"location":"external_content/ut-core-wiki/ut_kvp_profile%3A-Key%E2%80%90Value-Pair-Assertions-for-Unit-Testing/#get-field-marcos","title":"Get Field Marcos","text":"<p>The header defines several macros for common get types:</p> <ul> <li><code>UT_KVP_PROFILE_GET_BOOL(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT8(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT16(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT32(key)</code></li> <li><code>UT_KVP_PROFILE_GET_UINT64(key)</code></li> <li><code>UT_KVP_PROFILE_GET_LIST_COUNT(key)</code></li> <li><code>UT_KVP_PROFILE_GET_STRING(key, pszReturnedString )</code></li> </ul> <p>For more detailed information of operation see the header file ut_kvp_profile.h</p> <ul> <li><code>!include</code> is supported in the yaml files see ut_kvp: Support for Includes in YAML files, it is extremely important that shared features are segmented into independent files.</li> <li>Upgrades to the system are coming to allow multiple profile support e.g. <code>-p a.yaml -p b.yaml</code> See: #78 </li> <li>For detailed information on the <code>ut_kvp</code> module see ut_kvp: A Flexible Key-Value-Pair Framework</li> </ul>"},{"location":"external_content/ut-core-wiki/vDevice%3A-Overview/","title":"vDevice: Overview","text":"<p>Moved to https://github.com/rdkcentral/ut-core/wiki/5.0:-Standards:-vDevice-Overview</p>"},{"location":"halif/audio_decoder/current/audio_decoder/","title":"Audio Decoder","text":"<p>This document provides an overview of the Audio Decoder Hardware Abstraction Layer (HAL) service, which facilitates the decoding of compressed audio streams within the device. The HAL defines the interfaces through which the RDK (Reference Design Kit) middleware interacts with the vendor-specific audio decoding implementation.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#references","title":"References","text":"<p>Info</p> Interface Definition audio_decoder/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-audio_decoder_manager.service VTS Tests TBC Reference Implementation - vComponent TBC"},{"location":"halif/audio_decoder/current/audio_decoder/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Audio Sink</li> <li>AV Buffer</li> <li>Session State Management</li> </ul>"},{"location":"halif/audio_decoder/current/audio_decoder/#functionality","title":"Functionality","text":"<p>The Audio Decoder HAL service accepts compressed audio data as input. This data can be provided in secure buffers if the underlying vendor implementation supports secure audio processing. This is crucial for premium content protection.</p> <p>The decoded audio output can be delivered via two distinct paths:</p> <ul> <li> <p>Non-Tunnelled Mode: In this mode, the decoded audio, typically in Pulse Code Modulation (PCM) format, is returned to the RDK media pipeline as a frame buffer along with associated metadata (e.g., sample rate, bit depth, number of channels). This allows for further processing within the RDK middleware, such as volume control, audio effects, or synchronization with other media streams.</p> </li> <li> <p>Tunnelled Mode: In this mode, the decoded audio is passed directly to the audio mixer through the vendor layer. This bypasses the RDK media pipeline for audio processing. Tunnelled mode is often preferred for performance reasons, especially in resource-constrained devices, as it reduces latency and CPU overhead. It's often used when the audio stream is simple, and the RDK post-processing isn't required.</p> </li> </ul>"},{"location":"halif/audio_decoder/current/audio_decoder/#operational-modes","title":"Operational Modes","text":"<p>The choice between tunnelled and non-tunnelled mode is made on a per-codec basis during the initialization of the audio decoder. This flexibility allows the system to optimize performance for different audio formats. It's important to note that the audio decoder can switch between these modes for different codec instances, but a single codec instance must operate in one mode or the other for the duration of its use. The operational mode of the audio decoder is independent of the video decoder's mode. This means that it is perfectly valid to have tunnelled video and non-tunnelled audio, or vice-versa.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#pcm-handling","title":"PCM Handling","text":"<p>Uncompressed PCM audio streams do not require decoding. Therefore, they bypass the Audio Decoder HAL entirely. Instead, they are routed directly to the Audio Sink service for mixing and playback. This is an important distinction to make for clarity.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.AUDIODECODER.1 Starting and stopping audio streams shall never produce an audible click or pop artefact due to the audio waveform the audio streaming was started or stopped at. This requirement works in conjunction with the audio mixer. HAL.AUDIODECODER.2 An audio decoder shall indicate its support for secure audio processing through its resource capabilities. HAL.AUDIODECODER.3 An audio decoder advertising the secure audio processing capability that receives a secure buffer of compressed audio shall output decoded audio to secure buffers either returned to the client or tunnelled to the mixer. Secure audio path must be maintained. HAL.AUDIODECODER.4 An audio decoder can tunnel decoded audio to a mixer or the vendor audio sub-system for passthrough and/or return the decoded audio as PCM to the client. HAL.AUDIODECODER.5 When the client enables the audio decoder low latency property and the audio decoder and platform support low latency audio then the audio frame metadata shall indicate low latency. HAL.AUDIODECODER.6 Each audio decoder resource shall be presented by a unique ID. HAL.AUDIODECODER.7 Each audio decoder resource shall provide an API to expose its capabilities for secure audio processing and supported codecs. HAL.AUDIODECODER.8 Only 1 client connection shall be allowed to open and control an audio decoder resource. HAL.AUDIODECODER.9 Multiple client connections shall be allowed to register for events from an audio decoder resource. HAL.AUDIODECODER.10 Audio frame metadata shall be returned to a controlling client on the first audio frame decoded after an open or flush and then against not until the frame metadata changes. Not sent on every decoded audio frame buffer unless changed since previous. HAL.AUDIODECODER.11 The audio frame output buffer from an audio decoder shall match the platform PCM audio format required for mixing. See com.rdk.hal.audiosink.PlatformCapabilities HAL.AUDIODECODER.12 If a client process exits, the Audio Decoder server shall automatically stop and close any Audio Decoder instance controlled by that client."},{"location":"halif/audio_decoder/current/audio_decoder/#interface-definition","title":"Interface Definition","text":"<p>The interface can be found by following this link audiodecoder</p> Interface Description <code>IAudioDecoderManager.aidl</code> Audio Decoder Manager HAL which provides access to <code>IAudioDecoder</code> resource instances. <code>IAudioDecoder.aidl</code> Audio Decoder interface for a single audio decoder resource instance. <code>IAudioDecoderController.aidl</code> Controller interface for an <code>IAudioDecoder</code> resource instance. <code>IAudioDecoderControllerListener.aidl</code> Listener callbacks interface to clients from an <code>IAudioDecoderController</code>. <code>IAudioDecoderEventListener.aidl</code> Listener callbacks interface to clients from an <code>IAudioDecoder</code>. <code>Capabilities.aidl</code> Parcelable describing the capabilities of an <code>IAudioDecoder</code> resource instance. <code>ChannelType.aidl</code> Enum list of audio channel types. <code>Codec.aidl</code> Enum list of audio codecs. <code>CSDAudioFormat.aidl</code> Enum list of audio codec specific data formats. <code>ErrorCode.aidl</code> Enum list of audio decoder error codes. <code>FrameMetadata.aidl</code> Parcelable of audio frame metadata passed from the audio decoder. <code>PCMFormat.aidl</code> Enum list of PCM coding formats. <code>Property.aidl</code> Enum list of audio decoder properties."},{"location":"halif/audio_decoder/current/audio_decoder/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-audio_decoder_manager.service</code> unit file is provided by the vendor layer to start the service and should include Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The Audio Decoder Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the <code>IAudioDecoderManager</code> interface with the Service Manager using the String <code>IAudioDecoderManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#product-customization","title":"Product Customization","text":"<p>The <code>IAudioDecoderManager.getAudioDecoderIds()</code> should return an array of <code>IAudioDecoder.Id</code> parcelables to uniquely represent all of the audio decoder resources supported by the vendor layer. Typically, the ID value starts at 0 for the first audio decoder and increments by 1 for each additional audio decoder.</p> <p>The <code>Capabilities</code> parcelable returned by the <code>IAudioDecoder.getCapabilities()</code> function lists all of the <code>Codec</code> types supported by this audio decoder instance and indicates if the secure audio path can be used.</p> <p>An audio decoder instance may support any number of audio codecs, but can only operate on one compressed audio stream in an open session. Concurrent audio decode requires multiple audio decoder instances to be opened.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#system-context","title":"System Context","text":"<p>The Audio Decoder HAL can provide functionality to multiple clients.</p> <p>Typically an RDK middleware GStreamer audio decoder element will work with a single <code>IAudioDecoder</code> instance and pass it AV Buffer handles for decode.</p> <p>The RDK middleware resource management system will examine the number of audio decoder resources and their capabilities, so they can be allocated to streaming sessions.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IAudioDecoderEventListener(\"IAudioDecoderEventListener\")\n        IAudioDecoderControllerListener(\"IAudioDecoderControllerListener\")\n    end\n    subgraph IAudioDecoderHAL[\"Audio Decoder HAL\"]\n        IAudioDecoderManager(\"IAudioDecoderManager &lt;br&gt;(Service)\")\n        IAudioDecoder(\"IAudioDecoder &lt;br&gt;(Instance)\")\n        IAudioDecoderController(\"IAudioDecoderController &lt;br&gt;(Instance)\")\n    end\n    subgraph OutputComponents[\"Output\"]\n        AudioFramePool(\"Audio Frame Pool\")\n        PlatformDecoder(\"Platform Integrated Decoder/Mixer\")\n        AudioOutput(\"Audio Output Ports in passthrough\")\n    end\n    RDKClientComponent -- createAudioPool() &lt;br&gt; alloc() &lt;br&gt; free() &lt;br&gt; destroyPool() --&gt; IAVBuffer(IAVBuffer)\n    RDKClientComponent -- getIAudioDecoderIds() &lt;br&gt; getIAudioDecoder() --&gt; IAudioDecoderManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() --&gt; IAudioDecoder\n    RDKClientComponent -- registerEventListener() &lt;br&gt; unregisterEventListener() --&gt; IAudioDecoder\n    RDKClientComponent -- start() &lt;br&gt; stop() &lt;br&gt; setProperty() &lt;br&gt; decodeBuffer() &lt;br&gt; flush() &lt;br&gt; signalDiscontinuity() / signalEOS() &lt;br&gt; parseCodecSpecificData() --&gt; IAudioDecoderController\n    IAudioDecoderManager --&gt; IAudioDecoder --&gt; IAudioDecoderController\n    IAudioDecoder -- onStateChanged() &lt;br&gt; onDecodeError() --&gt; IAudioDecoderEventListener\n    IAudioDecoderEventListener --&gt; RDKClientComponent\n    IAudioDecoderControllerListener --&gt; RDKClientComponent\n    IAudioDecoderController -- onFrameOutput() --&gt; IAudioDecoderControllerListener\n    IAudioDecoderController -- alloc() --&gt; AudioFramePool\n    IAudioDecoderManager -- free() --&gt; IAVBuffer\n    IAudioDecoderController -. tunneled audio -.-&gt; PlatformDecoder\n    IAudioDecoderController -. tunneled audio &lt;br&gt;(passthrough) -.-&gt; AudioOutput\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IAudioDecoderManager:::wheat\n    IAudioDecoderController:::wheat\n    IAudioDecoder:::wheat\n    IAVBuffer:::green\n    IAudioDecoderControllerListener:::wheat\n    IAudioDecoderEventListener:::wheat\n    AudioFramePool:::green\n    PlatformDecoder:::green\n    AudioOutput:::green</code></pre>"},{"location":"halif/audio_decoder/current/audio_decoder/#resource-management","title":"Resource Management","text":"<p>The <code>IAudioDecoderManager</code> provides access to one or more <code>IAudioDecoder</code> sub-interfaces which each represent an audio decoder resource instance offered by the platform.</p> <p>Each <code>IAudioDecoder</code> resource instance is assigned a unique integer ID, which is used in <code>IAudioDecoder.Id.value</code> and can be read from <code>RESOURCE_ID</code> using the <code>IAudioDecoder.getProperty()</code> function.</p> <p>To use an <code>IAudioDecoder</code> resource instance it must be opened by a client, which returns an <code>IAudioDecoderController</code> sub-interface to access buffer decoding and additional state controls.</p> <p>Important</p> <p>Any number of clients can access the <code>IAudioDecoderManager</code> service and get access to the <code>IAudioDecoder</code> sub-interfaces, but only 1 client can <code>open()</code> an <code>IAudioDecoder</code> and access its <code>IAudioDecoderController</code> sub-interface.</p> <p>The diagram below shows the relationship between the Audio Decodeer HAL interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"Audio Decoder HAL\" ---\n    IAudioDecoderManager(\"IAudioDecoderManager\")\n\n    %% --- Audio Decoder Manager Service Spawns Instances ---\n    IAudioDecoderManager --&gt; ADI1(\"IAudioDecoder &lt;br&gt; ID = 0\")\n    IAudioDecoderManager --&gt; ADI2(\"IAudioDecoder &lt;br&gt; ID = 1\")\n    IAudioDecoderManager --&gt; ADI3(\"IAudioDecoder &lt;br&gt; ID = 2\")\n\n    %% --- Each Instance Has a Controller ---\n    ADI1 --&gt; ADIC1(\"IAudioDecoderController\")\n    ADI2 --&gt; ADIC2(\"IAudioDecoderController\")\n    ADI3 --&gt; ADIC3(\"IAudioDecoderController\")\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n    %% --- Apply Colors ---\n    class IAudioDecoderManager manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/audio_decoder/current/audio_decoder/#codec-support","title":"Codec Support","text":"<p>Each RDK product defines the audio codecs it requires for IP streaming, apps, broadcast, input ports and output ports.</p> <p>Some codecs are subject to third party licensing agreements and may therefore only be included in some products.</p> <p>The list below indicates the list of audio codecs which are mandatory for the platform to support as either software decode (non-secure) or hardware/vendor decode (potentially secure).</p> <p>Where a codec is optional for hardware/vendor support and is not implemented by the vendor supplied audio decoder then it shall be implemented as an RDK software decoder if required by the product specification.</p> Codec Typical Use Case Hardware/Vendor Support MPEG-1/2 audio layer II Broadcast streams, IP streams, files Mandatory MPEG-1/2 audio layer III MP3 files Optional AAC-LC Broadcast streams, IP streams, files Mandatory HE-AAC Broadcast streams, IP streams, files Mandatory HE-AAC v2 Broadcast streams, IP streams, files Mandatory exHE-AAC Broadcast streams, IP streams, files Optional AAC-ELD Apple AirPlay Optional Apple Lossless Audio Codec (ALAC) Apple AirPlay Optional Dolby AC-3 Broadcast streams, IP streams, files Mandatory (if platform is licensed) Dolby E-AC-3 Broadcast streams, IP streams, files Mandatory (if platform is licensed) Dolby E-AC-3+JOC (Atmos) Broadcast streams, IP streams, files Mandatory (if platform is licensed) Dolby AC-4 Broadcast streams, IP streams Mandatory (if platform is licensed) USAC IP streams Optional SBC Bluetooth Optional FLAC Amazon Music app, files Optional Vorbis WebM, files Optional Opus WebM, files Optional AVS Broadcast streams, files Optional WMA Files Optional RealAudio Files Optional"},{"location":"halif/audio_decoder/current/audio_decoder/#encrypted-audio-playback","title":"Encrypted Audio Playback","text":"<p>Encrypted audio is copied into a non-secure buffer by the application and then decrypted into a secure buffer. The secure buffer is then decoded by an audio decoder accessed through the <code>IAudioDecoderController</code> interface.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#secure-audio-processing","title":"Secure Audio Processing","text":"<p>Secure audio processing (SAP) is a requirement for RDK-E but not all platforms may have support initially. Audio decoder instances shall declare themselves as secure or non-secure by setting <code>Capabilities.supportsSecure</code> appropriately.</p> <p>A secure audio decoder shall be able to handle secure AV buffers and decoded PCM output from the decoder shall be either contained in secure AV buffers or securely tunnelled in the vendor layer.</p> <p>If any audio decoder supports SAP in non-tunnelled mode then the Audio Sink HAL must also support SAP to be able to process secure AV buffers of decoded PCM data, otherwise SAP support is optional.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#clear-pcm-audio-playback","title":"Clear PCM Audio Playback","text":"<p>PCM stream data can originate in the RDK media pipeline from multiple sources; from an application, from the RDK middleware or from a software audio decoder.  In these cases the PCM data does not enter an Audio Decoder and is passed directly to the Audio Sink HAL.</p> <p>Clear PCM audio is copied into a non-secure AV Buffer and then queued at the Audio Sink where it is then mixed for audio output.</p> <p>No buffer decryption or audio decode is required for clear PCM audio buffers.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#audio-passthrough-mode","title":"Audio Passthrough Mode","text":"<p>Audio passthrough can be selected on some output ports which can be applied individually to HDMI output (STB profile), S/PDIF and ARC/eARC (TV profile) ports of the device.</p> <p>Passthrough mode is intended to output the original audio stream to the sink device without decode or mixing of other audio inputs.</p> <p>If the sink device on a port cannot support the audio codec being streamed, then the user selected passthrough mode cannot be honored on that port and normal audio decode and mixing shall apply.</p> <p>When audio passthrough is enabled and possible, then audio stream buffers passed to the Audio Decoder HAL are tunnelled to the vendor audio subsystem for output.</p> <p>In some cases the passthrough mode enabled on some output ports may have to work concurrently with other audio ports not in passthrough mode. This use case requires the audio decoder to tunnel the compressed audio for passthrough and decode it for mixing.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#tunnelled-and-non-tunnelled-audio","title":"Tunnelled and Non-Tunnelled Audio","text":"<p>The Audio Decoder makes its own run-time choice about whether audio is tunnelled or non-tunnelled.</p> <p>Tunnelled audio is required when any audio output ports are in passthrough mode. Tunnelled audio may also be required for some audio codecs that need a vendor integrated decoder/mixer such as Dolby MS12.</p> <p>When only tunnelled audio is in operation, no audio frame pool buffer handles containing decoded PCM audio are handed back to the controller client and the invalid <code>frameBufferHandle</code> value -1 is passed in <code>onFrameOutput()</code> callbacks.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#frame-metadata","title":"Frame Metadata","text":"<p>As audio frames are decoded, the metadata which related to the frames must be passed to the client over <code>IAudioDecoderControllerListener.onFrameOutput()</code>.</p> <p>In non-tunnelled operating mode, the frame buffer handle and metadata related to the frame must be passed in the same <code>onFrameOutput()</code> call.</p> <p>To conserve CPU load, the frame metadata is only passed with the first decoded frame after a <code>start()</code>, the first decoded frame after a <code>flush()</code> or if the frame metadata changes.</p> <p>If the frame metadata does not need to be passed, then the <code>@nullable FrameMetadata metadata</code> parameter should be passed as null in <code>onFrameOutput()</code>.</p> <p>When operating in tunnelled mode, if there is no frame metadata to be passed, then no call to <code>onFrameOutput()</code> should be made because there is no frame buffer handle or frame metadata to return to the client.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#low-latency-mode","title":"Low Latency Mode","text":"<p>A media pipeline is operating in low latency mode when the audio decoder and video decoder (if present) are set with a <code>LOW_LATENCY_MODE</code> property to 1 (enabled).</p> <p>The platform support for low latency audio is indicated in the Audio Sink HAL <code>PlatformCapabilities</code>.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#receiver-mixed-supplementary-audio-decoding","title":"Receiver Mixed Supplementary Audio Decoding","text":"<p>Supplementary audio that is receiver mixed is common in TV broadcasting where the main audio and supplementary audio share a common codec but require 2 audio decoders and mixing.</p> <p>An audio decoder used for supplementary audio is identical to a primary audio decoder, but the indication of its use for supplementary audio is set in the Audio Sink HAL.</p> <p>Any metadata associated with the supplementary/primary audio mix levels is left to the vendor to extract and manage in the vendor layer implementation.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#audio-stream-discontinuities","title":"Audio Stream Discontinuities","text":"<p>Where the client has knowledge of PTS discontinuities in the audio stream, it shall call <code>IAudioDecoderController.signalDiscontinuity()</code> between the AV buffers passed to <code>decodeBuffer()</code>.</p> <p>For the first input AV Buffer audio frame passed in for decode after the discontinuity, it shall indicate the discontinuity in its next output <code>FrameMetadata</code>.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#end-of-stream-signalling","title":"End of Stream Signalling","text":"<p>When the client knows it has delivered the final audio frame buffer to a decoder it shall then call <code>IAudioDecoderController.signalEOS()</code>.</p> <p>The Audio Decoder shall continue to decode all buffers previously passed for decode, but no further audio buffers should be expected unless the audio decoder is first stopped and restarted or is flushed.</p> <p>The Audio Decoder shall emit a <code>FrameMetadata</code> with <code>endOfStream=true</code> after all audio frames have been output from the decoder.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#decoded-audio-frame-buffers","title":"Decoded Audio Frame Buffers","text":"<p>Decoded audio frame buffers are only passed from the audio decoder to the client when operating in non-tunnelled mode.</p> <p>If the input AV Buffer that contained the coded audio frame was passed in a secure buffer, then the corresponding decoded audio frame must be output in a secure audio frame buffer.</p> <p>Audio frame buffers are passed back as handles in the <code>IAudioDecoderControllerListener.onFrameOutput()</code> function <code>frameBufferHandle</code> parameter. If no frame buffer handle is available to pass but the call needs to be made to provide updated <code>FrameMetadata</code> then -1 shall be passed as the handle value.</p> <p>The format of the data in the decoded audio frame buffer is always PCM and described by the <code>FrameMetadata</code>.</p> <p>The frame buffer handle is later passed to the Audio Sink for queuing before presentation and is then freed.</p> <p>The vendor layer is expected to manage the pool of decoded audio buffers privately.</p> <p>If the frame buffer pool is empty then the audio decoder cannot output the next decoded frame until a new frame buffer becomes available. While frame output is blocked, it is reasonable for the audio decoder service to either buffer additional coded input buffers or to reject new calls to <code>decodeBuffer()</code> with a <code>false</code> return value.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#presentation-time-for-audio-frames","title":"Presentation Time for Audio Frames","text":"<p>The presentation time base units for audio frames is nanoseconds and passed in an int64 (long in AIDL definition) variable type. Video buffers shared the same time base units of nanoseconds.</p> <p>When coded audio frames are passed in through AV Buffer handles to <code>IAudioDecoderController.decodeBuffer()</code> the <code>nsPresentationTime</code> parameter represents the audio frame presentation time.</p> <p>Calls to <code>IVideoDecoderControllerListener.onFrameOutput()</code> with frame buffer handles (non-tunnelled mode) and/or frame metadata shall use the same <code>nsPresentationTime</code>.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#dolby-ms12-and-ac-4-audio-decoding","title":"Dolby MS12 and AC-4 Audio Decoding","text":"<p>MS12 is a platform integrated decoder/mixer which requires the compressed audio bitstreams to be tunnelled from the Audio Decoder. Decoded audio frame buffers are not expected to be returned to the RDK middleware.</p> <p>The Dolby AC-4 codec is a bitstream that can contain multiple compressed audio channels which are grouped together in presentations. A presentation is a mix of one or more channels from the bitstream and is achieved in the vendor layer.</p> <p>A licensed Dolby MS12 implementation is required in the vendor layer to support AC-4.</p> <p>By default, an AC-4 audio decoder must use the user preferences for the presentation selection, but players shall also be able to override some or all of these settings without affecting the user preferences. Players must also be able to manually select an AC-4 presentation.</p> <p>The Audio Mixer provides the platform user preferences for AC-4 default presentation selection.</p> <p>The Audio Decoder also provides properties which allow for an override of the platform user preferences for the current player session.</p>"},{"location":"halif/audio_decoder/current/audio_decoder/#audio-decoder-states","title":"Audio Decoder States","text":"<p>The Audio Decoder HAL follows the standard Session State Management paradigm.</p> <p>When an Audio Decoder session enters a <code>FLUSHING</code> or <code>STOPPING</code> transitory state it shall free any AV buffers it is holding.</p> <p>The sequence diagram below shows the behavior of the callbacks.</p> <pre><code>sequenceDiagram\n    %% --- RDK Audio Decoder ---\n    box rgb(30,136,229) RDK Audio Decoder \n        participant Client as RDK Client\n        participant IAudioDecoderEventListener as IAudioDecoderEventListener\n        participant IAudioDecoderControllerListener as IAudioDecoderControllerListener\n    end\n\n    %% --- Audio Decoder Server ---\n    box rgb(249,168,37) Audio Decoder Server\n        participant ADC as IAudioDecoder\n        participant Controller as IAudioDecoderController\n    end\n\n    %% --- Audio AV Buffer ---\n    box rgb(67,160,71) Audio AV Buffer\n        participant IAVBuffer as IAVBuffer\n    end\n\n    Client-&gt;&gt;ADC: registerEventListener(IAudioDecoderEventListener)\n\n    Note over ADC: open() transitions from CLOSED \u2192 OPENING \u2192 READY\n    Client-&gt;&gt;ADC: open(IAudioDecoderControllerListener)\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(CLOSED \u2192 OPENING)\n    ADC-&gt;&gt;Controller: new\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(OPENING \u2192 READY)\n    ADC--&gt;&gt;Client: IAudioDecoderController\n\n    Note over ADC: start() transitions from READY \u2192 STARTING \u2192 STARTED\n    Client-&gt;&gt;Controller: start()\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(READY \u2192 STARTING)\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(STARTING \u2192 STARTED)\n\n    Note over Client: Client can now send AV buffers\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=1, trimStartNs=0, trimEndNs=0)\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=2, trimStartNs=0, trimEndNs=0)\n    Controller--&gt;&gt;IAudioDecoderControllerListener: onFrameOutput(pts, frameBufferHandle=1000, metadata)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1)\n\n    Note over ADC: flush() transitions from STARTED \u2192 FLUSHING \u2192 STARTED\n    Client-&gt;&gt;Controller: flush()\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(STARTED \u2192 FLUSHING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=2)\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(FLUSHING \u2192 STARTED)\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=3, trimStartNs=0, trimEndNs=0)\n\n    Note over ADC: stop() transitions from STARTED \u2192 STOPPING \u2192 READY\n    Client-&gt;&gt;Controller: stop()\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(STARTED \u2192 STOPPING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=3)\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(STOPPING \u2192 READY)\n\n    Note over ADC: close() transitions from READY \u2192 CLOSING \u2192 CLOSED\n    Client-&gt;&gt;ADC: close()\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(READY \u2192 CLOSING)\n    ADC-&gt;&gt;Controller: delete\n    ADC--&gt;&gt;IAudioDecoderEventListener: onStateChanged(CLOSING \u2192 CLOSED)\n    Client-&gt;&gt;ADC: unregisterEventListener(IAudioDecoderEventListener)</code></pre>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/","title":"Audio Decoder (v0.5)","text":"<ul> <li>Note: This page is an early interface version, please ingore, its here for testing of versioning in the documentation</li> </ul>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#overview","title":"Overview","text":"<p>The Audio Decoder Manager service provides the interfaces for compressed audio to be passed to the vendor layer for decoding.  It may be passed secure buffers if it indicates support for secure audio processing.</p> <p>The output of an audio decoder can take 2 routes; non-tunnelled it comes back to the RDK media pipeline as a PCM stream and metadata or tunnelled through the vendor layer directly to the mixer.</p> <p>The choice of whether audio is tunnelled or non-tunnelled has no impact on the operational mode of the video decoder.  It is possible to have tunnelled video and non-tunnelled audio.</p> <p>The audio decoder can choose whether to operate in tunnelled or non-tunnelled mode when it is opened for a specific codec and does not need to always use the same mode.</p> <p>PCM audio does not need decoding and therefore never passes into an audio decoder, but is routed to the Audio Sink for mixing.</p> <p>The RDK middleware GStreamer pipeline contains an RDK Audio Decoder element designed specifically to work with the Audio Decoder HAL interface.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#implementation-requirements","title":"Implementation Requirements","text":"Requirement Comments HAL.AUDIODECODER.1 Starting and stopping audio streams shall never produce an audible click or pop artefact due to the audio waveform the audio streaming was started or stopped at. This requirement works in conjunction with the audio mixer. HAL.AUDIODECODER.2 An audio decoder shall indicate its support for secure audio processing through its resource capabilities. HAL.AUDIODECODER.3 An audio decoder advertising the secure audio processing capability that receives a secure buffer of compressed audio shall output decoded audio to secure buffers either returned to the client or tunnelled to the mixer. Secure audio path must be maintained. HAL.AUDIODECODER.4 An audio decoder can tunnel decoded audio to a mixer or the vendor audio sub-system for passthrough and/or return the decoded audio as PCM to the client. HAL.AUDIODECODER.5 When the client enables the audio decoder low latency property and the audio decoder and platform support low latency audio then the audio frame metadata shall indicate low latency. HAL.AUDIODECODER.6 Each audio decoder resource shall be presented by a unique ID. HAL.AUDIODECODER.7 Each audio decoder resource shall provide an API to expose its capabilities for secure audio processing and supported codecs. HAL.AUDIODECODER.8 Only 1 client connection shall be allowed to open and control an audio decoder resource. HAL.AUDIODECODER.9 Multiple client connections shall be allowed to register for events from an audio decoder resource. HAL.AUDIODECODER.10 Audio frame metadata shall be returned to a controlling client on the first audio frame decoded after an open or flush and then against not until the frame metadata changes. Not sent on every decoded audio frame buffer unless changed since previous. HAL.AUDIODECODER.11 The audio frame output buffer from an audio decoder shall match the platform PCM audio format required for mixing. See <code>com.rdk.hal.audiosink.PlatformCapabilities</code>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description IAudioDecoderManager.aidl Audio Decoder Manager HAL which provides access to <code>IAudioDecoder</code> resource instances. IAudioDecoder.aidl Audio Decoder interface for a single audio decoder resource instance. IAudioDecoderController.aidl Controller interface for an IAudioDecoder resource instance. IAudioDecoderControllerListener.aidl Listener callbacks interface to clients from an IAudioDecoderController. IAudioDecoderEventListener.aidl Listener callbacks interface to clients from an <code>IAudioDecoder</code>. Capabilities.aidl Parcelable describing the capabilities of an IAudioDecoder resource instance. ChannelType.aidl Enum list of audio channel types. Codec.aidl Enum list of audio codecs. CSDAudioFormat.aidl Enum list of audio codec specific data formats. ErrorCode.aidl Enum list of audio decoder error codes. FrameMetadata.aidl Parcelable of audio frame metadata passed from the audio decoder. PCMFormat.aidl Enum list of PCM coding formats. Property.aidl Enum list of audio decoder properties."},{"location":"halif/audio_decoder/v0.5/audio_decoder/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-audio_decoder_manager.service</code> unit file is provided by the vendor layer to start the service and should include Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The Audio Decoder Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the IAudioDecoderManager interface with the Service Manager using the String <code>IAudioDecoderManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#product-customization","title":"Product Customization","text":"<p>The IAudioDecoderManager.getAudioDecoderIds() should return an array of <code>IAudioDecoder.Id parcelables</code> to uniquely represent all of the audio decoder resources supported by the vendor layer.  Typically, the ID value starts at 0 for the first audio decoder and increments by 1 for each additional audio decoder.</p> <p>The Capabilities parcelable returned by the <code>IAudioDecoder.getCapabilities()</code> function lists all of the Codec types supported by this audio decoder instance and indicates if the secure audio path can be used.</p> <p>An audio decoder instance may support any number of audio codecs, but can only operate on one compressed audio stream in an open session.  Concurrent audio decode requires multiple audio decoder instances to be opened.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#system-context","title":"System Context","text":"<p>The Audio Decoder HAL can provide functionality to multiple clients which exist both inside the RDK middleware.</p> <p>Typically an RDK middleware GStreamer audio decoder element will work with a single IAudioDecoder instance and pass it AV Buffer handles for decode.</p> <p>The RDK middleware resource management system will examine the number of audio decoder resources and their capabilities, so they can be allocated to streaming sessions.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IAudioDecoderEventListener(\"IAudioDecoderEventListener\")\n        IAudioDecoderControllerListener(\"IAudioDecoderControllerListener\")\n    end\n    subgraph IAudioDecoderHAL[\"Audio Decoder HAL\"]\n        IAudioDecoderManager(\"IAudioDecoderManager &lt;br&gt;(Service)\")\n        IAudioDecoder(\"IAudioDecoder &lt;br&gt;(Instance)\")\n        IAudioDecoderController(\"IAudioDecoderController &lt;br&gt;(Instance)\")\n    end\n    subgraph OutputComponents[\"Output\"]\n        AudioFramePool(\"Audio Frame Pool\")\n        PlatformDecoder(\"Platform Integrated Decoder/Mixer\")\n        AudioOutput(\"Audio Output Ports in passthrough\")\n    end\n    RDKClientComponent -- createAudioPool() &lt;br&gt; alloc() &lt;br&gt; free() &lt;br&gt; destroyPool() --&gt; IAVBuffer(IAVBuffer)\n    RDKClientComponent -- getIAudioDecoderIds() &lt;br&gt; getIAudioDecoder() --&gt; IAudioDecoderManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() --&gt; IAudioDecoder\n    RDKClientComponent -- registerEventListener() / unregisterEventListener() --&gt; IAudioDecoder\n    RDKClientComponent -- start() &lt;br&gt; stop() &lt;br&gt; setProperty() &lt;br&gt; decodeBuffer() &lt;br&gt; flush() &lt;br&gt; signalDiscontinuity() / signalEOS() / parseCodecSpecificData() --&gt; IAudioDecoderController\n    IAudioDecoderManager --&gt; IAudioDecoder --&gt; IAudioDecoderController\n    IAudioDecoder -- onStateChanged() &lt;br&gt; onDecodeError() --&gt; IAudioDecoderEventListener\n    IAudioDecoderEventListener --&gt; RDKClientComponent\n    IAudioDecoderControllerListener --&gt; RDKClientComponent\n    IAudioDecoderController -- onFrameOutput() --&gt; IAudioDecoderControllerListener\n    IAudioDecoderController -- alloc() --&gt; AudioFramePool\n    IAudioDecoderManager -- free() --&gt; IAVBuffer\n    IAudioDecoderController -- tunneled audio --&gt; PlatformDecoder\n    IAudioDecoderController -- tunneled audio &lt;br&gt;(passthrough) --&gt; AudioOutput\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IAudioDecoderManager:::wheat\n    IAudioDecoderController:::wheat\n    IAudioDecoder:::wheat\n    IAVBuffer:::green\n    IAudioDecoderControllerListener:::wheat\n    IAudioDecoderEventListener:::wheat\n    AudioFramePool:::green\n    PlatformDecoder:::green\n    AudioOutput:::green</code></pre>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#resource-management","title":"Resource Management","text":"<p>The IAudioDecoderManager provides access to one or more <code>IAudioDecoder</code> sub-interfaces which each represent an audio decoder resource instance offered by the platform.</p> <p>Each IAudioDecoder resource instance is assigned a unique integer ID, which is used in IAudioDecoder.Id.value and can be read from RESOURCE_ID using the <code>IAudioDecoder.getProperty()</code> function.</p> <p>To use an IAudioDecoder resource instance it must be opened by a client, which returns an <code>IAudioDecoderController</code> sub-interface to access buffer decoding and additional state controls.</p> <p>Any number of clients can access the IAudioDecoderManager service and get access to the IAudioDecoder sub-interfaces, but only 1 client can open() an <code>IAudioDecoder</code> and access its <code>IAudioDecoderController</code> sub-interface.</p> <p>The diagram below shows the relationship between the interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"Audio Decoder HAL\" ---\n    subgraph ADHAL[\"Audio Decoder HAL\"]\n        direction LR\n        ADMS(\"IAudioDecoderManager\")\n\n        %% --- Audio Decoder Manager Service Spawns Instances ---\n        ADMS --&gt; ADI1(\"IAudioDecoder &lt;br&gt; ID = 0\")\n        ADMS --&gt; ADI2(\"IAudioDecoder &lt;br&gt; ID = 1\")\n        ADMS --&gt; ADI3(\"IAudioDecoder &lt;br&gt; ID = 2\")\n\n        %% --- Each Instance Has a Controller ---\n        ADI1 --&gt; ADIC1(\"IAudioDecoderController\")\n        ADI2 --&gt; ADIC2(\"IAudioDecoderController\")\n        ADI3 --&gt; ADIC3(\"IAudioDecoderController\")\n    end\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n    %% --- Apply Colors ---\n    class ADHAL hal;\n    class ADMS manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;\n</code></pre>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#encrypted-audio-playback","title":"Encrypted Audio Playback","text":"<p>Encrypted audio is copied into a non-secure buffer by the application and then decrypted into a secure buffer.  The secure buffer is then decoded by an audio decoder accessed through the IAudioDecoderController  interface.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#secure-audio-processing","title":"Secure Audio Processing","text":"<p>Secure audio processing (SAP) is a requirement for RDK-E but not all platforms may have support initially. Audio decoder instances shall declare themselves as secure or non-secure by setting Capabilities.supportsSecure appropriately.</p> <p>A secure audio decoder shall be able to handle secure AV buffers and decoded PCM output from the decoder shall be either contained in secure AV buffers or securely tunnelled in the vendor layer.</p> <p>If any audio decoder supports SAP in non-tunnelled mode then the Audio Sink HAL must also support SAP to be able to process secure AV buffers of decoded PCM data, otherwise SAP support is optional.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#clear-pcm-audio-playback","title":"Clear PCM Audio Playback","text":"<p>PCM stream data can originate in the RDK media pipeline from multiple sources; from an application, from the RDK middleware or from a software audio decoder.  In these cases the PCM data does not enter an Audio Decoder and is passed directly to the Audio Sink HAL.</p> <p>Clear PCM audio is copied into a non-secure buffer and is routed to the IAudioSink where it is mixed for audio output.</p> <p>No buffer decryption or audio decode is required for clear PCM audio buffers.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#audio-passthrough-mode","title":"Audio Passthrough Mode","text":"<p>Audio passthrough can be selected on some output ports which can be applied individually to HDMI output (STB profile), S/PDIF and ARC/eARC (TV profile) ports of the device.</p> <p>Passthrough mode is intended to output the original audio stream to the sink device without decode or mixing of other audio inputs.</p> <p>If the sink device on a port cannot support the audio codec being streamed, then the user selected passthrough mode cannot be honored on that port and normal audio decode and mixing shall apply.</p> <p>When audio passthrough is enabled and possible, then audio stream buffers passed to the Audio Decoder HAL are tunnelled to the vendor audio subsystem for output.</p> <p>In some cases the passthrough mode enabled on some output ports may have to work concurrently with other audio ports not in passthrough mode.  This use case requires the audio decoder to tunnel the compressed audio for passthrough and decode it for mixing.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#tunnelled-and-non-tunnelled-audio","title":"Tunnelled and Non-Tunnelled Audio","text":"<p>The Audio Decoder makes its own run-time choice about whether audio is tunnelled or non-tunnelled.</p> <p>Tunnelled audio is required when any audio output ports are in passthrough mode.  Tunnelled audio may also be required for some audio codecs that need a vendor integrated decoder/mixer such as Dolby MS12.</p> <p>When only tunnelled audio is in operation, no audio frame pool buffer handles containing decoded PCM audio are handed back to the controller client and the invalid frameBufferHandle value -1 is passed in onFrameOutput() callbacks.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#low-latency-mode","title":"Low Latency Mode","text":"<p>A media pipeline is operating in low latency mode the audio decoder HAL and video decoder HAL (if present) are set with a LOW_LATENCY_MODE property to 1 (enabled).</p> <p>The platform support for low latency audio is indicated is the Audio Sink Capabilities parcelable.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#receiver-mixed-supplementary-audio-decoding","title":"Receiver Mixed Supplementary Audio Decoding","text":"<p>Supplementary audio that is receiver mixed is common in TV broadcasting where the main audio and supplementary audio share a common codec but require 2 audio decoders and mixing.</p> <p>An audio decoder used for supplementary audio is identical to a primary audio decoder, but the indication of its use for supplementary audio is set in the Audio Sink HAL.</p> <p>Any metadata associated with the supplementary/primary audio mix levels is left to the vendor to extract and manage in the vendor layer implementation.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#audio-stream-discontinuities","title":"Audio Stream Discontinuities","text":"<p>Where the client has knowledge of PTS discontinuities in the audio stream, it shall call IAudioDecoderController.signalDiscontinuity() between the linear frame buffers passed to decodeBuffer().</p> <p>For the first input linear buffer audio frame passed in for decode after the discontinuity, it shall indicate the discontinuity in its next output FrameMetadata, </p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#end-of-stream-signalling","title":"End of Stream Signalling","text":"<p>When the client knows it has delivered the final audio frame buffer to a decoder it shall then call IAudioDecoderController.signalEOS().</p> <p>The Audio Decoder shall continue to decode all buffers previously passed for decode, but no further audio buffers should be expected unless the audio decoder is first stopped and restarted or is flushed.</p> <p>The Audio Decoder shall emit a FrameMetadata with endOfStream=true after all audio frames have been output from the decoder.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#dolby-ms12-and-ac-4-audio-decoding","title":"Dolby MS12 and AC-4 Audio Decoding","text":"<p>MS12 is a platform integrated decoder/mixer which requires the compressed audio bitstreams to be tunnelled from the Audio Decoder.  Decoded audio frame buffers are not expected to be returned to the RDK middleware.</p> <p>The Dolby AC-4 codec is a bitstream that can contain multiple compressed audio channels which are grouped together in presentations. A presentation is a mix of one or more channels from the bitstream is achieved in the vendor layer.</p> <p>A licensed Dolby MS12 implementation is required in the vendor layer to support AC-4.</p> <p>By default, an AC-4 audio decoder must use the user preferences for the presentation selection, but players shall also be able to override some or all of these settings without affecting the user preferences. Players must also be able to manually select an AC-4 presentation.</p> <p>The Audio Mixer provides the platform user preferences for AC-4 default presentation selection.</p> <p>The Audio Decoder also provides properties which allow for an override of the platform user preferences for the current player session.</p>"},{"location":"halif/audio_decoder/v0.5/audio_decoder/#audio-decoder-states","title":"Audio Decoder States","text":"<p>The Audio Decoder HAL follows the standard Session State Management  paradigm.</p> <p>When an Audio Decoder session enters a FLUSHING or STOPPING transitory state it shall free any AV buffers it is holding.</p> <p>The sequence diagram below shows the behavior of the callbacks.</p> <pre><code>@startuml\n\nbox RDK Audio Decoder #LightBlue\n  participant Client as \"RDK Client\"\n  participant IAudioDecoderEventListener\n  participant IAudioDecoderControllerListener\nendbox\nbox Audio Decoder Server #Yellow\n  participant ADC as \"IAudioDecoder\"\n  participant Controller as \"IAudioDecoderController\"\nendbox\nbox Audio AV Buffer #LightGreen\n  participant IAVBuffer as \"IAVBuffer\"\nendbox\n\n  Client-&gt;ADC: registerEventListener(IAudioDecoderEventListener)\n\n... open() transitions from CLOSED -&gt; OPENING -&gt; READY...\n\n  Client-&gt;ADC: open(IAudioDecoderControllerListener)\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(CLOSED -&gt; OPENING)\n  ADC-&gt;Controller **: new\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(OPENING -&gt; READY)\n  ADC--&gt;Client: IAudioDecoderController\n\n... start() transitions from READY -&gt; STARTING -&gt; STARTED...\n\n  Client-&gt;Controller: start()\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(READY -&gt; STARTING)\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(STARTING -&gt; STARTED)\n\n  Note over Client: Client can now\\nsend AV buffers\n\n  Client-&gt;Controller: decodeBuffer(pts, bufferHandle=1, trimStartNs=0, trimEndNs=0)\n  Client-&gt;Controller: decodeBuffer(pts, bufferHandle=2, trimStartNs=0, trimEndNs=0)\n  Controller--&gt;IAudioDecoderControllerListener: onFrameOutput(pts, frameBufferHandle=1000, metadata)\n  Controller-&gt;IAVBuffer: free(bufferHandle=1)\n\n... flush() transitions from STARTED -&gt; FLUSHING -&gt; STARTED...\n\n  Client-&gt;Controller: flush()\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(STARTED -&gt; FLUSHING)\n  Controller-&gt;IAVBuffer: free(bufferHandle=2)\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(FLUSHING -&gt; STARTED)\n\n  Client-&gt;Controller: decodeBuffer(pts, bufferHandle=3, trimStartNs=0, trimEndNs=0)\n\n... stop() transitions from STARTED -&gt; STOPPING -&gt; READY...\n\n  Client-&gt;Controller: stop()\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(STARTED -&gt; STOPPING)\n  Controller-&gt;IAVBuffer: free(bufferHandle=3)\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(STOPPING -&gt; READY)\n\n... close() transitions from READY -&gt; CLOSING -&gt; CLOSED...\n\n  Client-&gt;ADC: close()\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(READY -&gt; CLOSING)\n  ADC-&gt;Controller !!: delete\n  ADC--&gt;IAudioDecoderEventListener: onStateChanged(CLOSING -&gt; CLOSED)\n\n  Client-&gt;ADC: unregisterEventListener(IAudioDecoderEventListener)\n\n@enduml\n</code></pre>"},{"location":"halif/audio_mixer/current/audio_mixer/","title":"Audio Mixer","text":""},{"location":"halif/audio_mixer/current/audio_mixer/#references","title":"References","text":"<p>Info</p> Interface Definition audio_mixer/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-audio_mixer.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/audio_mixer/current/audio_mixer/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Audio Sink</li> <li>AV Buffer</li> <li>Session State Management</li> </ul>"},{"location":"halif/audio_mixer/current/audio_mixer/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/audio_mixer/current/intro/","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction. Please check back later for updates.</p>"},{"location":"halif/audio_sink/current/audio_sink/","title":"Audio Sink","text":"<p>The Audio Sink HAL provides a standardized interface for managing and controlling the playback of non-tunnelled Pulse Code Modulation (PCM) audio streams. It acts as an abstraction layer between the audio processing hardware and higher-level software components, such as the RDK middleware.  The primary function of the Audio Sink HAL is to receive PCM audio frame buffers, deliver them to the audio mixer, and expose controls for managing audio mixing levels, including volume, mute state, and fade effects.</p> <p>This HAL is designed to handle PCM audio data that has been decoded or generated by software components within the system. It specifically excludes support for tunnelled audio (where the encoded audio stream is passed directly to the hardware for decoding) and audio passthrough modes (where the audio stream bypasses software processing altogether).  These scenarios are handled differently within the audio pipeline.</p> <p>The RDK middleware, specifically the GStreamer pipeline, includes a dedicated RDK Audio Sink element that is designed to interact seamlessly with the Audio Sink HAL. This element handles the task of receiving audio data from the pipeline, formatting it into appropriate frame buffers, and delivering it to the HAL for playback.  It also manages the communication with the HAL to control mixing parameters and handle audio events.</p> <p>The Audio Sink HAL plays a critical role in the overall audio playback architecture by:</p> <ul> <li>Abstracting Hardware: It provides a consistent interface to the audio hardware, shielding higher-level software from hardware-specific details. This allows for easier porting of the middleware to different platforms with varying audio hardware.</li> <li>Managing Resources: The HAL can manage multiple audio sink instances, each representing a distinct audio output or stream. This allows for concurrent playback of multiple audio sources.</li> <li>Controlling Mixing: It provides controls for volume, mute, and fading, enabling applications to adjust the audio output to their requirements.</li> <li>Handling Buffers: The HAL is responsible for receiving audio frame buffers, ensuring they are in the correct format, and delivering them to the audio mixer for processing.</li> <li>Event Handling: The HAL can generate events related to audio playback, such as changes in state, errors, or end-of-stream notifications, allowing the middleware to react accordingly.</li> </ul> <p>The interaction between the RDK GStreamer Audio Sink element and the Audio Sink HAL is crucial for efficient and robust audio playback.  The element handles the higher-level stream management, while the HAL takes care of the low-level hardware interaction and mixing control.  This separation of concerns simplifies the design and maintenance of the audio subsystem.</p>"},{"location":"halif/audio_sink/current/audio_sink/#references","title":"References","text":"<p>Info</p> Interface Definition audio_sink/current API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-audio_sink.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/audio_sink/current/audio_sink/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Audio Decoder</li> <li>AV Buffer</li> <li>AV Clock</li> <li>Session State Management</li> </ul>"},{"location":"halif/audio_sink/current/audio_sink/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.AUDIOSINK.1 Starting and stopping audio streams shall never produce an audible click or pop artefact due to the audio waveform where the audio streaming was started or stopped. HAL.AUDIOSINK.2 If any audio decoders support secure audio path processing (SAP) then the audio sink shall be capable of processing secure input buffers to maintain SAP. HAL.AUDIOSINK.3 The default volume level for an audio sink session shall be 1.0 (full volume) and unmuted. HAL.AUDIOSINK.4 The default reference level for an audio sink session shall be -31dB. HAL.AUDIOSINK.5 If a client process exits, the Audio Sink server shall automatically stop and close any Audio Sink instance controlled by that client."},{"location":"halif/audio_sink/current/audio_sink/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IAudioSinkManager.aidl</code> Audio Sink Manager HAL interface which provides access to the <code>IAudioSink</code> resource instances. <code>IAudioSink.aidl</code> Audio Sink interface for a single audio sink resource instance. <code>IAudioSinkController.aidl</code> Controller interface for an <code>IAudioSink</code> resource instance. <code>IAudioSinkControllerListener.aidl</code> Listener callbacks interface to clients from an <code>IAudioSinkController</code>. <code>IAudioSinkEventListener.aidl</code> Listener callbacks interface to clients from an <code>IAudioSink</code>. <code>Capabilities.aidl</code> Parcelable describing the capabilities of an <code>IAudioSink</code> resource instance. <code>ErrorCode.aidl</code> Enum list of audio sink error codes. <code>PlatformCapabilities.aidl</code> Parcelable describing the capabilities of the platform audio. <code>Property.aidl</code> Enum list of audio sink properties. <code>Volume.aidl</code> Parcelable for defining a volume and mute state. <code>VolumeRamp.aidl</code> Enum list of volume ramp types."},{"location":"halif/audio_sink/current/audio_sink/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-audios_sink_manager.service</code> unit file is provided by the vendor layer to start the service and should include Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The Audio Sink Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the <code>IAudioSinkManager</code> interface with the Service Manager using the string <code>IAudioSinkManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/audio_sink/current/audio_sink/#product-customization","title":"Product Customization","text":"<p>The <code>IAudioSinkManager.getAudioSinkIds()</code> should return an array of <code>IAudioSink.Id</code> parcelables to uniquely represent all of the audio sink resources supported by the vendor layer. Typically, the ID value starts at 0 for the first audio sink and increments by 1 for each additional audio sink.</p> <p>The <code>Capabilities</code> parcelable returned by the <code>IAudioSink.getCapabilities()</code> function lists all capabilities supported by this audio sink instance.</p> <p>An audio sink instance can only operate on one audio stream in an open session. Concurrent audio streams require multiple audio sink instances to be opened.</p>"},{"location":"halif/audio_sink/current/audio_sink/#system-context","title":"System Context","text":"<p>The Audio Sink HAL can provide functionality to multiple clients.</p> <p>Typically an RDK middleware GStreamer audio sink element will work with a single <code>IAudioSink</code> instance and pass it PCM audio in AV Buffer handles for mixing.</p> <p>The RDK middleware resource management system will examine the number of audio sink resources and their capabilities, so they can be allocated to streaming sessions.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IAudioSinkEventListener(\"IAudioSinkEventListener\")\n        IAudioSinkControllerListener(\"IAudioSinkControllerListener\")\n    end\n    subgraph IAudioSinkHAL[\"Audio Decoder HAL\"]\n        IAudioSinkManager(\"IAudioSinkManager &lt;br&gt;(Service)\")\n        IAudioSink(\"IAudioSink &lt;br&gt;(Instance)\")\n        IAudioSinkController(\"IAudioSinkController &lt;br&gt;(Instance)\")\n    end\n    subgraph OutputComponents[\"Output\"]\n        platformMixer(\"Platform Integrated Mixer\")\n    end\n    RDKClientComponent -- createAudioPool() &lt;br&gt; alloc() &lt;br&gt; free() &lt;br&gt; destroyPool() --&gt; IAVBuffer(IAVBuffer)\n    AudioFramePool(\"Audio Frame Pool\")\n    IAVBuffer -- free() --&gt; AudioFramePool\n    RDKClientComponent -- getIAudioSinkIds() &lt;br&gt; getIAudioSink() --&gt; IAudioSinkManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getProperty() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() &lt;br&gt; registerEventListener() &lt;br&gt; unregisterEventListener() --&gt; IAudioSink\n    RDKClientComponent -- setAudioDecoder() &lt;br&gt; getAudioDecoder() &lt;br&gt; start() &lt;br&gt; stop() &lt;br&gt; queueAudioFrame() &lt;br&gt; flush() &lt;br&gt; getVolume() &lt;br&gt; setVolume() &lt;br&gt; setVolumeRamp() --&gt; IAudioSinkController\n    IAudioSinkManager --&gt; IAudioSink --&gt; IAudioSinkController\n    IAudioSink -- onStateChanged() &lt;br&gt; onFristFrameRendered() &lt;br&gt; onEndOfStream() &lt;br&gt; onAudioUnderflow() &lt;br&gt; onAudioResumed() &lt;br&gt; onFlushComplete()--&gt; IAudioSinkEventListener\n    IAudioSinkController -- onStateChanged() &lt;br&gt; onFristFrameRendered() &lt;br&gt; onEndOfStream() &lt;br&gt; onAudioUnderflow() &lt;br&gt; onAudioResumed() &lt;br&gt; onFlushComplete()--&gt; IAudioSinkControllerListener\n    IAudioSinkEventListener --&gt; RDKClientComponent\n    IAudioSinkControllerListener --&gt; RDKClientComponent\n    IAudioSinkManager -- free() --&gt; IAVBuffer\n    IAudioSinkController -. audio -.-&gt; platformMixer\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IAudioSinkManager:::wheat\n    IAudioSinkController:::wheat\n    IAudioSink:::wheat\n    IAVBuffer:::green\n    IAudioSinkControllerListener:::wheat\n    IAudioSinkEventListener:::wheat\n    AudioFramePool:::green\n    platformMixer:::green</code></pre>"},{"location":"halif/audio_sink/current/audio_sink/#resource-management","title":"Resource Management","text":"<p>The <code>IAudioSinkManager</code> provides access to one or more <code>IAudioSink</code> sub-interfaces which each represent an audio sink resource instance offered by the platform.</p> <p>Each <code>IAudioSink</code> resource instance is assigned a unique integer ID, which is used in the <code>IAudioSink.Id.value</code> and can be read from <code>RESOURCE_ID</code> using the <code>IAudioSink.getProperty()</code> function.</p> <p>To use an <code>IAudioSink</code> resource instance it must be opened by a client, which returns an <code>IAudioSinkController</code> sub-interface to access buffer queuing and additional state controls.</p> <p>Important</p> <p>Any number of clients can access the <code>IAudioSinkManager</code> service and get access to the <code>IAudioSink</code> sub-interfaces, but only 1 client can <code>open()</code> an <code>IAudioSink</code> and access its <code>IAudioSinkController</code> sub-interface.</p> <p>The diagram below shows the relationship between the interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"Audio Decoder HAL\" ---\n    IAudioSinkManager(\"IAudioSinkManager\")\n\n    %% --- Audio Decoder Manager Service Spawns Instances ---\n    IAudioSinkManager --&gt; ADI1(\"IAudioSink &lt;br&gt; ID = 0\")\n    IAudioSinkManager --&gt; ADI2(\"IAudioSink &lt;br&gt; ID = 1\")\n    IAudioSinkManager --&gt; ADI3(\"IAudioSink &lt;br&gt; ID = 2\")\n\n    %% --- Each Instance Has a Controller ---\n    ADI1 --&gt; ADIC1(\"IAudioSinkController\")\n    ADI2 --&gt; ADIC2(\"IAudioSinkController\")\n    ADI3 --&gt; ADIC3(\"IAudioSinkController\")\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n    %% --- Apply Colors ---\n    class IAudioSinkManager manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/audio_sink/current/audio_sink/#audio-buffers","title":"Audio Buffers","text":"<p>Audio buffers entering the Audio Sink shall be delivered as AV Buffer handles (allocated from either an AV Buffer audio pool or the audio frame pool) with a presentation timestamp and metadata describing the audio frame through the <code>IAudioSinkController.queueAudioFrame()</code> function.</p> <p>An AV Buffer audio pool would be used for PCM data which has come from system memory (e.g. PCM sound clip) or from a soft audio decoder. In this case the audio pool is created against <code>IAudioDecoder.Id.UNDEFINED</code>.</p> <p>The audio data must be in the PCM audio format and sample rate, as reported in <code>PlatformCapabilities</code> returned from the <code>IAudioSinkManager.getPlatformCapabilities()</code> function.</p> <p>Once the data in an audio frame buffer has been fully passed to or processed by the mixer, the Audio Sink shall free the handle by calling <code>IAVBuffer.free()</code>.</p>"},{"location":"halif/audio_sink/current/audio_sink/#secure-audio-processing","title":"Secure Audio Processing","text":"<p>If any audio decoder supports SAP in non-tunnelled mode then the Audio Sink HAL must also support SAP to be able to process secure AV buffers of decoded PCM data, otherwise SAP support is optional.</p>"},{"location":"halif/audio_sink/current/audio_sink/#clear-pcm-audio-playback","title":"Clear PCM Audio Playback","text":"<p>PCM stream data can originate in the RDK media pipeline from multiple sources; from an application, from the RDK middleware or from a software audio decoder. In these cases the PCM data is passed directly to the Audio Sink HAL.</p> <p>Clear PCM audio is copied into a non-secure AV Buffer and is routed to the <code>IAudioSinkController</code> where it is queued for mixing.</p>"},{"location":"halif/audio_sink/current/audio_sink/#tunnelled-audio-passthrough-mode","title":"Tunnelled Audio &amp; Passthrough Mode","text":"<p>The Audio Sink HAL cannot handle audio frame buffers when tunnelled audio is exclusively in use or when audio passthrough mode is enabled.</p> <p>In these cases an Audio Decoder does not return audio frame buffer handles that can be passed to the Audio Sink.</p> <p>The Audio Sink HAL is still used to control the audio stream volume, mute and volume ramping.</p>"},{"location":"halif/audio_sink/current/audio_sink/#end-of-stream-signalling","title":"End of Stream Signalling","text":"<p>The Audio Decoder shall emit a <code>FrameMetadata</code> with <code>endOfStream=true</code> after all audio frames have been output from the decoder.</p> <p>For PCM audio, a <code>FrameMetadata</code> with <code>endOfStream=true</code> shall be generated by the RDK middleware client after the last audio frame buffer has been passed to the Audio Sink.</p> <p>For non-tunnelled audio, the Audio Sink shall be passed this metadata with the final audio frame buffer or after the last audio frame buffer has been queued by the RDK middleware client.</p> <p>All audio frame buffers queued up in the Audio Sink are expected to continue to be fed into the audio mixer in the usual way, but the Audio Sink is not expecting any further audio buffers to be queued.</p>"},{"location":"halif/audio_sink/current/audio_sink/#audio-sink-states","title":"Audio Sink States","text":"<p>The Audio Sink HAL follows the standard Session State Management paradigm.</p> <p>When an Audio Sink session enters a <code>FLUSHING</code> or <code>STOPPING</code> transitory state it shall free any AV buffers it is holding.</p> <p>The sequence diagram below shows the behavior of the callbacks.</p> <pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK Audio Sink\n        participant Client as RDK Client\n        participant IAudioSinkEventListener\n        participant IAudioSinkControllerListener\n    end\n    box rgb(249,168,37) Audio Sink Server\n        participant ADC as IAudioSink\n        participant Controller as IAudioSinkController\n    end\n    box rgb(67,160,71) Audio AV Buffer\n        participant IAVBuffer as IAVBuffer\n    end\n\n    Client-&gt;&gt;ADC: registerEventListener(IAudioSinkEventListener)\n\n    Note over ADC: open() transitions from CLOSED -&gt; OPENING -&gt; READY\n\n    Client-&gt;&gt;ADC: open(IAudioSinkControllerListener)\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(CLOSED -&gt; OPENING)\n    ADC-&gt;&gt;Controller: new\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(OPENING -&gt; READY)\n    ADC--&gt;&gt;Client: IAudioSinkController\n    Client-&gt;&gt;Controller: setAudioSink(0)\n\n    Note over ADC: start() transitions from READY -&gt; STARTING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: start()\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(READY -&gt; STARTING)\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(STARTING -&gt; STARTED)\n\n    Note over Client: Client can now queue\\n audio frame buffers\n\n    Client-&gt;&gt;Controller: queueAudioFrame(pts, bufferHandle=1000, metadata)\n    Client-&gt;&gt;Controller: queueAudioFrame(pts, bufferHandle=1001, metadata)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1000)\n\n    Note over ADC: flush() transitions from STARTED -&gt; FLUSHING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: flush()\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(STARTED -&gt; FLUSHING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1001)\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(FLUSHING -&gt; STARTED)\n\n    Client-&gt;&gt;Controller: queueAudioFrame(pts, bufferHandle=1002, metadata)\n\n    Note over ADC: stop() transitions from STARTED -&gt; STOPPING -&gt; READY\n\n    Client-&gt;&gt;Controller: stop()\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(STARTED -&gt; STOPPING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1002)\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(STOPPING -&gt; READY)\n\n    Note over ADC: close() transitions from READY -&gt; CLOSING -&gt; CLOSED\n\n    Client-&gt;&gt;ADC: close()\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(READY -&gt; CLOSING)\n    ADC-&gt;&gt;Controller: delete\n    ADC--&gt;&gt;IAudioSinkEventListener: onStateChanged(CLOSING -&gt; CLOSED)\n\n    Client-&gt;&gt;ADC: unregisterEventListener(IAudioSinkEventListener)</code></pre>"},{"location":"halif/av_buffer/current/av_buffer/","title":"AV Buffer","text":"<p>The AV Buffer HAL manages both secure and non-secure memory heaps and pools for the media pipeline and related A/V HAL components.</p> <ul> <li>An AV buffer typically stores audio or video data, which may be in either encrypted or clear form.</li> <li>Secure memory buffers handle decrypted data when DRM, conditional access, or other secure decryption mechanisms are used.</li> <li>Non-secure memory is allocated for encrypted data from a media player source until it is decrypted into a secure memory buffer.</li> <li>If a media player processes only clear (unencrypted) audio or video data, non-secure memory buffers can be used throughout from source to decoder.</li> <li>AV memory buffers are referenced by handles as they move through the media pipeline and across HAL interfaces.</li> </ul>"},{"location":"halif/av_buffer/current/av_buffer/#references","title":"References","text":"<p>Info</p> Interface Definition av_buffer/current API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-av_buffer.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/av_buffer/current/av_buffer/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Audio Decoder</li> <li>Audio Sink</li> <li>AV Clock</li> <li>Session State Management</li> <li>Video Decoder</li> </ul>"},{"location":"halif/av_buffer/current/av_buffer/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.AVBUF.1 AV buffer handles shall be unique across all memory pools and heaps, including the vendor video frame pool and audio frame pool. HAL.AVBUF.2 Pool handles shall be unique across all memory pools and heaps. HAL.AVBUF.3 Buffer allocations from pools are made to fit a single video frame or audio frame. HAL.AVBUF.4 The last buffer allocated from a pool may be trimmed to reduce its allocated size down. HAL.AVBUF.5 Metrics on heap usage can be retrieved. HAL.AVBUF.6 Metrics on pool usage can be retrieved. HAL.AVBUF.7 Memory buffers allocated from a secure memory pool cannot be mapped into the address space of unprivileged processes and must meet secure video path or secure audio path requirements. Only vendor layer trusted entities can access secure memory (e.g. TA or secure hardware peripheral). HAL.AVBUF.8 The size of the heaps and pools shall be determined by the vendor to meet the platform and product requirements for audio and video. HAL.AVBUF.9 A helper library shall be provided to allow middleware processes to map and unmap non-secure buffers, and copy data to secure and non-secure buffers."},{"location":"halif/av_buffer/current/av_buffer/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IAVBuffer.aidl</code> AV Buffer HAL interface which provides the central API for buffer management. <code>IAVBufferSpaceListener.aidl</code> Pool space listener callback interface. <code>Pool.aidl</code> Pool handle parcelable definition. <code>HeapMetrics.aidl</code> Heap metrics parcelable definition. <code>PoolMetrics.aidl</code> Pool metrics parcelable definition."},{"location":"halif/av_buffer/current/av_buffer/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-av_buffer.service</code> unit file is provided by the vendor layer to start the service and should include\u00a0Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The AV Buffer service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the\u00a0IAVBuffer interface with the Service Manager\u00a0using the String <code>IAVBuffer.serviceName</code> and immediately become operational.</p>"},{"location":"halif/av_buffer/current/av_buffer/#product-customization","title":"Product Customization","text":"<p>AV Buffer provides pools of memory for audio and video decoders, for both compressed and uncompressed data in secure and non-secure forms.</p> <p>The size of the memory pools allocated for the decoders is chosen by the HAL implementation where it is calculated according to the capabilities of the platform decoders, the requirements of the platform and the product requirements.</p> <p>The method of providing secure memory for secure video path and secure audio path is left to the vendor layer to implement, where it can choose the technology best suited for the SoC and platform drivers.\u00a0 All memory buffers are referenced by a handle and a helper library is provided by the vendor layer for the RDK middleware to perform map, unmap and copy operations on the memory buffers.</p>"},{"location":"halif/av_buffer/current/av_buffer/#system-context","title":"System Context","text":"<p>The AV Buffer service provides functionality to multiple clients which exist both inside the RDK middleware and the vendor layer.</p> <p>Applications that stream A/V utilise a GStreamer pipeline in the RDK middleware which understands how to operate the A/V HALs to perform playback.</p> <p>When A/V data flows from the application it gets copied as early as possible into memory buffers allocated from AV Buffer service pools.</p> <p>The video and audio frame pools are managed entirely by the vendor layer, but it is important that any handles representing frame allocations share the same handle space as pool allocations made by applications, so that a handle of any type can be passed to IAVBuffer.free() to be returned to its original pool.</p> <p>Where A/V data frames are encrypted, they are decrypted by the a CDM, which will make a memory buffer allocation from a secure pool (if supported) for the output data.</p> <p></p>"},{"location":"halif/av_buffer/current/av_buffer/#memory-heaps","title":"Memory Heaps","text":"<p>Heaps are blocks of memory managed by the vendor layer that clients can create pools from and are global in the system.</p> <p>Heaps must support the creation of pools by the client which are targeted for use by a specific audio or video decoder instance.</p> <p>Typically a media pipeline client shall create one or more pools from the heaps to make buffer allocations from for audio and video data frames.</p> <p>The platform shall implement 2 heaps which offer secure and non-secure memory.</p> Heap Type Description secureHeap=false The non-secure heap shall be used for audio and video data that is encrypted or does not need to meet secure audio path or secure video path requirements. The heap shall be large enough to handle concurrent decode of all audio and video decoders or the requirements of a given product specification. secureHeap=true The secure heap must be secure SOC memory and cannot be mapped into a non-secure process (i.e. not in any RDK middleware or unprivileged process) and can only be passed by handle between middleware processes. <p>The heap shall be large enough to handle concurrent decode of all audio and video decoders or the requirements of a given product specification.</p> <p>It is mandatory for the AV buffer manager to support both heap types in the APIs but it may report a 0 byte size if a heap is not implemented.</p> <p>The <code>getHeapMetrics()</code> function allows the middleware to interrogate the heap usage data for a specified heap type and it returns a HeapMetrics parcelable with the bytes used out of the bytes total.</p>"},{"location":"halif/av_buffer/current/av_buffer/#memory-pools","title":"Memory Pools","text":"<p>A memory pool is created by a client to make buffer allocations from either the secure or non-secure heap by calling <code>createAudioPool()</code> or <code>createVideoPool()</code>\u00a0with the audio or video resource ID it plans to use if for.</p>"},{"location":"halif/av_buffer/current/av_buffer/#pool-lifecycle","title":"Pool Lifecycle","text":"<p>The size of the memory pool is determined by the vendor layer implementation when the client passes a video or audio resource ID in to <code>createVideoPool()</code> or <code>createAudioPool()</code>.</p> <p>Once a pool is created it is referenced by an Pool handle. When the client has finished with a pool it calls\u00a0destroyPool() with the Pool handle.</p>"},{"location":"halif/av_buffer/current/av_buffer/#pool-handles","title":"Pool Handles","text":"<p>Pool handles are assigned by the AV buffer manager as positive integers (int8_t) and must be globally unique in the system across all heaps and all client connections.</p> <p>The immediate re-use of pool handles after they have been destroyed is discouraged as this could lead to stale pool handles held in the client being used in error and cause unexpected behaviour.</p> <p>The recommended vendor implementation for pool handle assignment is to start at 0 and increment by 1 for each pool allocation made across all of the clients.\u00a0 When pool handle 127 has been allocated, the next handle value can wrap back around to 0 or the next unused pool handle integer value.</p>"},{"location":"halif/av_buffer/current/av_buffer/#pool-implementation-recommendation","title":"Pool Implementation Recommendation","text":"<p>Allocations made from a memory pool for video and audio data shall typically be freed in the same order, but no guarantees are made.</p> <p>It is recommended that the vendor implements a circular buffer for allocations to be made from but allow flexibility in the order of the buffer frees.</p>"},{"location":"halif/av_buffer/current/av_buffer/#av-buffers","title":"AV Buffers","text":"<p>AV buffers are allocated by the client to typically hold a frame of audio or video data.\u00a0 The data may be coded, decoded, encrypted or in the clear, but the AV Buffer Manager has no understanding of the data contents.</p> <p>Only AV buffers that are allocated from a pool created from the non-secure heap can be directly mapped inside an RDK middleware client process for read-write access.\u00a0\u00a0</p>"},{"location":"halif/av_buffer/current/av_buffer/#buffer-lifecycle","title":"Buffer Lifecycle","text":"<p>A client can allocate a new AV buffer from a pool by calling the <code>IAVBuffer.alloc()</code> function with the Pool handle to allocate from and the buffer size.</p> <p>On success, the buffer is returned to the client as an integer handle (int64_t) which must be globally unique in the system across all pools and all client connections.</p> <p>The client can pass ownership of the AV buffer handle to a HAL component (e.g. <code>IAudioDecoderController.decodeBuffer()</code> or <code>IAudioSinkController.queueAudioFrame()</code>) where it will eventually be freed otherwise it must call <code>IAVBuffer.free()</code> itself.</p> <p>If a HAL component (e.g. a decoder or sink) has finished with a buffer that it has taken ownership of then it must be freed and the buffer is returned to its original pool.\u00a0 This can be achieved by calling the public HAL API <code>IAVBuffer.free()</code> or by a private internal call inside the vendor layer which has the same effect.</p> <p>It is important that buffer allocations can be allocated and freed through any client session connection with the AV Buffer Manager service and not restricted to a single client session.</p>"},{"location":"halif/av_buffer/current/av_buffer/#buffer-handles","title":"Buffer Handles","text":"<p>Similar to pool handles, the immediate re-use of AV buffer handles after they have been freed is discouraged as this could lead to stale AV buffer handles held in the client being used in error and cause unexpected behaviour.</p>"},{"location":"halif/av_buffer/current/av_buffer/#handling-out-of-memory-conditions","title":"Handling Out of Memory Conditions","text":"<p>Pools have finite memory resources to allocate from and when its limits are reached it will return an out of memory status on <code>IAVBuffer.alloc()</code> requests.</p> <p>The client can request to be notified when enough space or resources become available for an allocation of a specific size from a pool by calling <code>notifyWhenSpaceAvailable()</code>.</p> <p>The AV Buffer Manager shall make a callback to <code>onSpaceAvailable()</code> on the <code>IAVBufferSpaceListener</code> interface passed in the <code>createAudioPool()</code> or <code>createVideoPool()</code> call when the pool was created.</p> <p>The client must guarantee that its <code>IAVBufferSpaceListener</code> interface instance remains available for the lifetime of the memory pool it was intended for and can only be destroyed after the related <code>destroyPool()</code> call has returned.</p>"},{"location":"halif/av_buffer/current/av_buffer/#audio-video-frame-pools","title":"Audio &amp; Video Frame Pools","text":"<p>The audio and video frame pools are allocated from privately inside the vendor layer by the audio and video decoders.</p> <p>In tunnelled mode the frame buffer allocations are automatically freed when they are no longer needed by the downstream AV pipeline vendor components.</p> <p>In non-tunnelled mode the client is passed these handles back from the decoder and may still be in possession of them when an AV pipeline is being stopped or flushed. In this case the client must free the frame buffer handles by calling IAVBuffer.free().</p>"},{"location":"halif/av_buffer/current/av_buffer/#media-pipeline-example","title":"Media Pipeline Example","text":"<p>The sequence diagram below provides an example of a secure media pipeline implementation.</p> <p>The AppSource is delivered encrypted audio and video frames and it creates 2 non-secure memory pools for these types of frames.</p> <p>The CDM is handed the non-secure encrypted audio and video frame buffers and decrypts them into secure buffers of the same size. \u00a0It uses 2 secure memory pools for audio and video decrypted frames.</p> <p>After the media pipeline has a secure buffer decoded by an audio or video decoder it can free the buffer.</p> <p>Note: The diagram below does not show how multiple audio and video buffers may be allocated at once, to allow for buffering points along the media pipeline.</p> <pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GStreamer Pipeline\n        participant c1 as AppSource\n        participant c2 as CDM\n        participant adc as AudioDecoder\n        participant vdc as VideoDecoder\n    end\n\n    box rgb(249,168,37) AV Buffer Service\n        participant avbm as IAVBuffer\n    end\n\n    box rgb(67,160,71) AV Buffer Helper Library\n        participant avblib as libavbufferhelper.so\n    end\n\n    box Service Manager\n        participant sm as Service Manager\n    end\n\n    c1 -&gt;&gt; sm: getService(IAVBuffer.serviceName)\n\n    Note over c1: AppSource in media pipeline&lt;br/&gt;creates non-secure pools for &lt;br/&gt;encrypted A/V data frames.\n\n    c1 -&gt;&gt; avbm: nonsec-pool-audio = createAudioPool(false, IVideoAudioDecoder.Id=0, spaceListener)\n    c1 -&gt;&gt; avbm: nonsec-pool-video = createVideoPool(false, IVideoVideoDecoder.Id=0, spaceListener)\n\n    Note over c1: Create secure pools&lt;br/&gt;for decrypted A/V data frames.\n\n    c1 -&gt;&gt; avbm: sec-pool-audio = createAudioPool(true, IVideoAudioDecoder.Id=0, spaceListener)\n    c1 -&gt;&gt; avbm: sec-pool-video = createVideoPool(true, IVideoVideoDecoder.Id=0, spaceListener)\n\n    loop while media pipeline is playing\n        Note over c1: Encrypted A/V frames are &lt;br/&gt;loaded into AV buffers.\n\n        Note over c1: Process new audio frame\n        c1 -&gt;&gt; avbm: nonsec-a-handle = alloc(nonsec-pool-audio, audiodata-size)\n        c1 -&gt;&gt; avblib: mapHandle(nonsec-a-handle, &amp;ptr)\n        c1 -&gt;&gt; c1: memcpy(ptr, audiodata, audiodata-size)\n        c1 -&gt;&gt; avblib: unmapHandle(nonsec-a-handle, ptr)\n\n        c1 -&gt;&gt; c2: nonsec-a-handle\n        c2 -&gt;&gt; avbm: sec-a-handle = alloc(sec-pool-audio, audiodata-size)\n        c2 -&gt;&gt; c2: decrypt(sec-a-handle, nonsec-a-handle, audiodata-size)\n        c2 -&gt;&gt; avbm: free(nonsec-a-handle)\n        c2 -&gt;&gt; adc: sec-a-handle\n        adc -&gt;&gt; adc: decodeBuffer(sec-a-handle)\n        adc -&gt;&gt; avbm: free(sec-a-handle)\n\n        Note over c1: Process new video frame\n        c1 -&gt;&gt; avbm: nonsec-v-handle = alloc(nonsec-pool-video, videodata-size)\n        c1 -&gt;&gt; avblib: mapHandle(nonsec-v-handle, &amp;ptr)\n        c1 -&gt;&gt; c1: memcpy(ptr, videodata, videodata-size)\n        c1 -&gt;&gt; avblib: unmapHandle(nonsec-v-handle, ptr)\n        c1 -&gt;&gt; c2: nonsec-v-handle\n\n        c2 -&gt;&gt; avbm: sec-v-handle = alloc(sec-pool-video, videodata-size)\n        c2 -&gt;&gt; c2: decrypt(sec-v-handle, nonsec-v-handle, videodata-size)\n        c2 -&gt;&gt; avbm: free(nonsec-v-handle)\n        c2 -&gt;&gt; vdc: sec-v-handle\n        vdc -&gt;&gt; vdc: decodeBuffer(sec-v-handle)\n        vdc -&gt;&gt; avbm: free(sec-v-handle)\n    end\n\n    Note over c1: When pipeline has finished, the client cleans up&lt;br/&gt;Any buffers held in the media pipeline or in HAL services are freed&lt;br/&gt;Then the pools are destroyed.\n\n    c1 -&gt;&gt; avbm: destroyPool(sec-pool-audio)\n    c1 -&gt;&gt; avbm: destroyPool(sec-pool-video)\n    c1 -&gt;&gt; avbm: destroyPool(nonsec-pool-audio)\n    c1 -&gt;&gt; avbm: destroyPool(nonsec-pool-video)</code></pre>"},{"location":"halif/av_buffer/current/av_buffer/#fragmentation-in-memory-pools","title":"Fragmentation in Memory Pools","text":"<p>There is no guarantee that the IAVBuffer.alloc() and IAVBuffer.free() calls for a pool are in the same order, so the vendor implementation must allow for out-of-order free() calls to be made.</p> <p>The table below shows an example sequence of calls made to allocate and free 3 buffers in an order that should be supported by the AV Buffer Manager service.</p> # Buffer 1 Buffer 2 Buffer 3 1 alloc() 2 alloc() 3 free() 4 alloc() 5 free() 6 free()"},{"location":"halif/av_buffer/current/av_buffer/#buffer-trimming-for-broadcast-sources","title":"Buffer Trimming for Broadcast Sources","text":"<p>MPEG-2 transport stream broadcast sources may load frames progressively as data emerges from TS packet filters and PES filters.</p> <p>For this reason an oversized buffer may be allocated for the incoming audio or video data and once the frame boundary has been determined the buffer is trimmed to its actual size.</p> <p>Only the last allocated memory buffer is capable of being trimmed, which helps manage the pool memory in a circular buffer.</p>"},{"location":"halif/av_buffer/current/av_buffer/#memory-mapping-in-processes","title":"Memory Mapping in Processes","text":"<p>The non-secure shared memory buffers must be mapped inside processes so they can be access for read/write operations.</p> <p>Mapping provides a local process pointer to the memory which cannot be meaningfully shared across processes.</p> <p>The <code>mapHandle()</code> and <code>unmapHandle()</code> functions are provided by a library to provide process-local mapping.</p>"},{"location":"halif/av_buffer/current/av_buffer/#buffer-mapping-helper-library-libavbufferhelperso","title":"Buffer Mapping Helper Library - libavbufferhelper.so","text":"<p>The libavbufferhelper.so user space library is provided by the vendor layer to perform memory mapping/unmapping and copy operations on non-secure AV buffers.</p> <p>RDK middleware processes use the API to copy data into AV buffers represented by a handle.</p> <p>The library <code>mapHandle()</code> function is used to map a non-secure AV buffer handle into a concrete process mapped pointer which allows for data read/write access.</p> <p>The library <code>unmapHandle()</code> function is used to unmap a non-secure AV buffer handle and pointer pair.</p> <p>The library <code>write()</code> function is used to write data from system memory to buffer and works for both secure or non-secure AV buffers.</p> <p>The library <code>copyWithMap()</code> function is used to copy one or more ranges of byte from a source buffer to a destination buffer and works for both secure or non-secure AV buffers.</p> <p>Hint</p> <p>When mapping non-secure handles there is an possible optimisation to map the entire pool space into the process space only once on the first call and subsequent calls to <code>mapHandle()</code> simply provide an offset into the mapped memory.</p>"},{"location":"halif/av_clock/current/av_clock/","title":"AV Clock","text":"<p>The AV Clock HAL service establishes synchronization between audio and video sinks, enabling lip-sync playback by driving them from a shared clock.</p> <p>In broadcast scenarios, the Program Clock Reference (PCR) is provided to the AV Clock HAL. This allows the local System Time Clock (STC) to be synchronized with the broadcast encoder's timing, crucial for preventing buffer underflow or overflow.</p> <p>For IP streaming, clients can manipulate the playback rate, facilitating pause functionality and fine-grained adjustments for clock synchronization with other devices or streams.</p> <p>Audio and video sinks associated with a given AV Clock instance comprise a synchronization group.  Members of a sync group share a common presentation clock.  The AV Clock HAL provides an interface for the application to define the composition of these sync groups, specifying the video sink and the associated audio sink(s).</p>"},{"location":"halif/av_clock/current/av_clock/#references","title":"References","text":"<p>Info</p> Interface Definition av_clock/current API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-av_clock.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/av_clock/current/av_clock/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Audio Sink</li> <li>Video Sink</li> <li>Plane Control</li> </ul>"},{"location":"halif/av_clock/current/av_clock/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.AVCLOCK.1 A single client-server session shall manage a single AV clock instance and sync group. HAL.AVCLOCK.2 Multiple AV clocks may operate concurrently. HAL.AVCLOCK.3 Broadcast PCR samples shall be provided by the client to drive the AV clock instance in PCR mode. HAL.AVCLOCK.4 PCR samples are based on a 27MHz clock from the MPEG standard but delivered in nanosecond units. HAL.AVCLOCK.5 PCR samples can start at any value, contain discontinuities and may wrap according to broadcast encoding rules. HAL.AVCLOCK.6 An AV clock shall support audio with video, video only or audio only. HAL.AVCLOCK.7 Supplementary audio (e.g. audio description) shall be supported in addition to a main audio. HAL.AVCLOCK.8 For non-PCR driven playback, the playback rate shall be adjustable between 0.0 and 2.0, where 0 is paused and 1.0 is normal speed. YouTube requirement is to play between 0.5 and 2.0 with pitch correction. HAL.AVCLOCK.9 A client shall be able to read the current AV clock time. For PCR mode. It should return the \"invalid\" value until the first PCR is received. HAL.AVCLOCK.10 If a client process exits, the AV Clock server shall automatically stop and close any AV Clock instance controlled by that client."},{"location":"halif/av_clock/current/av_clock/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IAVClockManager.aidl</code> AV Clock Manager HAL interface which provides access to IAVClock resource instances. <code>IAVClock.aidl</code> AV Clock HAL interface for a single AV Clock resource instance. <code>IAVClockController.aidl</code> Controller interface for an IAVClock resource instance. <code>IAVClockControllerListener.aidl</code> Listener callbacks interface to clients from an IAVClockController. <code>IAVClockEventListener.aidl</code> Listener callbacks interface to clients from an IAVClock. <code>Capabilities.aidl</code> Parcelable describing the capabilities of an IAVClock resource instance. <code>ClockMode.aidl</code> Enum list of clock modes. <code>ClockTime.aidl</code> Parcelable holding a clock time. <code>Property.aidl</code> Enum list of AV Clock properties."},{"location":"halif/av_clock/current/av_clock/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-av_clock_manager.service</code> unit file is provided by the vendor layer to start the service and should include Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The AV Clock Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the <code>IAVClockManager</code> interface with the Service Manager using the String <code>IAVClockManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/av_clock/current/av_clock/#product-customization","title":"Product Customization","text":"<p>The <code>IAVClockManager.getAVClockIds()</code> should return an array of <code>IAVClock.Id</code> parcelables to uniquely represent all of the AV Clock resources supported by the vendor layer. Typically, the ID value starts at 0 for the first AV Clock and increments by 1 for each additional AV Clock.</p> <p>The <code>Capabilities</code> parcelable returned by the <code>IAVClock.getCapabilities()</code> function lists the capabilities of a specific AV Clock resource instance.</p>"},{"location":"halif/av_clock/current/av_clock/#system-context","title":"System Context","text":"<p>The AV Clock service provides functionality to multiple clients inside the RDK middleware.</p> <p>An AV Clock is used to time the delivery of video frames and audio samples from an AV pipeline as a sync group that share a common timebase and reference clock.</p> <p>It can also operate in a video-only or audio-only mode.</p> <p>Each AV pipeline utilises its own instance of an AV clock which operates independently of any other AV clock instance.</p> <p>Clients can access their AV clock time by calling <code>getCurrentClockTime()</code> to synchronise data streams such as closed captions and subtitles.</p> <p>The AV clock is always linked to the timebase source it has been configured to use (PCR, audio master or video master).</p> <p>A PCR driven AV clock may wrap or jump at PCR discontinuities.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IAVClockEventListener(\"IAVClockEventListener\")\n        IAVClockControllerListener(\"IAVClockControllerListener\")\n    end\n    subgraph IAVClockHAL[\"Audio Clock HAL\"]\n        IAVClockManager(\"IAVClockManager &lt;br&gt;(Service)\")\n        IAVClock(\"IAVClock &lt;br&gt;(Instance)\")\n        IAVClockController(\"IAVClockController &lt;br&gt;(Instance)\")\n    end\n    subgraph SyncGroup[\"Sync Group\"]\n        AudioFrameQueue(\"Audio Frame Queue\")\n        VideoFrameQueue(\"Video Frame Queue\")\n    end\n      platformAVSync(\"Platform AV Sync\")\n    RDKClientComponent -- getIAVClockIds() &lt;br&gt; getIAVClock() --&gt; IAVClockManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getProperty() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() &lt;br&gt; registerEventListener() &lt;br&gt; unregisterEventListener() --&gt; IAVClock\n    RDKClientComponent -- setAudioSink() &lt;br&gt; getAudioSink() setSupplementaryAudioSink() setSupplementaryAudioSink() &lt;br&gt; setVideoSink() &lt;br&gt; getVideoSink() &lt;br&gt; start() &lt;br&gt; stop() &lt;br&gt; setClockMode() &lt;br&gt; getClockMode() &lt;br&gt; notifyPCRSample() &lt;br&gt; getCurrentClockTime() &lt;br&gt; setPlaybackRate() &lt;br&gt; getPlaybackRate() --&gt; IAVClockController\n    IAVClockManager --&gt; IAVClock --&gt; IAVClockController\n    IAVClock -- onStateChanged() --&gt; IAVClockEventListener\n    IAVClockController -- onStateChanged() --&gt; IAVClockControllerListener\n    IAVClockEventListener --&gt; RDKClientComponent\n    IAVClockControllerListener --&gt; RDKClientComponent\n    IAVClockController --&gt; platformAVSync\n    %% Sync Group\n    AudioFrameQueue --&gt; platformAVSync\n    VideoFrameQueue --&gt; platformAVSync\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IAVClockManager:::wheat\n    IAVClockController:::wheat\n    IAVClock:::wheat\n    IAVClockControllerListener:::wheat\n    IAVClockEventListener:::wheat\n    platformAVSync:::green\n    AudioFrameQueue:::green\n    VideoFrameQueue:::green</code></pre>"},{"location":"halif/av_clock/current/av_clock/#resource-management","title":"Resource Management","text":"<p>The <code>IAVClockManager</code> provides access to one or more <code>IAVClock</code> sub-interfaces which each represent an AV Clock resource instance offered by the platform.</p> <p>Each <code>IAVClock</code> resource instance is assigned a unique integer ID, which is used in <code>IAVClock.Id.value</code> and can be read from <code>RESOURCE_ID</code> using the <code>IAVClock.getProperty()</code> function.</p> <p>To use an <code>IAVClock</code> resource instance it must be opened by a client, which returns an <code>IAVClockController</code> sub-interface to access clock modes, clock time, the PCR sample notification function and playback rate control.</p> <p>Important</p> <p>Any number of clients can access the <code>IAVClockManager</code> service and get access to the <code>IAVClock</code> sub-interfaces, but only 1 client can <code>open()</code> an <code>IAVClock</code> and access its <code>IAVClockController</code> sub-interface.</p> <p>The diagram below shows the relationship between the interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"AV Clock Manager HAL\" ---\n    IAVClockManager(\"IAVClockManager\")\n\n    %% --- AV Clock Manager Service Spawns Instances ---\n    IAVClockManager --&gt; ADI1(\"IAVClock &lt;br&gt; ID = 0\")\n    IAVClockManager --&gt; ADI2(\"IAVClock &lt;br&gt; ID = 1\")\n    IAVClockManager --&gt; ADI3(\"IAVClock &lt;br&gt; ID = 2\")\n\n    %% --- Each Instance Has a Controller ---\n    ADI1 --&gt; ADIC1(\"IAVClockController\")\n    ADI2 --&gt; ADIC2(\"IAVClockController\")\n    ADI3 --&gt; ADIC3(\"IAVClockController\")\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n    %% --- Apply Colors ---\n    class IAVClockManager manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/av_clock/current/av_clock/#av-sources-and-sync-groups","title":"AV Sources and Sync Groups","text":"<p>There can be at most 1 Video Sink source and at most 2 Audio Sink sources linked by an AV Clock session in a sync group.</p> <p>The second Audio Sink is intended for supplementary audio where receiver side mixing is required. </p> <p>See https://www.etsi.org/deliver/etsi_en/300400_300499/300468/01.16.01_20/en_300468v011601a.pdf Annex J.</p> <p>The client calls the <code>setAudioSink()</code>, <code>setSupplementaryAudioSink()</code> and <code>setVideoSink()</code> APIs to link audio and video sink instances as a sync group to the AV Clock session.</p> <p>The AV Clock is required for video decoders/sinks operating in tunnelled, non-tunnelled and/or video texture modes.</p> <p>Where a HDMI or composite video source is being tunnelled, no AV clock is utilised.</p>"},{"location":"halif/av_clock/current/av_clock/#clock-modes","title":"Clock Modes","text":"<p>The enum <code>ClockMode</code> provides constants used to specify the mode for the AV clock in calls to <code>setClockMode()</code>.</p> <p>Audio and video master modes are expected to be used in special low latency use cases (e.g. Apple AirPlay, Miracast).</p> enum ClockMode Description AUTO Auto will use AUDIO_MASTER if there is an audio sink linked otherwise VIDEO_MASTER. AUTO is the default clock mode. PCR Use PCR samples as the clock source as provided in successive calls to <code>notifyPCRSample()</code>. PCR mode can only be used on live broadcasts and calls to <code>setPlaybackRate()</code> are not allowed. The AV Clock time is phase locked to the incoming PCR sample values. AUDIO_MASTER Use an audio sink as the clock master. The AV Clock time is crash locked to the first audio sample PTS received for playback. The AV Clock timebase is linked to the audio subsystem clock of the platform. VIDEO_MASTER Use the video sink source as the clock master. The AV Clock time is crash locked to the first video frame PTS received for playback. The AV Clock timebase is driven by the vendor implementation."},{"location":"halif/av_clock/current/av_clock/#mpeg-2-transport-stream-broadcast-timing-with-pcr-clock-mode","title":"MPEG-2 Transport Stream Broadcast Timing with PCR Clock Mode","text":"<p>The MPEG standard defines 4 timing references in the standard.</p> Timing Reference Description System time clock (STC) The STC is a common system clock that is used to time the decode and presentation of elementary audio and video streams. Program clock reference (PCR) The PCR is a sample of the STC delivered in the MPEG-2 transport stream which the decoder should use to regenerate the STC locally. Decode timestamp (DTS) The DTS specifies the time at which an audio or video segment should be passed to the decoder, ahead of presentation. Presentation timestamp (PTS) The PTS specifies the time at which a decoded audio or video segment should be presented. <p>The conceptual diagram below shows how the timing information is used in a typical broadcast setup for video.</p> <p></p>"},{"location":"halif/av_clock/current/av_clock/#pcr-clock-recovery","title":"PCR Clock Recovery","text":"<p>The PCR clock recovery starts in the RDK middleware by filtering the PCR from the adaptation field in the MPEG-2 transport stream and immediately creating a local timestamp using the <code>CLOCK_MONOTONIC_RAW</code> clock to record the reception time.</p> <p>For details of the PCR encoding in adaptation fields see ISO/IEC13818-1 Generic coding of moving pictures and associated audio information Part 1: Systems</p> <p><code>CLOCK_MONOTONIC_RAW</code> is used because it is guaranteed to be driven by the local oscillator and not susceptible to NTP adjustments as <code>CLOCK_MONOTONIC</code> is.</p> <p>For details on <code>CLOCK_MONOTONIC_RAW</code> see https://man7.org/linux/man-pages/man2/clock_gettime.2.html</p> <p>The PCR filtered from the adaptation field is converted to nanoseconds before being passed with the local <code>CLOCK_MONOTONIC_RAW</code> timestamp to the <code>notifyPCRSample()</code> HAL API. This extra local timestamp is made to allow the recovery algorithm to compensate for jitter in the stream and filtering processes.</p> <p>The AV Clock is then responsible for using the PCR samples to drive the clock used for AV sync and presentation.</p> <p>If there are no PCR samples available in the stream, it is the RDK middleware media player responsibility to change the ClockMode.</p> <p>Note that the PCR is passed in nanoseconds to match the timebase units across all other RDK-E HAL components.</p> <p>Broadcast stream sources are subject to behaviors unique to broadcast environments which are covered in the table below, with implementation guidelines.</p> PCR Behavior Description Implementation Guidelines Signal loss Signal and data loss where multiple PCR samples may be lost and cannot be reported through <code>notifyPCRSample()</code>. On gaps in the PCR delivery, it is expected that the vendor implementation continues to advance the STC at its latest calculated rate. Data corruption Data corruption where the PCR sample reported through <code>notifyPCRSample()</code> may contain a bad PCR time. The vendor implementation is responsible for determining that a single value is corrupt and not a discontinuity. After a few samples it can be detected that is it a true discontinuity. PCR discontinuities Planned PCR discontinuities in the broadcast where the PCR sample value may jump unexpectedly. Same as above. Test streams Broadcast test stream playout wrapping where the PCR sample value may jump unexpectedly back to an earlier value as the test stream loops. Same as above. PCR wrap PCR value wrapping where the encoded bits for PCR can no longer increment the value and it needs to wrap around to 0. Wraps occur approximately every 26.5 hours if the PCR is incrementing continuously. A wrap can be treated in the same way as a normal discontinuity. The vendor implement shall perform perfect AV presentation across the PCR wrap, without audio or video jitter or artefacts. <p>Todo</p> <ul> <li>Define free-running mode when PCR and PTS are far apart.</li> <li>What is the AV sync behaviour we need to define?</li> </ul> <p>In all of these cases the AV Clock is responsible for handling these scenarios by relocking the STC clock on a new set of stable PCR clock values.</p> <p>The vendor implementation should fall back to a free-running mode if the difference between the PTS and STC becomes too large to facilitate proper decoding of audio and video. This will be required in many of the cases listed above. For instance, we need smooth decoding until the PCR matches the PTS again after a stream is wrapping.</p>"},{"location":"halif/av_clock/current/av_clock/#extracting-the-broadcast-stc-from-av-clock","title":"Extracting the Broadcast STC from AV Clock","text":"<p>The AV Clock time is a mirror of the MPEG STC clock but in different units.</p> <p>The pseudo code below shows how an application would can accurately access the STC clock time in 90kHz timebase:</p> <pre><code>ClockTime clockTime;\nlong long localTimeNs;\nlong long correctedClockTimeNs;\nstruct timespec monoRawTime;\n\n// Get the AV clock time.\npAVClock-&gt;getCurrentClockTime(&amp;clockTime);\n\n// Get the system monotonic raw clock time 'now' in nanoseconds.\nclock_gettime(CLOCK_MONOTONIC_RAW, &amp;monoRawTime);\nlocalTimeNs = monoRawTime.tv_sec * 1000000000LL;\nlocalTimeNs += monoRawTime.tv_nsec;\n\n// Correct the AV clock time to 'now' local time.\ncorrectedClockTimeNs = clockTime.clockTime + (localTimeNs - clockTime.sampleTimestamp);\n\n// Convert to 90kHz timebase.\nSTC90kHz = (correctedClockTimeNs * 90000LL) / 1000000000LL;\n</code></pre>"},{"location":"halif/av_clock/current/av_clock/#playback-rate","title":"Playback Rate","text":"<p>The playback rate can be set between 0.0 &lt;= rate &lt;= 2.0 by calling <code>setPlaybackRate()</code>, to support a range of common playback speeds used by applications.</p> <p>Some applications may dynamically adjust the playback rate during playback either in response to a customer setting (e.g. YouTube playback speed x1.75) or for playback synchronisation.</p> <p>A playback rate of 0.0 indicates a paused state and the last displayed video frame should be held on the video plane and audio playback should similarly be paused. While paused the AV clock holds its current time value.</p> <p>Playback rates between 0.5 and 2.0 shall perform audio pitch correction to match the audio playback pitch at speed 1.0. Audio should be muted when the playback speed is &lt; 0.5.</p> <p>Live broadcasts which are driven by a PCR clock source cannot support playback rate changes and any attempt to call <code>setPlaybackRate()</code> results in an error.</p>"},{"location":"halif/av_clock/current/av_clock/#av-clock-usage","title":"AV Clock Usage","text":"<p>The sequence diagram below show typical use cases for AV Clock.</p>"},{"location":"halif/av_clock/current/av_clock/#session-for-av-playback-over-ip","title":"Session for AV Playback over IP","text":"<pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GST Pipeline\n      participant Client as RDK Client\n      participant Listener as IAVClockControllerListener\n    end\n    box rgb(249,168,37) AVClock HAL\n      participant CLKMAN as IAVClockManager\n      participant CLK as IAVClock\n      participant CTRL as IAVClockController\n    end\n\n    Client-&gt;&gt;CLKMAN: getAVClock(0)\n    Client-&gt;&gt;CLK: open(IAVClockControllerListener)\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSED, OPENING)\n    CLK-&gt;&gt;CTRL: create\n    activate CTRL\n    CLK--&gt;&gt;Listener: onStateChanged(OPENING, READY)\n    CLK--&gt;&gt;Client: IAVClockController\n    note over CLK: Default clock mode is AUTO\\nwhen session is opened.\n    Client-&gt;&gt;CTRL: setAudioSink(0)\n    Client-&gt;&gt;CTRL: setVideoSink(0)\n    Client-&gt;&gt;CTRL: start()\n    CLK--&gt;&gt;Listener: onStateChanged(READY, STARTING)\n    CLK--&gt;&gt;Listener: onStateChanged(STARTING, STARTED)\n    loop while playback continues\n      Client-&gt;&gt;CTRL: getCurrentClockTime()\n    end\n    Client-&gt;&gt;CTRL: stop()\n    CLK--&gt;&gt;Listener: onStateChanged(STARTED, STOPPING)\n    CLK--&gt;&gt;Listener: onStateChanged(STOPPING, READY)\n    Client-&gt;&gt;CLK: close(IAVClockController)\n    CLK--&gt;&gt;Listener: onStateChanged(READY, CLOSING)\n    CLK-&gt;&gt;CTRL: destroy\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSING, CLOSED)</code></pre>"},{"location":"halif/av_clock/current/av_clock/#session-for-radio-playback-over-ip","title":"Session for Radio Playback over IP","text":"<pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GST Pipeline\n      participant Client as RDK Client\n      participant Listener as IAVClockControllerListener\n    end\n    box rgb(249,168,37) AVClock HAL\n      participant CLKMAN as IAVClockManager\n      participant CLK as IAVClock\n      participant CTRL as IAVClockController\n    end\n\n    Client-&gt;&gt;CLKMAN: getAVClock(0)\n    Client-&gt;&gt;CLK: open(IAVClockControllerListener)\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSED, OPENING)\n    CLK-&gt;&gt;CTRL: create\n    activate CTRL\n    CLK--&gt;&gt;Listener: onStateChanged(OPENING, READY)\n    CLK--&gt;&gt;Client: IAVClockController\n    note over CLK: Default clock mode is AUTO\\nwhen session is opened.\n    Client-&gt;&gt;CTRL: setAudioSink(0)\n    Client-&gt;&gt;CTRL: start()\n    CLK--&gt;&gt;Listener: onStateChanged(READY, STARTING)\n    CLK--&gt;&gt;Listener: onStateChanged(STARTING, STARTED)\n    loop while playback continues\n      Client-&gt;&gt;CTRL: getCurrentClockTime()\n    end\n    Client-&gt;&gt;CTRL: stop()\n    CLK--&gt;&gt;Listener: onStateChanged(STARTED, STOPPING)\n    CLK--&gt;&gt;Listener: onStateChanged(STOPPING, READY)\n    Client-&gt;&gt;CLK: close(IAVClockController)\n    CLK--&gt;&gt;Listener: onStateChanged(READY, CLOSING)\n    CLK-&gt;&gt;CTRL: destroy\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSING, CLOSED)</code></pre>"},{"location":"halif/av_clock/current/av_clock/#session-for-av-playback-over-broadcast","title":"Session for AV Playback over Broadcast","text":"<pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GST Pipeline\n      participant Client as RDK Client\n      participant Listener as IAVClockControllerListener\n    end\n    box rgb(249,168,37) AVClock HAL\n      participant CLKMAN as IAVClockManager\n      participant CLK as IAVClock\n      participant CTRL as IAVClockController\n    end\n\n    Client-&gt;&gt;CLKMAN: getAVClock(0)\n    Client-&gt;&gt;CLK: open(IAVClockControllerListener)\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSED, OPENING)\n    CLK-&gt;&gt;CTRL: create\n    activate CTRL\n    CLK--&gt;&gt;Listener: onStateChanged(OPENING, READY)\n    CLK--&gt;&gt;Client: IAVClockController\n    note over CLK: Default clock mode is AUTO\\nwhen session is opened.\n    Client-&gt;&gt;CTRL: setClockMode(PCR)\n    Client-&gt;&gt;CTRL: setAudioSink(0)\n    Client-&gt;&gt;CTRL: setVideoSink(0)\n    Client-&gt;&gt;CTRL: start()\n    CLK--&gt;&gt;Listener: onStateChanged(READY, STARTING)\n    CLK--&gt;&gt;Listener: onStateChanged(STARTING, STARTED)\n    loop while playback continues\n      note over Client: As PCR is filtered, it is delivered to AV Clock.\n      Client-&gt;&gt;CTRL: notifyPCRSample()\n      note over Client: Periodically, we get clock time for use in subtitle sync with video.\n      Client-&gt;&gt;CTRL: getCurrentClockTime()\n    end\n    Client-&gt;&gt;CTRL: stop()\n    CLK--&gt;&gt;Listener: onStateChanged(STARTED, STOPPING)\n    CLK--&gt;&gt;Listener: onStateChanged(STOPPING, READY)\n    Client-&gt;&gt;CLK: close(IAVClockController)\n    CLK--&gt;&gt;Listener: onStateChanged(READY, CLOSING)\n    CLK-&gt;&gt;CTRL: destroy\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSING, CLOSED)</code></pre>"},{"location":"halif/av_clock/current/av_clock/#session-for-av-playback-with-supplementary-audio-over-broadcast","title":"Session for AV Playback with Supplementary Audio over Broadcast","text":"<pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GST Pipeline\n      participant Client as RDK Client\n      participant Listener as IAVClockControllerListener\n    end\n    box rgb(249,168,37) AVClock HAL\n      participant CLKMAN as IAVClockManager\n      participant CLK as IAVClock\n      participant CTRL as IAVClockController\n    end\n\n    Client-&gt;&gt;CLKMAN: getAVClock(0)\n    Client-&gt;&gt;CLK: open(IAVClockControllerListener)\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSED, OPENING)\n    CLK-&gt;&gt;CTRL: create\n    activate CTRL\n    CLK--&gt;&gt;Listener: onStateChanged(OPENING, READY)\n    CLK--&gt;&gt;Client: IAVClockController\n    note over CLK: Default clock mode is AUTO\\nwhen session is opened.\n    Client-&gt;&gt;CTRL: setClockMode(PCR)\n    Client-&gt;&gt;CTRL: setAudioSink(0)\n    Client-&gt;&gt;CTRL: setSupplementaryAudioSink(1)\n    Client-&gt;&gt;CTRL: setVideoSink(0)\n    Client-&gt;&gt;CTRL: start()\n    CLK--&gt;&gt;Listener: onStateChanged(READY, STARTING)\n    CLK--&gt;&gt;Listener: onStateChanged(STARTING, STARTED)\n    loop while playback continues\n      note over Client: As PCR is filtered, it is delivered to AV Clock.\n      Client-&gt;&gt;CTRL: notifyPCRSample()\n      note over Client: Periodically, we get clock time for use in subtitle sync with video.\n      Client-&gt;&gt;CTRL: getCurrentClockTime()\n    end\n    Client-&gt;&gt;CTRL: stop()\n    CLK--&gt;&gt;Listener: onStateChanged(STARTED, STOPPING)\n    CLK--&gt;&gt;Listener: onStateChanged(STOPPING, READY)\n    Client-&gt;&gt;CLK: close(IAVClockController)\n    CLK--&gt;&gt;Listener: onStateChanged(READY, CLOSING)\n    CLK-&gt;&gt;CTRL: destroy\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSING, CLOSED)</code></pre>"},{"location":"halif/av_clock/current/av_clock/#session-for-av-playback-over-ip-with-rate-control","title":"Session for AV Playback over IP with Rate Control","text":"<pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK GST Pipeline\n      participant Client as RDK Client\n      participant Listener as IAVClockControllerListener\n    end\n\n    box rgb(249,168,37) AVClock HAL\n      participant CLKMAN as IAVClockManager\n      participant CLK as IAVClock\n      participant CTRL as IAVClockController\n    end\n\n    Client-&gt;&gt;CLKMAN: getAVClock(0)\n    Client-&gt;&gt;CLK: open(IAVClockControllerListener)\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSED, OPENING)\n    CLK-&gt;&gt;CTRL: create\n    activate CTRL\n    CLK--&gt;&gt;Listener: onStateChanged(OPENING, READY)\n    CLK--&gt;&gt;Client: IAVClockController\n    note over CLK: Default clock mode is AUTO\\nwhen session is opened.\n    Client-&gt;&gt;CTRL: setAudioSink(0)\n    Client-&gt;&gt;CTRL: setVideoSink(0)\n    Client-&gt;&gt;CTRL: start()\n    CLK--&gt;&gt;Listener: onStateChanged(READY, STARTING)\n    CLK--&gt;&gt;Listener: onStateChanged(STARTING, STARTED)\n    note over Client: Playback starts in paused state.\n    Client-&gt;&gt;CTRL: setPlaybackRate(0.0)\n    note over Client: AV data is buffered.\n    note over Client: Change playback rate to 1.0 to start playback.\n    Client-&gt;&gt;CTRL: setPlaybackRate(1.0)\n    note over Client: Change playback rate to 2.0 after some time.\n    Client-&gt;&gt;CTRL: setPlaybackRate(2.0)\n    Client-&gt;&gt;CTRL: stop()\n    CLK--&gt;&gt;Listener: onStateChanged(STARTED, STOPPING)\n    CLK--&gt;&gt;Listener: onStateChanged(STOPPING, READY)\n    Client-&gt;&gt;CLK: close(IAVClockController)\n    CLK--&gt;&gt;Listener: onStateChanged(READY, CLOSING)\n    CLK-&gt;&gt;CTRL: destroy\n    CLK--&gt;&gt;Listener: onStateChanged(CLOSING, CLOSED)</code></pre>"},{"location":"halif/boot/current/boot/","title":"Boot","text":""},{"location":"halif/boot/current/boot/#references","title":"References","text":"<p>Info</p> Interface Definition boot/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-boot.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/boot/current/boot/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/broadcast/current/broadcast/","title":"Broadcast","text":""},{"location":"halif/broadcast/current/broadcast/#references","title":"References","text":"<p>Info</p> Interface Definition broadcast/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-broadcast.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/broadcast/current/broadcast/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/broadcast/current/broadcast/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/cdm/current/cdm/","title":"CDM","text":""},{"location":"halif/cdm/current/cdm/#references","title":"References","text":"<p>Info</p> Interface Definition cdm/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-cdm.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/cdm/current/cdm/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/cdm/current/cdm/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/cec/current/cec/","title":"HDMI CEC","text":""},{"location":"halif/cec/current/cec/#references","title":"References","text":"<p>Info</p> Interface Definition cec/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-cec.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/cec/current/cec/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/cec/current/cec/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/common/current/common/","title":"Common","text":""},{"location":"halif/common/current/common/#references","title":"References","text":"<p>Info</p> Interface Definition common/current API Documentation TBD HAL Interface Type AIDL and Binder VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/common/current/common/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/common/current/common/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/composite_input/current/composite_input/","title":"Composite Input","text":""},{"location":"halif/composite_input/current/composite_input/#references","title":"References","text":"<p>Info</p> Interface Definition compositeinput/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-composite_input.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/composite_input/current/composite_input/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/composite_input/current/composite_input/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/deep_sleep/current/deep_sleep/","title":"DeepSleep HAL","text":""},{"location":"halif/deep_sleep/current/deep_sleep/#overview","title":"Overview","text":"<p>The DeepSleep HAL provides a platform-abstracted mechanism to transition a device into a low-power deep sleep state and return from it based on hardware-triggered wake-up events. This HAL enables features like wake-on-remote, wake-on-LAN, and timer-based resume in a consistent, vendor-independent manner.</p> <p>It manages entry into DeepSleep:</p> <ul> <li>Wake-up via supported hardware trigger types</li> <li>Tracking and reporting of wake-up cause</li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#references","title":"References","text":"<p>Info</p> Interface Definition com/rdk/hal/deepsleep API Documentation TBD HAL Interface Type AIDL and Binder Initialization Unit systemd service VTS Tests TBD Reference Implementation TBD"},{"location":"halif/deep_sleep/current/deep_sleep/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>HAL Feature Profile</li> <li>HAL Interface Overview</li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#functional-overview","title":"Functional Overview","text":"<p>The <code>IDeepSleep</code> interface is responsible for:</p> <ul> <li>Reporting supported and preconfigured wake-up triggers</li> <li>Entering deep sleep and blocking until triggered to resume</li> <li>Providing wake-up cause information, including keycode (if RCU-based)</li> <li>Setting and retrieving timer values for wake-up via clock events</li> </ul> <p>It operates at the HAL layer and is used by middleware components responsible for system power policy management or user-initiated standby.</p>"},{"location":"halif/deep_sleep/current/deep_sleep/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.DeepSleep.1 The HAL shall expose a <code>getCapabilities()</code> method Returns <code>supportedTriggers[]</code> and <code>preconfiguredTriggers[]</code> HAL.DeepSleep.2 The HAL shall implement <code>enterDeepSleep()</code> Blocks until resume; returns trigger cause HAL.DeepSleep.3 The HAL shall support timer-based wake-up via <code>setWakeUpTimer()</code> Requires <code>TIMER</code> trigger in capabilities; must wake within \u00b15 seconds HAL.DeepSleep.4 The HAL shall report keycode if the wake-up was RCU-based Linux input keycode HAL.DeepSleep.5 The HAL shall ensure <code>preconfiguredTriggers[]</code> are always enabled Even if not explicitly listed by client"},{"location":"halif/deep_sleep/current/deep_sleep/#interface-definitions","title":"Interface Definitions","text":"AIDL File Description <code>IDeepSleep.aidl</code> Main interface to enter/exit deep sleep and manage timers <code>Capabilities.aidl</code> Parcelable reporting supported and preconfigured triggers <code>KeyCode.aidl</code> Parcelable reporting Linux key code from wake-up trigger <code>WakeUpTrigger.aidl</code> Enum of supported wake-up sources"},{"location":"halif/deep_sleep/current/deep_sleep/#initialization","title":"Initialization","text":"<ul> <li>HAL service is binderized and registered via <code>IDeepSleep::serviceName = \"DeepSleep\"</code>.</li> <li>Starts via a systemd unit in the vendor or HAL layer during system boot.</li> <li>Must register with the <code>ServiceManager</code>.</li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#product-customization","title":"Product Customization","text":"<ul> <li>Supported and preconfigured wake-up sources are defined via platform-specific YAML (<code>HAL Feature Profile</code>).</li> </ul> <pre><code>deep_sleep:\n  interfaceVersion: current\n  supportedTriggers:\n      - RCU_IR\n      - RCU_BT\n      - LAN\n      - WLAN\n      - TIMER\n      - FRONT_PANEL\n      - CEC\n      - PRESENCE\n      - VOICE\n  preconfiguredTriggers:\n      - RCU_IR\n      - RCU_BT\n      - TIMER\n      - FRONT_PANEL\n</code></pre> <ul> <li> <p><code>preconfiguredTriggers[]</code> are always armed by the platform, regardless of whether the client includes them in the <code>enterDeepSleep()</code> call.</p> </li> <li> <p>These reflect hardware or firmware limitations where certain wake sources are always enabled.</p> </li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#system-context","title":"System Context","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant DeepSleep HAL\n    participant Vendor Driver\n\n    Client-&gt;&gt;DeepSleep HAL: getCapabilities()\n    DeepSleep HAL-&gt;&gt;Vendor Driver: query wake sources\n    Vendor Driver--&gt;&gt;DeepSleep HAL: Capabilities\n    DeepSleep HAL--&gt;&gt;Client: Capabilities\n\n    Client-&gt;&gt;DeepSleep HAL: setWakeUpTimer(seconds)\n    DeepSleep HAL-&gt;&gt;Vendor Driver: set timer\n\n    Client-&gt;&gt;DeepSleep HAL: enterDeepSleep(triggers[])\n    Note over DeepSleep HAL, Vendor Driver: System enters deep sleep\n\n    Vendor Driver--&gt;&gt;DeepSleep HAL: wake-up trigger info\n    DeepSleep HAL--&gt;&gt;Client: wokeUpByTriggers[], keyCode</code></pre>"},{"location":"halif/deep_sleep/current/deep_sleep/#resource-management","title":"Resource Management","text":"<ul> <li>The HAL is single-client controlled.</li> <li>Only one call to <code>enterDeepSleep()</code> is active at a time.</li> <li>On client crash or termination, HAL must abort sleep entry and return control to the system.</li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#operation-and-data-flow","title":"Operation and Data Flow","text":"<ul> <li> <p>Input:</p> </li> <li> <p><code>triggersToWakeUpon[]</code> \u2014 wake-up conditions explicitly requested by the client</p> </li> <li> <p><code>setWakeUpTimer(seconds)</code> \u2014 timer duration in seconds</p> </li> <li> <p>Output:</p> </li> <li> <p><code>wokeUpByTriggers[]</code> \u2014 triggers that caused device to resume</p> </li> <li> <p><code>KeyCode</code> \u2014 if RCU-based trigger, gives Linux key code</p> </li> <li> <p>The platform is expected to wake the device within \u00b15 seconds of the programmed timer value.</p> </li> <li> <p><code>preconfiguredTriggers[]</code> are always active. If a client omits them from the <code>triggersToWakeUpon[]</code>, the HAL implicitly adds them.</p> </li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#modes-of-operation","title":"Modes of Operation","text":"<p>No distinct runtime modes. However, trigger availability may vary by platform. Clients should always inspect <code>getCapabilities()</code> at runtime.</p>"},{"location":"halif/deep_sleep/current/deep_sleep/#event-handling","title":"Event Handling","text":"<p>This HAL is synchronous and does not emit asynchronous events. It blocks on <code>enterDeepSleep()</code> and returns with trigger information when the system resumes.</p>"},{"location":"halif/deep_sleep/current/deep_sleep/#platform-capabilities","title":"Platform Capabilities","text":"<ul> <li>Supports timer-based wake-up for durations up to 7 days</li> <li>Wake timer accuracy must be within \u00b15 seconds of the programmed interval</li> <li><code>preconfiguredTriggers[]</code> are platform-enforced and always armed</li> <li>Clients can enumerate <code>supportedTriggers[]</code> to choose their wake policy</li> </ul>"},{"location":"halif/deep_sleep/current/deep_sleep/#error-handling","title":"Error Handling","text":"<ul> <li><code>enterDeepSleep()</code> returns <code>false</code> if any specified trigger is unsupported</li> <li>If wake-up reason is ambiguous or unknown, <code>WakeUpTrigger.ERROR_UNKNOWN</code> is returned</li> <li>A <code>setWakeUpTimer()</code> call with invalid input returns <code>false</code></li> </ul>"},{"location":"halif/device_info/current/device_info/","title":"Device Information","text":""},{"location":"halif/device_info/current/device_info/#references","title":"References","text":"<p>Info</p> Interface Definition deviceinfo/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-device_info.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/device_info/current/device_info/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/device_info/current/device_info/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/ffv/current/ffv/","title":"Far Field Voice (FFV)","text":""},{"location":"halif/ffv/current/ffv/#references","title":"References","text":"<p>Info</p> Interface Definition ffv/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-ffv.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/ffv/current/ffv/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/ffv/current/ffv/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/flash/current/flash/","title":"Flash Image","text":""},{"location":"halif/flash/current/flash/#references","title":"References","text":"<p>Info</p> Interface Definition flash/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-flash.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/flash/current/flash/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/flash/current/flash/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/hdmi_input/current/hdmi_input/","title":"HDMI Input","text":""},{"location":"halif/hdmi_input/current/hdmi_input/#references","title":"References","text":"<p>Info</p> Interface Definition hdmiinput/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-hdmi_input.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/hdmi_input/current/hdmi_input/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/hdmi_input/current/hdmi_input/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/hdmi_output/current/hdmi_output/","title":"HDMI Output","text":""},{"location":"halif/hdmi_output/current/hdmi_output/#references","title":"References","text":"<p>Info</p> Interface Definition hdmioutput/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-hdmi_output.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/hdmi_output/current/hdmi_output/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/hdmi_output/current/hdmi_output/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/indicator/current/indicator/","title":"HAL Indicator","text":""},{"location":"halif/indicator/current/indicator/#overview","title":"Overview","text":"<p>The Indicator interface abstracts control of persistent device indicator states\u2014typically backed by hardware elements such as LEDs or front-panel displays. It allows higher-level components, such as middleware and system services, to reflect the system's current status to the user using a set of standardised states.</p> <p>The abstraction hides all platform-specific details. Each vendor is responsible for implementing these states in a manner consistent with their product design. The HAL implementation must reflect each state via hardware-controlled visual indicators (e.g., colours, blink patterns, panel brightness), but upper layers remain unaware of any physical wiring, LED models, or mapping logic.</p> <p>This decoupling ensures consistency across devices while allowing flexibility for OEM-specific behaviour.</p> <p>The interface supports:</p> <ul> <li>A single active state at any time, managed via <code>set(State)</code> and read via <code>get()</code></li> <li>Discovery of supported states via <code>getCapabilities()</code>, aligned with the HFP file</li> <li>No support for transient triggers like momentary LED flashes; these are handled independently</li> </ul>"},{"location":"halif/indicator/current/indicator/#references","title":"References","text":"<p>Info</p> Interface Definition indicator/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization Unit systemd service VTS Tests TBD Reference Implementation TBD HAL Feature Profile hfp-indicator.yaml"},{"location":"halif/indicator/current/indicator/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>HAL Feature Profile</li> <li>HAL Interface Overview</li> <li>Other HALs or Framework Components</li> </ul>"},{"location":"halif/indicator/current/indicator/#functional-overview","title":"Functional Overview","text":"<p>The Indicator HAL defines a discrete and finite set of persistent system states, each representing an observable operational condition (e.g., <code>ACTIVE</code>, <code>WPS_CONNECTING</code>, <code>SOFTWARE_DOWNLOAD_ERROR</code>). These are:</p> <ul> <li>Long-lived: The state persists until explicitly changed</li> <li>Mutually exclusive: Only one state can be active at a time</li> <li>User-visible: Each state should correspond to a user-facing behaviour (e.g., LED colour/pattern)</li> </ul> <p>Clients interact using the following flow:</p> <ol> <li><code>getCapabilities()</code> to retrieve the list of supported states</li> <li><code>set(State)</code> to enter a new persistent indicator state</li> <li><code>get()</code> to retrieve the currently active state</li> </ol>"},{"location":"halif/indicator/current/indicator/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.INDICATOR.1 The service shall expose a single active state using <code>set(State)</code> Only one state is active at a time HAL.INDICATOR.2 The service shall return the current state via <code>get()</code> Must reflect latest successfully set value HAL.INDICATOR.3 The platform shall advertise supported states via <code>Capabilities</code> Validated against <code>hfp-indicator.yaml</code> HAL.INDICATOR.4 States not listed in <code>Capabilities</code> shall not be settable Invalid <code>set()</code> calls must fail gracefully HAL.INDICATOR.5 <code>ERROR_UNKNOWN</code> and <code>BOOT</code> must be read-only states <code>BOOT</code> is platform-initialised only"},{"location":"halif/indicator/current/indicator/#interface-definitions","title":"Interface Definitions","text":"AIDL File Description <code>IIndicator.aidl</code> Primary interface for querying and setting state <code>Capabilities.aidl</code> Parcelable describing supported states <code>State.aidl</code> Enum of valid indicator states"},{"location":"halif/indicator/current/indicator/#platform-capabilities","title":"Platform Capabilities","text":"<p>The platform-specific file <code>hfp-indicator.yaml</code> defines the subset of states supported by each device. This must be kept in sync with the runtime implementation and used for:</p> <ul> <li>Runtime validation (<code>getCapabilities()</code>)</li> <li>Automated testing (VTS test case selection)</li> <li>Middleware introspection</li> </ul>"},{"location":"halif/indicator/current/indicator/#enum-value-groupings","title":"Enum Value Groupings","text":"<p>The <code>State</code> enum uses explicit, grouped integer values to simplify vendor extension and downstream parsing. For example:</p> Group Value Range Examples General 0\u201399 <code>BOOT</code>, <code>ACTIVE</code>, <code>OFF</code> WPS 100\u2013199 <code>WPS_CONNECTING</code>, <code>WPS_ERROR</code> Network 200\u2013299 <code>IP_ACQUIRED</code>, <code>NO_IP</code> System Events 300\u2013399 <code>USB_UPGRADE</code>, <code>PSU_FAILURE</code> Vendor 1000+ <code>USER_DEFINED_*</code> <p>These ranges are not enforced by the interface but are recommended for clarity and HFP alignment.</p>"},{"location":"halif/indicator/current/indicator/#supported-state-subset-example","title":"Supported State Subset (Example)","text":"<pre><code>supportedStates:\n  - BOOT\n  - ACTIVE\n  - STANDBY\n  - OFF\n  - WPS_CONNECTING\n  - WPS_CONNECTED\n  - WPS_ERROR\n  - WIFI_ERROR\n  - IP_ACQUIRED\n  - FULL_SYSTEM_RESET\n  - PSU_FAILURE\n</code></pre>"},{"location":"halif/indicator/current/indicator/#platform-specific-extensions","title":"Platform-Specific Extensions","text":"<p>Platforms may define new persistent states beginning at <code>USER_DEFINED_BASE = 1000</code>. These must:</p> <ul> <li>Follow the same semantics (persistent, exclusive, not transient)</li> <li>Be defined in the HFP YAML under <code>supportedStates</code></li> <li>Be documented for test coverage and integration</li> </ul>"},{"location":"halif/indicator/current/indicator/#error-handling","title":"Error Handling","text":"Condition Expected Behaviour Invalid <code>set(State)</code> call Must fail cleanly and leave state unchanged <code>set()</code> on read-only state Rejected (<code>BOOT</code>, <code>ERROR_UNKNOWN</code>) Unsupported enum value Rejected if not listed in <code>Capabilities</code> <code>get()</code> before any <code>set()</code> Returns <code>ERROR_UNKNOWN</code>"},{"location":"halif/key_concepts/hal/hal_feature_profiles/","title":"HAL Feature Profile (HFP)","text":"<p>The HAL Feature Profile (HFP) is a YAML-based declaration provided by OEMs to define the capabilities of their vendor layer implementation. It serves critical functions:</p> <ul> <li>Test Driver Configuration: Enables the vendor test suite to perform targeted testing based on the declared feature set.</li> <li>Capability Declaration: Provides a comprehensive list of supported HAL features for verification against product requirements.</li> </ul> <p>Each HAL component defines its own <code>hfp_xxx.yaml</code> within the vendor layer deliverables, typically located in a configuration directory (e.g., <code>vendor/&lt;vendor_name&gt;/&lt;platform&gt;/config/</code>).</p>"},{"location":"halif/key_concepts/hal/hal_feature_profiles/#file-syntax-and-schema","title":"File Syntax and Schema","text":"<p>The HFP utilizes YAML syntax for structured data representation, this is an example format the actual format is defined with the components.</p> <pre><code>hal:\n  profile: \"TV\" # Profile Type\n  platform: \"Sky Glass\" # Platform Identifier\n  schema_version: \"1.2.0\" # HFP Schema Version\n\n  components:\n    kernel:\n      version: \"5.15.164\"\n\n    av_buffer:\n      non_secure_heap_bytes: 1048576 # 1MB\n      secure_heap_bytes: 524288 # 512KB\n\n    video_decoder:\n      resources:\n        - id: 0\n          codecs: [\"H264\", \"HEVC\"]\n          max_resolution: \"4K\"\n          max_fps: 60\n          bit_depth: 10\n        - id: 1\n          codecs: [\"MPEG2\", \"AV1\"]\n          max_resolution: \"1080p\"\n          max_fps: 30\n          bit_depth: 8\n\n    cdm:\n      mandatory: true\n      resources:\n        PlayReady:\n          version: \"4.4\"\n          mandatory: true\n          secure_storage: true\n          concurrent_sessions: 2\n        WideVine:\n          version: \"L3\"\n          mandatory: false\n          secure_storage: false\n          concurrent_sessions: 1\n        FairPlay:\n          version: \"4.0\"\n          mandatory: false\n\n    audio_decoder:\n      supported_formats: [\"AAC\", \"MP3\", \"AC3\", \"DTS\", \"Dolby Digital\"]\n      max_channels: 8\n      sample_rate: 192000\n\n    tuner:\n      type: \"dvb-c\"\n      frequency_range: \"50-860 MHz\"\n      modulation: [\"QAM16\", \"QAM64\", \"QAM256\"]\n      bandwidth: 8\n\n    display:\n      resolution: \"1920x1080\"\n      hdr_support: true\n      interfaces: [\"HDMI\", \"DisplayPort\"]\n      refresh_rate: 60\n      color_space: \"BT.2020\"\n\n    network:\n      interfaces: [\"Ethernet\", \"WiFi\"]\n      wifi_standards: [\"802.11a\", \"802.11b\", \"802.11g\", \"802.11n\", \"802.11ac\", \"802.11ax\"]\n      ethernet_speed: \"1Gbps\"\n      ipv6_support: true\n\n    bluetooth:\n      version: \"5.2\"\n      profiles: [\"A2DP\", \"HFP\", \"AVRCP\", \"BLE\"]\n      le_coded_phy: true\n\n    input:\n      devices:\n        - name: \"Remote Control\"\n          types: [\"IR\", \"Bluetooth\", \"RF4CE\"]\n          features: [\"Voice Control\", \"Navigation\"]\n        - name: \"Keyboard\"\n          types: [\"Bluetooth\"]\n          features: [\"Text Input\"]\n\n    camera:\n      resolution: \"1920x1080\"\n      fps: 30\n      auto_focus: true\n      hdr: true\n\n    mic:\n      channels: 2\n      noise_cancellation: true\n      echo_cancellation: true\n\n    graphics_compositor:\n      layers: 4\n      alpha_blending: true\n      scaling: true\n      rotation: true\n\n    power_management:\n      states: [\"On\", \"Standby\", \"Deep Sleep\"]\n      wake_sources: [\"Remote\", \"Network\", \"Timer\"]\n      power_consumption:\n        standby: \"0.5W\"\n        deep_sleep: \"0.1W\"\n\n    telemetry:\n      supported_metrics: [\"CPU Usage\", \"Memory Usage\", \"Network Throughput\", \"Temperature\"]\n      reporting_interval: 60 # seconds\n      logging_levels: [\"Error\", \"Warning\", \"Info\", \"Debug\"]\n\n    drm_session_management:\n      max_concurrent_sessions: 4\n      secure_storage_types: [\"TEE\", \"Secure Flash\"]\n      persistent_sessions: true\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_feature_profiles/#mandatory-and-optional-hals-and-features","title":"Mandatory and Optional HALs and Features","text":"<p>The HFP explicitly lists all supported HAL components. Components or specific features within them can be marked as <code>mandatory</code> to indicate their requirement status. Any field not defined can be assumed to be <code>false</code> but for clarity can also be stated e.g. <code>mandatory: false</code>.</p> <pre><code>hal:\n  components:\n    cdm:\n      mandatory: true\n      resources:\n        PlayReady:\n          version: \"4.4\"\n          mandatory: true\n        WideVine:\n          version: \"L3\"\n          mandatory: false\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_feature_profiles/#hfp-versioning","title":"HFP Versioning","text":"<p>The <code>schema_version</code> field adheres to semantic versioning (major.minor.patch) to ensure backward compatibility as the HFP schema evolves.</p>"},{"location":"halif/key_concepts/hal/hal_feature_profiles/#tooling","title":"Tooling","text":"<p>Dedicated tools are essential for creating and validating the HFP will be created:</p> <ul> <li>Schema Validation: Implements robust validation against a defined schema (e.g., JSON Schema).</li> <li>HFP Generator: Tool to help create HFP files.</li> </ul>"},{"location":"halif/key_concepts/hal/hal_interfaces/","title":"HAL Interface Overview","text":"<p>Interfaces / Testing Suites / Component code must progress through multiple stages before a stable interface version can be realised. The first interface version will only be finalized at Phase 6, ensuring that it has been thoroughly tested and refined. Until the interface reaches this phase the interface is subject to change and cannot be considered stable.</p> <p>Tip</p> <ul> <li>Each phase requires an engineering &amp; architecture sign-off and review before proceeding to the next stage.</li> <li>Target Information is listed in the with the status. e.g. M3/25, Q2/25, H2/25, for moving to the next phase.</li> </ul>"},{"location":"halif/key_concepts/hal/hal_interfaces/#interface-phases","title":"Interface Phases","text":"Development Phase Goal Description Phase 1 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6)Qx/25 Define High-Level Requirements The Interface Working Group collaborates with stakeholders to identify and document high-level requirements, including functionality, performance, and security considerations. This phase concludes with a formal review and approval of the finalized requirements. Phase 2 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa\u26aa(2/6) Define HAL AIDL Interface Develop the Hardware Abstraction Layer (HAL) AIDL interface, incorporating comprehensive Doxygen comments to clearly describe each API element. This phase includes an in-depth review process, culminating in the approval of the initial release of the interface. Phase 3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa(3/6) Develop Detailed Module Specification Create a detailed specification document outlining the module\u2019s operation, behavior, and interface beyond the API definition and Doxygen documentation. This serves as a key reference for implementors, ensuring consistency and adherence to design principles. Phase 4 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa(4/6) Feedback &amp; Refinement Update the interface based on feedback from testing suites or insights gained from vDevice Phase 1. This may include documentation improvements, interface extensions, or necessary rework to enhance clarity and usability. Phase 5 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa(5/6) Hardware &amp; Architecture Validation Validation of interface functionality and architecture design on both the vDevice and lead hardware platform using testing suites. Phase 6 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2(6/6) Interface Freeze &amp; Versioning Finalize and freeze the component interface, officially releasing version 1 of the stable AIDL. At this stage, no breaking changes are permitted; only backward-compatible updates can be introduced."},{"location":"halif/key_concepts/hal/hal_interfaces/#testing-suites","title":"Testing Suites","text":""},{"location":"halif/key_concepts/hal/hal_interfaces/#levels-of-test","title":"Levels of Test","text":"Level Testing Type Purpose Level 1 (L1) Component Function Testing API function testing of individual components + requirements documentation Level 2 (L2) Component Unit Testing Focused testing of individual modules in a component, aligned with requirements documentation Level 3 (L3) Component Stimulus Testing Pre-commit testing using external stimuli to validate component responses and adherence to requirements Level 4 (L4) System Interface Testing (VSI) Validate interactions with external interfaces and devices, including Bluetooth, WiFi, graphics, and kernel interfaces <p>Note</p> <ul> <li>Not all components will undergo every testing phase, as some require interaction with other component groups to operate effectively.</li> </ul> <p>For More detailed information see Testing Suite Levels</p>"},{"location":"halif/key_concepts/hal/hal_interfaces/#testing-suite-phases","title":"Testing Suite Phases","text":"Development Phase Goal Description Phase 1\ud83d\udfe1\u26aa\u26aa\u26aa\u26aa(1/5) Define Testing Specification Develop a comprehensive testing specification outlining the testing strategy, test cases, and acceptance criteria for the module. This phase also incorporates feedback from testing efforts to refine Doxygen comments and improve the module specification. Phase 2\ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa(2/5) Generate Testing Suite Implement a phased testing suite based on the defined specification to validate the module\u2019s functionality, performance, and compliance with requirements. Phase 3\ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa(3/5) Validate Testing Suite Use the virtual component (vComponent) environment to verify the accuracy, effectiveness, and reliability of the testing suite before deploying it for broader system-level testing. Phase 4\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa(4/5) Hardware &amp; Architecture Validation Validation of interface functionality and architecture design on both the vDevice and lead hardware platform using testing suites. Phase 5\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2(5/5) Integrate and Test Integrate the module into the broader system and conduct rigorous testing using the developed testing suites. This phase ensures correct module functionality within the overall system architecture and verifies that it meets defined requirements. <p>Warning</p> <p>Testing suites must prioritize MVP bring-up and ensure the first-phase delivery of core features.</p>"},{"location":"halif/key_concepts/hal/hal_interfaces/#vcomponent-phases","title":"vComponent Phases","text":"Glossary Meaning vDevice Virtual Vendor Layer vComponent Independent Virtual component part of the vDevice <p>For more information on the Virtual device please see vDevice Overview</p> Development Phase Goal Description Phase 1\ud83d\udfe1\u26aa\u26aa\u26aa\u26aa(1/5) Interface Foundation Confidence Develop a proof of concept (PoC) for the interface implementation to validate its design and correctness. Findings from this phase provide direct feedback into Phase 4 of the Interface Specification process. Phase 2\ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa(2/5) Define vComponent Requirements Establish a detailed specification for implementing a vComponent on x86 architecture, including explicit requirements for execution under Linux. This phase incorporates iterative feedback to refine Doxygen comments and update the module specification. Phase 3\ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa(3/5) Control Plane Requirements Definition Define the control plane requirements for managing the vComponent state machine using a REST API. This phase formalizes the YAML-based message structure used for communication and state transitions within the vComponent. Additionally, it defines platform-specific startup requirements, ensuring that platform-specific configurations are correctly passed and applied. Phase 4 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa(4/5) Develop vComponent Implementation Implement a phased delivery of the vComponent module based on the vComponent specification. This module integrates with the vDevice vendor layer, enabling validation against the testing suite and ensuring conformance to interface specifications. (Can work with 3rd Parties on implementation) Phase 5\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2(5/5) Integration &amp; Testing Integrate the vComponent into the broader vDevice system and perform rigorous testing against the defined testing suites. Incorporate feedback to refine the implementation, update test cases as needed, and verify compliance with all specified requirements."},{"location":"halif/key_concepts/hal/hal_interfaces/#phase-relationships","title":"Phase Relationships","text":"<p>The flowchart below shows the relationships and flows between the phases.</p> <p>Info</p> <p>Once the interface reaches \"Phase 4: Feedback &amp; Refinement\" \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2, then \"Testing Suite: Phase 1\" &amp; \"vComponent: Phase 1\" can commence.</p> <pre><code>flowchart TD\n    %% Dummy node to enforce left alignment\n    X[ Start ] -.-&gt; Interface_Phases\n\n    subgraph vComponent_Phases\n        V1[P1: Interface Foundation Confidence&lt;br&gt;\ud83d\udfe1] --&gt; V2[P2: Define vComponent Requirements\ud83d\udfe1\ud83d\udfe1]\n        V2 --&gt; V3[P3: Control Plane Requirements Definition&lt;br&gt;\ud83d\udfe0\ud83d\udfe0\ud83d\udfe0]\n        V3 --&gt; V4[P4: Develop vComponent Implementation&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n        V4 --&gt; V5[P5: Integration &amp; Testing&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n    end\n\n    subgraph Testing_Suite_Phases\n        T1[P1: Define Testing Specification &lt;br&gt;\ud83d\udfe1] --&gt; T2[P2: Generate Testing Suite &lt;br&gt;\ud83d\udfe1\ud83d\udfe1]\n        T2 --&gt; T3[P3: Validate Testing Suite&lt;br&gt;\ud83d\udfe0\ud83d\udfe0\ud83d\udfe0]\n        T3 --&gt; T4[P4: Hardware &amp; Architecture Validation&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n        T4 --&gt; T5[P5: Integrate and Test&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n    end\n\n    subgraph Interface_Phases\n        P1[P1: Define High-Level Requirements &lt;br&gt;\ud83d\udfe1] --&gt; P2[P2: Define HAL AIDL Interface&lt;br&gt;\ud83d\udfe1\ud83d\udfe1]\n        P2 --&gt; P3[P3: Develop Detailed Module Specification&lt;br&gt;\ud83d\udfe0\ud83d\udfe0\ud83d\udfe0]\n        P3 --&gt; P4[P4: Feedback &amp; Refinement&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n        P4 &lt;--&gt; |Feedback/Refine | P5[P5: Hardware &amp; Architecture Validation&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n        P5 --&gt; P6[P6: Interface Freeze &amp; Versioning&lt;br&gt;\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2]\n    end\n\n    P4 --&gt; |Feedback loop | P2\n    P4 &lt;--&gt; |Foundation/Feedback| V1\n    P4 --&gt; |Testing/Feedback| T1\n    T4 &lt;--&gt; |Testing loop| V4\n    T2 &lt;--&gt; |Feedback loop| T3\n    T4 &lt;--&gt; | Feedback loop | P5\n    V5 &lt;--&gt; | Feedback loop | P5\n    T5 &lt;--&gt; | Feedback loop | P5\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_interfaces/#interface-testing-vcomponent-status","title":"Interface / Testing / vComponent Status","text":""},{"location":"halif/key_concepts/hal/hal_interfaces/#av-components","title":"AV Components","text":"<p>This list provides an overview of various HAL components, their device profiles, and functionality within the system.</p> HAL Component Interface L1 L2 L3 vComponent Audio Decoder \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (x/5) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5) Q3 Audio Sink \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (x/5) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5) Q3 Audio Mixer \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (2/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q3 AV Buffer \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (x/5) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5) Q3 AV Clock \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (x/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (x/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (x/5) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q3 Video Decoder \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (x/5) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5) Q3 Video Sink \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (x/5) Q3 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (1/5) Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5) Q3 A/V Tests L4 vDevice Generic A/V Tests \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5)Q3 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (1/5)Q3"},{"location":"halif/key_concepts/hal/hal_interfaces/#non-av-components","title":"Non AV Components","text":"<p>This list provides an overview of various HAL components, their device profiles, and functionality within the system.</p> HAL Component Interface L1 L2 L3 vComponent Plane Control \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (x/5) Q4 \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Composite Input \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 HDMI CEC \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (2/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 HDMI Input \ud83d\udfe1\ud83d\udfe0\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 HDMI Output \ud83d\udfe1\ud83d\udfe0\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Service Manager \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (4/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Boot \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Broadcast \ud83d\udfe1\ud83d\udfe1\u26aa\u26aa\u26aa\u26aa (2/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Common \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Deep Sleep \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (3/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Device Info \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Indicator \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa\u26aa (3/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Panel \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Sensor \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 FFV \u26aa\u26aa\u26aa\u26aa\u26aa\u26aa (x/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4"},{"location":"halif/key_concepts/hal/hal_interfaces/#non-av-components-tbd","title":"Non AV Components TBD","text":"HAL Component Interface L1 L2 L3 vComponent Comments CDM \u26aa\u26aa\u26aa\u26aa\u26aa\u26aa (X/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) \u26aa\u26aa\u26aa\u26aa\u26aa (x 5) \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Needs to reviewed in light of non-standard integration for vendors Secapi \u26aa\u26aa\u26aa\u26aa\u26aa\u26aa (X/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Used for crypto, needs rationalisation  with TEE"},{"location":"halif/key_concepts/hal/hal_interfaces/#vendor-system-interfaces-vsi","title":"Vendor System Interfaces (VSI)","text":"<p>The following smaller subset of HALs function as in-process libraries, collectively referred to as the Vendor System Interface (VSI). They are dynamically linked to the RDK Middleware, commonly used for:</p> HAL Component Interface L4 vDevice Comment Bluetooth \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q4 \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa (3/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Graphics (OpenGLES, EGL) \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q4 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa (4/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Wi-Fi \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q4 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa (4/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Kernel \ud83d\udfe0\ud83d\udfe0\ud83d\udfe0\u26aa\u26aa\u26aa (3/6) Q4 \ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\ud83d\udfe2\u26aa (4/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5)Q4 Filesystem \ud83d\udfe0\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 TBD: /opt. eCryptFS, /sysfs. /procfs, (resilience) abstracted filing system Linux Input Device \ud83d\udfe1\u26aa\u26aa\u26aa\u26aa\u26aa (1/6) Q3 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4"},{"location":"halif/key_concepts/hal/hal_interfaces/#vendor-system-interfaces-vsi-tbd","title":"Vendor System Interfaces (VSI) TBD","text":"HAL Component L4 Comments Graphics Display \u26aa\u26aa\u26aa\u26aa\u26aa (x/5) Q4 Integrated with the display, EGL &amp; Plane Control (Benchmarks) (Wayland), Composition"},{"location":"halif/key_concepts/hal/hal_naming_conventions/","title":"Naming Conventions for the Repository","text":"<p>To ensure consistency and maintainability across the repository, we adhere to the following naming conventions:</p>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#directory-and-file-naming-for-documentation","title":"Directory and File Naming for Documentation","text":"<ul> <li>Case: All directory and file names MUST be lowercase.</li> <li>Word Separation: Use underscores (<code>_</code>) instead of hyphens (<code>-</code>) or camel case to separate words in directory and file names.</li> <li>Rationale: This convention aligns with Unix-like system structures, ensuring smooth integration, ease of navigation, and simplified automation processes.</li> </ul> <p>Documentation will be located under the <code>docs</code> directory, split into interfaces <code>hal</code>. <code>vsi</code>, then split my module, following the convention below.</p>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#examples","title":"Examples","text":"<p>Good:</p> <pre><code>docs/audio_decoder/introduction_information.md\n</code></pre> <p>Bad:</p> <pre><code>docs/audio-decoder/intro-information.md       (Hyphen used)\ndocs/audiodecoder/introinformation.md         (No separator)\ndocs/audiodecoder/introInformation.md         (Camel case used)\ndocs/AudioDecoder/intro_information.md        (Incorrect case in directory)\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#directory-and-file-naming-for-interfaces","title":"Directory and File Naming for Interfaces","text":"<ul> <li>Case: All directory and file names MUST be lowercase.</li> <li>Camel case: The filename will match the Class defination extended with <code>.aidl</code> the class defination is defined using Camcel case.</li> <li>Rationale: This convention aligns with coding standards used for C++ classes.</li> </ul> <p>Source code will be located under the <code>src</code> directory, then split my module, following the convention below.</p> <p>Good:</p> <pre><code>src/audiodecoder/IAudioDecoderInterface.aidl\n</code></pre> <p>Bad:</p> <pre><code>srcs/audio-decoder/intro-information.md      (Hyphen used)\nsrc/audiodecoder/introinformation.md         (All lower case)\nsrc/audiodecoder/introInformation.md         (Camel case used, but first letter of filename not capitals)\nsrc/AudioDecoder/intro_information.md        (Underscore used)\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#interface-naming","title":"Interface Naming","text":"<pre><code>interface IAudioSinkManager\n{\n    /** The service name to publish. To be returned by getServiceName() in the derived class. */\n    const\n    @utf8InCpp String serviceName = \"AudioSinkManager\";\n}\n</code></pre>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#systemd-naming-of-launch","title":"Systemd Naming of Launch","text":"<p>Naming convention for systemd services follows the convention for documentation i.e. <code>hal-audio_decoder_manager.service</code></p>"},{"location":"halif/key_concepts/hal/hal_naming_conventions/#additional-considerations","title":"Additional Considerations","text":"<ul> <li>Abbreviations: Avoid abbreviations unless they are extremely common and well-understood within the project (e.g., <code>HAL</code>, <code>API</code>, <code>RDK</code>).  Prefer full words for clarity.</li> <li>Length: Keep file and directory names reasonably short and descriptive.  Avoid excessively long names.</li> <li>Special Characters: Do not use special characters (e.g., spaces, punctuation) in file or directory names, except for underscores as separators.</li> <li>File Extensions: Use appropriate file extensions for each file type (e.g., <code>.md</code> for Markdown, <code>.aidl</code> for AIDL).</li> <li>Directory Structure:  Consider adding a brief description of the intended directory structure.  For example, what types of files go into the <code>docs</code> directory, <code>src</code> directory, etc.  This helps new contributors understand the organization of the repository.</li> <li>Consistency Across Project: If there are other repositories in the project, it may be a good idea to align naming conventions.</li> </ul>"},{"location":"halif/key_concepts/hal/hal_properties/","title":"HAL <code>setProperty</code> and <code>getProperty</code>","text":"<p>This document provides a concise overview of the <code>setProperty</code> and <code>getProperty</code> methods within RDK-AIDL-HAL. These methods offer a flexible mechanism for interacting with services, encompassing both metadata management and functional control.</p>"},{"location":"halif/key_concepts/hal/hal_properties/#core-functionality","title":"Core Functionality:","text":"<p><code>setProperty(String key, String value)</code>:  Sets a property associated with the service.  The <code>key</code> identifies the property, and the <code>value</code> provides the data to be stored or used.</p> <p><code>getProperty(String key)</code>: Retrieves the value of a specified property. The <code>key</code> identifies the property to retrieve.</p>"},{"location":"halif/key_concepts/hal/hal_properties/#key-considerations","title":"Key Considerations:","text":"<ul> <li> <p>Implementation-Defined Behavior:  The meaning and effect of any given <code>key</code> and <code>value</code> are entirely determined by the service implementing the AIDL interface.  The AIDL itself only defines the communication mechanism, not the semantics.</p> </li> <li> <p>Beyond Metadata: While <code>setProperty</code> and <code>getProperty</code> can be used for storing and retrieving metadata (e.g., object names, versions), they are not limited to this purpose.  </p> </li> </ul> <p>They can be used to:</p> <ul> <li>Control Service Behavior: Setting a property might trigger an action, change a service's state, or modify its operational parameters.</li> <li> <p>Retrieve Service State: Getting a property might return the current state of a component, a calculated value, or any other information the service chooses to expose.</p> </li> <li> <p>General-Purpose Communication: Think of these methods as a generic communication channel. The AIDL defines the channel (key-value pairs), but the service defines the \"language\" spoken over that channel (the meaning of each key).</p> </li> </ul>"},{"location":"halif/key_concepts/hal/hal_properties/#example-use-cases","title":"Example Use Cases:","text":"<ul> <li>Configuration: <code>setProperty(\"logLevel\", \"DEBUG\")</code> could set the logging verbosity.</li> <li>State Management: <code>getProperty(\"connectionStatus\")</code> might return the current connection state.</li> <li>Command Execution: <code>setProperty(\"reboot\", \"true\")</code> could trigger a reboot.</li> <li> <p>Data Retrieval: <code>getProperty(\"sensorData\")</code> might return sensor readings.</p> </li> <li> <p>No Inherent Semantics:  The AIDL interface itself imposes no restrictions on the types of data that can be stored or retrieved, nor does it define what any particular key should represent.  The service is solely responsible for defining and managing these.</p> </li> </ul>"},{"location":"halif/key_concepts/hal/hal_properties/#best-practices","title":"Best Practices:","text":"<ul> <li>Documentation is Crucial: Service developers should clearly document the available properties, their meanings, valid value ranges, and any side effects.  This is essential for clients to use the interface correctly.</li> <li>Consistent Key Naming: Employ a consistent naming convention for properties to improve readability and maintainability.</li> <li>Error Handling: Services should handle invalid property keys or values gracefully, possibly by returning error codes or throwing exceptions.</li> </ul> <p>In summary: <code>setProperty()</code> and <code>getProperty()</code> are powerful and flexible tools.  They can be used for metadata, configuration, state management, and more.  However, their true potential is realized when service developers thoroughly document and carefully design the properties they expose, ensuring clear communication and predictable behavior for clients.</p>"},{"location":"halif/key_concepts/hal/hal_session_state_management/","title":"Session State Management","text":"<p>Several of the HAL services follow the same session state management paradigm and share a common pattern for state transitions and notifications.</p> <p>Any HAL service that handles AV data buffers will follow the session state management described in this section.</p> <p>Where resource instances managed by a HAL service, often a sub-interface is offered to manage that specific resource (e.g. <code>IAudioDecoderManager</code> provides <code>IAudioDecoder</code>\u00a0resource instance sub-interfaces).\u00a0 In this case each of the resource instances operates its own session state machine.</p> <p>Not all states may be applicable to all HAL services, so check the relevant HAL service documentation.</p>"},{"location":"halif/key_concepts/hal/hal_session_state_management/#hal-aidl-definitions","title":"HAL AIDL Definitions","text":"<p>See <code>State.aidl</code> in Common.</p>"},{"location":"halif/key_concepts/hal/hal_session_state_management/#implementation-requirements","title":"Implementation Requirements","text":"Requirement Comments HAL.STATE.1 When a function is called which changes state, an initial <code>onStateChanged()</code> callback shall occur indicating the new transitory state within 10ms. HAL.STATE.2 When a function is called which changes state, the final <code>onStateChanged()</code> callback shall occur indicating the new target state within 500ms."},{"location":"halif/key_concepts/hal/hal_session_state_management/#hal-service-component-states","title":"HAL Service Component States","text":"<p>When a service instance has finished initialising, its initial state is\u00a0<code>CLOSED</code>.</p> <p>A HAL service notifies the client of state changes through the <code>&lt;Listener&gt;.onStateChanged()</code>\u00a0callback which is usually registered with the <code>registerEventListener()</code> function.</p> <p>The functions which cause a state transition; <code>open()</code>, <code>close()</code>, <code>start()</code>, <code>stop()</code> and <code>flush()</code> cause the component to enter a transitory state for a period of time until it enters it target state.\u00a0 Both the transitory state change and target state change are both notified to the client through the <code>onStateChanged()</code>\u00a0callback.</p> <p>If an internal error occurs during the <code>OPENING</code>\u00a0or <code>STARTING</code> transitory states, then it cannot transition to the new target state, but instead returns to the previous state which is notified to the client through the <code>onStateChanged()</code>\u00a0callback.</p> enum State State Type Description UNKNOWN Transitory The initial HAL service session state while initialising, before transitioning to the\u00a0<code>CLOSED</code>\u00a0state. CLOSED Non-transitory Initial state entered after initialisation. OPENING Transitory The HAL service session is transitioning from CLOSED to the <code>READY</code>\u00a0state. READY Non-transitory The HAL service session is open and ready to start, but in a stopped state. STARTING Transitory The HAL service session is transitioning from READY to the <code>STARTED</code>\u00a0state. STARTED Non-transitory The opened HAL service session has been started. FLUSHING Transitory The started HAL service session is flushing internal state/buffers.\u00a0 Once flushed, the HAL service session returns to the <code>STARTED</code>\u00a0state. STOPPING Transitory The started HAL service session is stopping and flushing its internal state/buffers.\u00a0 Once flushed, the HAL service session enters the <code>READY</code>\u00a0state. CLOSING Transitory The HAL service session is transitioning from READY to the <code>CLOSED</code>\u00a0state."},{"location":"halif/key_concepts/hal/hal_session_state_management/#state-diagram","title":"State Diagram","text":"<p>The state diagram below includes the typical function names which trigger state transitions.</p> <p>Transitory states are only held while the HAL service performs internal processing to achieve the next target state.</p> <pre><code>stateDiagram-v2\n    direction LR\n    [*] --&gt; UNKNOWN\n    UNKNOWN --&gt; CLOSED: &lt;init&gt;\n\n    CLOSED --&gt; OPENING: open()\n    OPENING --&gt; READY: success\n    OPENING --&gt; CLOSED: &lt;error&gt;\n\n    READY --&gt; STARTING: start()\n    STARTING --&gt; READY: &lt;error&gt;\n    STARTING --&gt; STARTED: success\n\n    STARTED --&gt; FLUSHING: flush()\n    FLUSHING --&gt; STARTED: success\n\n    STARTED --&gt; STOPPING: stop()\n    STOPPING --&gt; READY: success\n\n    READY --&gt; CLOSING: close()\n    CLOSING --&gt; CLOSED: success\n\n    classDef NonTransitory fill:#1976D2, color:white, font-weight:bold;\n    classDef Transitory fill:#90CAF9, color:black, font-weight:bold;\n    class CLOSED,READY,STARTED NonTransitory\n    class UNKNOWN,OPENING,CLOSING,STARTING,STOPPING,FLUSHING Transitory</code></pre>"},{"location":"halif/key_concepts/hal/hal_session_state_management/#state-change-callbacks-sequence","title":"State Change Callbacks Sequence","text":"<p>The sequence diagram below shows the typical behaviour of the state machine and the expected callbacks.</p> <p>Many HAL services allow for multiple callback listeners to be registered and each registered listener would be notified of the state changes.</p> <pre><code>sequenceDiagram\n    box rgb(30,136,229) Client Component\n        participant Client as Client to &lt;br&gt;HAL service\n        participant Listener as Callback Listener\n    end\n    box rgb(249,168,37) HAL Component\n        participant HAL as HAL Service\n    end\n\n    Client-&gt;&gt;HAL: registerEventListener(... callback listener...)\n    Note over HAL: open() transitions from CLOSED -&gt; OPENING -&gt; READY\n\n    Client-&gt;&gt;HAL: open()\n    HAL--&gt;&gt;Listener: onStateChanged(CLOSED -&gt; OPENING)\n    HAL--&gt;&gt;Listener: onStateChanged(OPENING -&gt; READY)\n\n    Note over HAL: start() transitions from READY -&gt; STARTING -&gt; STARTED\n\n    Client-&gt;&gt;HAL: start()\n    HAL--&gt;&gt;Listener: onStateChanged(READY -&gt; STARTING)\n    HAL--&gt;&gt;Listener: onStateChanged(STARTING -&gt; STARTED)\n\n    Note over HAL: flush() transitions from STARTED -&gt; FLUSHING -&gt; STARTED\n\n    Client-&gt;&gt;HAL: flush()\n    HAL--&gt;&gt;Listener: onStateChanged(STARTED -&gt; FLUSHING)\n    HAL--&gt;&gt;Listener: onStateChanged(FLUSHING -&gt; STARTED)\n\n    Note over HAL: stop() transitions from STARTED -&gt; STOPPING -&gt; STOPPED\n\n    Client-&gt;&gt;HAL: stop()\n    HAL--&gt;&gt;Listener: onStateChanged(STARTED -&gt; STOPPING)\n    Note over HAL: A flush is also implied by stop().\n    HAL--&gt;&gt;Listener: onStateChanged(STOPPING -&gt; READY)\n\n    Note over HAL: stop() transitions from READY -&gt; CLOSING -&gt; CLOSED\n\n    Client-&gt;&gt;HAL: close()\n    HAL--&gt;&gt;Listener: onStateChanged(READY -&gt; CLOSING)\n    HAL--&gt;&gt;Listener: onStateChanged(CLOSING -&gt; CLOSED)\n\n    Note over HAL: Errors during open() transitions from CLOSED -&gt; OPENING -&gt; CLOSED\n\n    Client-&gt;&gt;HAL: open()\n    HAL--&gt;&gt;Listener: onStateChanged(CLOSED -&gt; OPENING)\n    HAL--&gt;&gt;Listener: onStateChanged(OPENING -&gt; CLOSED)\n\n    Client-&gt;&gt;HAL: unregisterEventListener(... callback listener...)\n</code></pre>"},{"location":"halif/panel/current/panel/","title":"Panel","text":""},{"location":"halif/panel/current/panel/#references","title":"References","text":"<p>Info</p> Interface Definition panel/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-panel.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/panel/current/panel/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/panel/current/panel/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/plane_control/current/plane_control/","title":"Plane Control","text":"<p>The Plane Control HAL manages the platform\u2019s video and graphics plane resources, exposing each plane as a resource with readable capabilities.  </p> <p>It enables linking video sources\u2014such as video sinks, HDMI input, and composite input\u2014to a video plane. Additionally, it provides the RDK middleware with a native window graphics plane handle for EGL-based graphics display.  </p> <p>Each plane is configurable through a set of properties that clients can read or modify, either individually or in batches.</p>"},{"location":"halif/plane_control/current/plane_control/#references","title":"References","text":"<p>Info</p> Interface Definition planecontrol/current API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-plane_control.service VTS Tests https://github.com/rdkcentral/rdk-halif-binder-test-planecontrol Reference Implementation - vComponent TBC"},{"location":"halif/plane_control/current/plane_control/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Video Sink</li> </ul>"},{"location":"halif/plane_control/current/plane_control/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.PLANECONTROL.1 Shall provide APIs to manage the geometry, z-order, visibility and other properties of graphics and video planes for tunnelled and non-tunnelled operational modes of the video pipeline. HAL.PLANECONTROL.2 Shall allow tunnelled video sources from a video decoder/sink, a HDMI input or a composite input to be linked to a video plane for display. HAL.PLANECONTROL.3 Shall provide an API to expose the plane resources and their capabilities for a client to discover. HAL.PLANECONTROL.4 Shall provide an API to atomically set multiple properties of a plane which take effect at the next available vsync. HAL.PLANECONTROL.5 Shall allow only 1 source to be mapped to any given video plane. HAL.PLANECONTROL.6 Shall provide an API to atomically update multiple video source to video plane mappings."},{"location":"halif/plane_control/current/plane_control/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IPlaneControl.aidl</code> Plane Control HAL interface which provides the central API video and graphics plane management. <code>IPlaneControlListener.aidl</code> Plane Control listener for callbacks. <code>AspectRatio.aidl</code> Enum list of aspect ratios. <code>Capabilities.aidl</code> Parcelable describing a single plane resource capabilities. <code>PlaneType.aidl</code> Enum list of plane types. <code>Property.aidl</code> Enum list of plane properties. <code>PropertyKVPair.aidl</code> Parcelable of a single property key and value pair. <code>SourcePlaneMapping.aidl</code> Parcelable of a single source to plane mapping. <code>SourceType.aidl</code> Enum list of source types used in source plane mapping."},{"location":"halif/plane_control/current/plane_control/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-plane_control.service</code> unit file is provided by the vendor layer to start the service and should include Wants or Requires  directives to start any platform driver services it depends upon.</p> <p>The Plane Control service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the <code>IPlaneControl</code> interface with the Service Manager using the String <code>IPlaneControl.serviceName</code> and immediately become operational.</p>"},{"location":"halif/plane_control/current/plane_control/#product-customization","title":"Product Customization","text":"<p>The <code>IPlaneControl.getCapabilities()</code> returns an array of <code>Capabilities</code> parcelables to uniquely represent all of the plane resources supported by the vendor layer.</p> <p>Typically, the plane index (resource ID) value starts at 0 for the first video plane and increments by 1 for each additional video plane, followed by the graphic plane(s).</p> <p>The <code>Capabilities</code> parcelable returned by the <code>IPlaneControl.getCapabilities()</code> function lists all capabilities supported by a plane resource. - Concurrent control of plane resources is allowed by multiple clients. The RDK middleware is responsible for ensuring only 1 controlling client is active at any given time.</p>"},{"location":"halif/plane_control/current/plane_control/#system-context","title":"System Context","text":"<p>The Plane Control service provides functionality to multiple clients which exist inside the RDK middleware.</p> <p>Typically, video planes are linked to video sources when a GStreamer pipeline is created in the RDK middleware. The geometry of the video planes can be manipulated by the Window Manager through a separate client connection.</p> <p>Native graphics plane windows are taken by the RDK middleware compositor to link graphics display updates from EGL to the hardware.</p> <pre><code>flowchart TD\n    %% --- Components ---\n    RDKClientComponent[\"RDK Client Component\"]\n    IPlaneControlListener[\"IPlaneControlListener\"]\n\n    subgraph Connections[\"Vendor Layer\"]\n        subgraph IPlaneControlHAL[\"Plane Control HAL\"]\n            IPlaneControl[\"IPlaneControl\"]\n        end\n\n        subgraph OutputComponents[\" \"]\n            VideoPlane0[\"Video Plane 0\"]\n            VideoPlane1[\"Video Plane 1\"]\n            VideoPlane2[\"Graphics Plane 2\"]\n        end\n    end\n\n    %% --- Function Calls Over Single Line ---\n    RDKClientComponent -- getCapabilities()\n    getNativeGraphicsWindowHandle()\n    releaseNativeGraphicsWindowHandle()\n    flipGraphicsBuffer()\n    setVideoSourceDestinationPlaneMapping()\n    getVideoSourceDestinationPlaneMapping()\n    getProperty()\n    setProperty()\n    getPropertyMulti()\n    setPropertyMultiAtomic()\n    registerListener()\n    unregisterListener()\n     --&gt; IPlaneControl\n\n    IPlaneControlListener --&gt; RDKClientComponent\n\n    %% --- Wrapped Connections in a Subgraph ---\n        IPlaneControl --&gt; IPlaneControlListener\n        IPlaneControl -.-&gt; VideoPlane0\n        IPlaneControl -.-&gt; VideoPlane1\n        IPlaneControl -.-&gt; VideoPlane2\n\n    %% --- Apply Colors ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IPlaneControl:::wheat\n    IPlaneControlListener:::wheat\n    VideoPlane0:::green\n    VideoPlane1:::green\n    VideoPlane2:::green\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#resource-management","title":"Resource Management","text":"<p>The <code>IPlaneControl</code> interface provides access to all of the plane resource instances offered by the platform.</p> <p>Each plane resource instance is assigned a unique integer resource ID or index, which is used in the <code>IPlaneControl</code> function calls to indicate which plane is being accessed.</p> <p>Any number of clients can access the <code>IPlaneControl</code> service and access plane settings.</p> <p>The diagram below shows the relationship between the interface and resource instances.</p> <pre><code>graph\n\n    %% --- Encapsulating Everything Inside \"Audio Decoder HAL\" ---\n    subgraph Connections[\"Plane Control HAL\"]\n        IPlaneControl(\"IPlaneControl\")\n\n        %% --- Audio Decoder Manager Service Spawns Instances ---\n        IPlaneControl --&gt; ADI1(\"Video Plane &lt;br&gt; RESOURCE_ID = 0\")\n        IPlaneControl --&gt; ADI2(\"Video Plane &lt;br&gt; RESOURCE_ID = 1\")\n        IPlaneControl --&gt; ADI3(\"Graphics Plane &lt;br&gt; RESOURCE_ID = 2\")\n    end\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n\n\n    %% --- Apply Colors ---\n    class IPlaneControl manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/plane_control/current/plane_control/#plane-types-and-fixed-configuration","title":"Plane Types and Fixed Configuration","text":"<p>For the 2 types of planes (video and graphics) there are fixed configurations which they are expected to hold.</p> Plane Type Fixed Configuration Video If there is no video to display on a visible plane, then it shall render transparent black. The z-order is dynamic only for video planes. Primary video plane shall always be listed at resource index 0. Graphics Calls to <code>getNativeGraphicsWindowHandle()</code> will return a handle that can be used to connect with EGL display implementations."},{"location":"halif/plane_control/current/plane_control/#video-planes","title":"Video Planes","text":"<p>Video sources (video sinks, HDMI inputs, and composite inputs) can be mapped to destination video planes for presentation.</p> <p>A video plane can only be mapped to one video source at a time, and any attempt to set additional video sources shall fail.</p> <p>A call to the <code>setVideoSourceDestinationPlaneMapping()</code> allows for multiple sources and planes to be mapped and can perform complex operations such as plane swapping between main and PIP video.</p> <p>The sequence of calls below shows how man video and PIP video can be mapped separately and then swapped.</p>"},{"location":"halif/plane_control/current/plane_control/#main-video-on-plane-0","title":"Main Video on Plane 0","text":"<ul> <li>The main video using video sink 0 is displayed on video plane 0. </li> <li>AV playback is started.</li> </ul> <pre><code>SourcePlaneMapping[] =\n{\n    sourceType = \"SOURCE_VIDEO_SINK\",\n    sourceIndex = 0,\n    destinationPlaneIndex = 0\n}\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#2-pip-video-on-plane-1","title":"2. PIP Video on Plane 1","text":"<ul> <li>The PIP video using video sink 1 is displayed on video plane 1.</li> <li>AV playback is started.</li> </ul> <pre><code>SourcePlaneMapping[] =\n{\n    sourceType = \"SOURCE_VIDEO_SINK\",\n    sourceIndex = 1,\n    destinationPlaneIndex = 1\n}\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#3a-swapping-main-and-pip-planes","title":"3a. Swapping Main and PIP Planes","text":"<ul> <li>First variant: The destination plane indices for main and PIP are swapped in a single call.</li> </ul> <pre><code>SourcePlaneMapping[] =\n{\n  sourceType = \"SOURCE_VIDEO_SINK\",\n  sourceIndex = 0,\n  destinationPlaneIndex = 1\n},\n{\n  sourceType = \"SOURCE_VIDEO_SINK\",\n  sourceIndex = 1,\n  destinationPlaneIndex = 0\n}\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#3b-unmapping-main-and-moving-pip","title":"3b. Unmapping Main and Moving PIP","text":"<ul> <li>Second variant: The destination plane index for PIP is moved to plane 0 and main is unmapped.</li> </ul> <pre><code>SourcePlaneMapping[] =\n{\n    sourceType = \"SOURCE_VIDEO_SINK\",\n    sourceIndex = 0,\n    destinationPlaneIndex = -1 // -1 indicates unmapping\n},\n{\n    sourceType = \"SOURCE_VIDEO_SINK\",\n    sourceIndex = 1,\n    destinationPlaneIndex = 0\n}\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#stopping-video-display","title":"Stopping Video Display","text":"<p>When video is being stopped, the video source must also be unmapped from the plane.</p> <p>The plane unmapping can technically be performed before or after the video source is stopped.</p> <p>The <code>setVideoSourceDestinationPlaneMapping()</code> function can be used to unmap one or more video sources from planes.</p> <ul> <li>Video sink 0 is unmapped from plane 0.</li> </ul> <pre><code>SourcePlaneMapping[]=\n{\n    sourceType = SOURCE_VIDEO_SINK, \n    sourceIndex = 0, \n    destinationPlaneIndex = -1\n}\n</code></pre>"},{"location":"halif/plane_control/current/plane_control/#z-order","title":"Z-Order","text":"<p>The default z-order for planes is linked to their resource ID (index).</p> <p>The z-order can be changed by setting the <code>ZORDER</code> property on a plane.</p> <p>Higher z-order planes display over the top of lower z-order planes.</p> <p>A virtual background plane of opaque black or ultra-black (RGB=0,0,0 or YUV=0,0,0) shall be used to display when no plane pixel is visible above it.</p> <p>The diagram below shows a typical default plane resource configuration for 2 video planes and a single graphics plane.</p> <p></p>"},{"location":"halif/plane_control/current/plane_control/#compositor","title":"Compositor","text":"<p>The compositor is a platform component responsible for blending the raster in the visible planes using z-order and alpha settings to produce a single output display image.</p> <p>For STB devices the display image is scaled and output over HDMI and for TV devices it is scaled and displayed on the panel.</p> <p>There is explicit HAL API exposed for the compositor as it is expected to be configured and managed privately by the vendor layer implementation based on the plane properties.</p>"},{"location":"halif/plane_control/current/plane_control/#plane-dimensions-geometry-control","title":"Plane Dimensions &amp; Geometry Control","text":"<p>When properties affecting the plane geometry are changed by the client, they shall take immediate effect on the next available vsync.</p> <p>For video planes, if there is already a video frame displayed on a plane that remains visible, then it shall be updated to reflect the new geometry settings.</p> <p>The frameWidth and frameHeight in the Capabilities specify the pixel coordinate system of the plane reference frame, when used for positioning and scaling the plane.  The plane properties X, Y, WIDTH and HEIGHT are all defined in terms of the reference frame geometry.</p> <p>The maxWidth and maxHeight specify the maximum size the plane can be scaled to within the reference frame.</p> <p>While a primary video plane commonly supports full screen display (maxWidth=frameWidth and maxHeight=frameHeight), it may not always be the case for other video planes.</p> <p>If a plane has a size limitation (e.g. 1/4 screen) then the maxWidth and maxHeight must reflect this limitation. </p> <p>There is no limitation on the positioning of a plane within its reference frame.</p> <p></p>"},{"location":"halif/plane_control/current/plane_control/#alpha-blending","title":"Alpha Blending","text":"<p>Where a plane is configured to use a translucent alpha setting (<code>Property::ALPHA = 1..254</code>), the porter-duff operation shall be <code>OVER</code> using pre-multiplied alpha.</p>"},{"location":"halif/plane_control/current/plane_control/#plane-display-latency","title":"Plane Display Latency","text":"<p>The <code>vsyncDisplayLatency</code> in <code>Capabilities</code> indicates the delay of video or graphics presentation changes before final output.</p> <p>For example, video planes may have latency incurred by vendor specific PQ pipelines or MEMC processing and graphics planes may have latency incurred by vendor specific double buffering or composition.</p> <p>Understanding the latencies for each plane is important when performing display synchronisation between different planes.</p> <p>For example, when subtitles on the graphics plane need to be displayed with a particular video frame the application rendering the subtitles needs to understand any latency difference between a video plane and the graphics plane to compensate for any differences.</p>"},{"location":"halif/sec_api/current/sec_api/","title":"Secure API (sec_api)","text":""},{"location":"halif/sec_api/current/sec_api/#references","title":"References","text":"<p>Info</p> Interface Definition secapi/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-secapi.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/sec_api/current/sec_api/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/sec_api/current/sec_api/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/sensor/current/sensor/","title":"Sensor","text":""},{"location":"halif/sensor/current/sensor/#references","title":"References","text":"<p>Info</p> Interface Definition sensor/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-sensor.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"halif/sensor/current/sensor/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"halif/sensor/current/sensor/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"halif/video_decoder/current/video_decoder/","title":"Video Decoder","text":"<p>The Video Decoder HAL service provides interfaces for passing compressed video to the vendor layer for decoding. If the service supports secure audio processing, it may also handle secure buffers.</p> <p>The output of the video decoder can follow two paths:</p> <ul> <li>Non-tunnelled mode \u2013 The decoded video is returned to the RDK media pipeline as a video frame buffer along with metadata.</li> <li>Tunnelled mode \u2013 The decoded video is passed directly through the vendor layer.</li> </ul> <p>The choice between tunnelled and non-tunnelled video does not affect the operational mode of the audio decoder. It is possible to have tunnelled video while using non-tunnelled audio.</p> <p>The video decoder's operational mode can be selected by the client upon initialization.</p> <p>The RDK middleware GStreamer pipeline includes a dedicated RDK Video Decoder element, specifically designed to integrate with the Video Decoder HAL interface.</p>"},{"location":"halif/video_decoder/current/video_decoder/#references","title":"References","text":"<p>Info</p> Interface Definition video_decoder/current API Documentation TBD HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-video_decoder.service VTS Tests TBC Reference Implementation - vComponent https://github.com/rdkcentral/rdk-halif-aidl/tree/main/videodecoder/current"},{"location":"halif/video_decoder/current/video_decoder/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Video Sink</li> <li>AV Buffer</li> <li>Session State Management</li> </ul>"},{"location":"halif/video_decoder/current/video_decoder/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.VIDEODECODER.1 Video elementary stream data shall be passed to the video decoder to be decoded as frames. Decontainerisation and demuxing are performed by the RDK AV pipeline before the video decoder. HAL.VIDEODECODER.2 Encoded video data is passed one frame at a time to the video decoder in stream, file or broadcast delivered order. HAL.VIDEODECODER.3 Decoded video frames are output from the decoder in presentation order. HAL.VIDEODECODER.4 Only one video frame shall be output per output frame callback from the video decoder. HAL.VIDEODECODER.5 Encoded video data shall be passed in shared memory buffers by handle and shall be in either secure or non-secure buffer types. The pool implementation of memory buffers for secure and non-secure memory is implemented by the vendor. See AV Buffer for details. HAL.VIDEODECODER.6 The video decoder shall support a secure video pipeline where encoded and decoded data in secure buffers shall not be exposed to any process outside of the secure video pipeline. Secure coded video input buffers to the video decoder shall always be output in secure decoded frame buffers. HAL.VIDEODECODER.7 The video decoder shall operate in either a tunnelled or non-tunnelled operational mode. Only one of these operational modes needs be supported by the video decoder. HAL.VIDEODECODER.8 The video decoder may optionally operate in a textured video operational mode. HAL.VIDEODECODER.9 The video decoder HAL shall report on the number of video decoder instances supported and their capabilities. HAL.VIDEODECODER.10 An opened video decoder instance shall be configured to decode only a single codec type. No dynamic video codec switching is supported while open.\u00a0 A video decoder instance must be closed and reopened to change the codec type. HAL.VIDEODECODER.11 The video decoder shall be able to decode back to back I-frames. Used in I-frame trick modes. HAL.VIDEODECODER.12 The video decoder shall discard any frames until the first reference frame has been received. HAL.VIDEODECODER.13 If a client process exits, the Video Decoder server shall automatically stop and close any Video Decoder instance controlled by that client."},{"location":"halif/video_decoder/current/video_decoder/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IVideoDecoderManager.aidl</code> Video Decoder Manager HAL which provides access to\u00a0IVideoDecoder\u00a0resource instances. <code>IVideoDecoder.aidl</code> Video\u00a0Decoder interface for a single video decoder resource instance. <code>IVideoDecoderController.aidl</code> Controller interface for an\u00a0IVideoDecoder\u00a0resource instance. <code>IVideoDecoderControllerListener.aidl</code> Listener callbacks interface to clients from an\u00a0IVideoDecoderController. <code>IVideoDecoderEventListener.aidl</code> Listener callbacks interface to clients from an\u00a0IVideoDecoder. <code>Capabilities.aidl</code> Parcelable describing the capabilities of an\u00a0IVideoDecoder\u00a0resource instance. <code>Codec.aidl</code> Enum list of video codecs. <code>CodecCapabilities.aidl</code> Parcelable describing the capabilities of a codec supported by an\u00a0IVideoDecoder. <code>CSDVideoFormat.aidl</code> Enum list of video codec specific data formats. <code>DynamicRange.aidl</code> Enum list of dynamic ranges. <code>ErrorCode.aidl</code> Enum list of video decoder error codes. <code>FrameMetadata.aidl</code> Parcelable of video frame metadata passed from the video decoder. <code>OperationalMode.aidl</code> Enum list of video decoder operational modes. <code>PixelFormat.aidl</code> Enum list of video pixel formats. <code>Property.aidl</code> Enum list of video decoder properties. <code>PropertyKVPair.aidl</code> Parcelable of a Property and PropertyValue pair. <code>ScanType.aidl</code> Enum list of video frame scan types."},{"location":"halif/video_decoder/current/video_decoder/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-video_decoder_manager.service</code> unit file is provided by the vendor layer to start the service and should include\u00a0 Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The Video Decoder Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the\u00a0<code>IVideoDecoderManager</code>\u00a0interface with the Service Manager\u00a0using the String <code>IVideoDecoderManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/video_decoder/current/video_decoder/#product-customization","title":"Product Customization","text":"<p>The\u00a0<code>IVideoDecoderManager.getVideoDecoderIds()</code>\u00a0should return an array of\u00a0<code>IVideoDecoder.Id</code>\u00a0parcelables to uniquely represent all of the video decoder resources supported by the vendor layer.\u00a0 Typically, the ID value starts at 0 for the first video decoder and increments by 1 for each additional video decoder.</p> <p>The\u00a0Capabilities\u00a0parcelable returned by the\u00a0IVideoDecoder.getCapabilities()\u00a0function lists all of the\u00a0Codec types and DynamicRange types supported by this video decoder instance and indicates if the secure audio path can be used.</p> <p>A video decoder instance may support any number of video codecs, but can only operate on one compressed video stream in an open session.\u00a0 Concurrent video decode requires multiple video decoder instances to be opened.</p>"},{"location":"halif/video_decoder/current/video_decoder/#system-context","title":"System Context","text":"<p>The Video Decoder HAL can provide functionality to multiple clients.</p> <p>Typically an RDK middleware GStreamer video decoder element will work with a single\u00a0IVideoDecoder\u00a0instance and pass it\u00a0AV Buffer\u00a0handles for decode.</p> <p>The RDK middleware resource management system will examine the number of video decoder resources and their capabilities, so they can be allocated to streaming sessions.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IVideoDecoderEventListener(\"IVideoDecoderEventListener\")\n        IVideoDecoderControllerListener(\"IVideoDecoderControllerListener\")\n    end\n    subgraph IVideoDecoderHAL[\"Video Decoder HAL\"]\n        IVideoDecoderManager(\"IVideoDecoderManager &lt;br&gt;(Service)\")\n        IVideoDecoder(\"IVideoDecoder &lt;br&gt;(Instance)\")\n        IVideoDecoderController(\"IVideoDecoderController &lt;br&gt;(Instance)\")\n    end\n    subgraph OutputComponents[\"Output\"]\n        VideoFramePool(\"Video Frame Pool\")\n        VideoFrameQueue[\"Video Frame Queue\"]\n    end\n    RDKClientComponent -- createVideoPool() &lt;br&gt; alloc() &lt;br&gt; free() &lt;br&gt; destroyPool() --&gt; IAVBuffer\n    RDKClientComponent -- getVideoDecoderIds() &lt;br&gt; getVideoDecoder() getSupportedOperationModes()--&gt; IVideoDecoderManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getProperty() &lt;br&gt; getPropertyMulti() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() &lt;br&gt; registerEventListener() &lt;br&gt; unregisterEventListener()--&gt; IVideoDecoder\n    RDKClientComponent -- registerEventListener() &lt;br&gt; unregisterEventListener() --&gt; IVideoDecoder\n    RDKClientComponent -- start() &lt;br&gt; stop() &lt;br&gt; setProperty() &lt;br&gt; decodeBuffer() &lt;br&gt; flush() &lt;br&gt; signalDiscontinuity() &lt;br&gt; signalEOS() &lt;br&gt; parseCodecSpecificData() --&gt; IVideoDecoderController\n    IVideoDecoderManager --&gt; IVideoDecoder --&gt; IVideoDecoderController\n    IVideoDecoder -- onStateChanged() &lt;br&gt; onDecodeError() --&gt; IVideoDecoderEventListener\n    IVideoDecoderEventListener --&gt; RDKClientComponent\n    IVideoDecoderControllerListener --&gt; RDKClientComponent\n    IVideoDecoderController -- onFrameOutput() --&gt; IVideoDecoderControllerListener\n    IVideoDecoderController -- onUserDataOutput() --&gt; IVideoDecoderControllerListener\n    IVideoDecoderController -- alloc --&gt; VideoFramePool\n    IVideoDecoderManager -- free --&gt; IAVBuffer\n    IVideoDecoderController -- tunneled Video --&gt; VideoFrameQueue\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IVideoDecoderManager:::wheat\n    IVideoDecoderController:::wheat\n    IVideoDecoder:::wheat\n    IAVBuffer:::green\n    IVideoDecoderControllerListener:::wheat\n    IVideoDecoderEventListener:::wheat\n    VideoFramePool:::green\n    VideoFrameQueue:::green</code></pre>"},{"location":"halif/video_decoder/current/video_decoder/#resource-management","title":"Resource Management","text":"<p>The\u00a0<code>IVideoDecoderManager</code> provides access to one or more\u00a0IVideoDecoder\u00a0sub-interfaces which each represent a video decoder resource instance offered by the platform.</p> <p>Each\u00a0IVideoDecoder\u00a0resource instance is assigned a unique integer ID, which is used in\u00a0IVideoDecoder.Id.value\u00a0and can be read from\u00a0RESOURCE_ID\u00a0using the\u00a0IVideoDecoder.getProperty()\u00a0function.</p> <p>To use an\u00a0IVideoDecoder\u00a0resource instance it must be opened by a client, which returns an\u00a0IVideoDecoderController\u00a0sub-interface to access buffer decoding and additional state controls.</p> <p>Important</p> <p>Any number of clients can access the\u00a0<code>IVideoDecoderManager</code>\u00a0service and get access to the\u00a0IVideoDecoder\u00a0sub-interfaces, but only 1 client can\u00a0open()\u00a0an\u00a0IVideoDecoder\u00a0and access its\u00a0IVideoDecoderController\u00a0sub-interface.</p> <p>The diagram below shows the relationship between the interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"Video Decoder HAL\" ---\n    IVideoDecoderManager(\"IVideoDecoderManager\")\n\n    %% --- Video Decoder Manager Service Spawns Instances ---\n    IVideoDecoderManager --&gt; ADI1(\"IVideoDecoder &lt;br&gt; ID = 0\")\n    IVideoDecoderManager --&gt; ADI2(\"IVideoDecoder &lt;br&gt; ID = 1\")\n    IVideoDecoderManager --&gt; ADI3(\"IVideoDecoder &lt;br&gt; ID = 2\")\n\n    %% --- Each Instance Has a Controller ---\n    ADI1 --&gt; ADIC1(\"IVideoDecoderController\")\n    ADI2 --&gt; ADIC2(\"IVideoDecoderController\")\n    ADI3 --&gt; ADIC3(\"IVideoDecoderController\")\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n    %% --- Apply Colors ---\n    class IVideoDecoderManager manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/video_decoder/current/video_decoder/#codec-support","title":"Codec Support","text":"<p>Each RDK product defines the video codecs it requires for IP streaming, apps and broadcast.</p> <p>Some codecs are subject to third party licensing agreements and may therefore only be included in some products.</p> <p>The list below indicates the list of video codecs which are mandatory for the platform to support as hardware/vendor decode (potentially secure).</p> Codec Typical Use Case Hardware/Vendor Support MPEG-2 H.262 up to 1080P@60fps Broadcast streams, IP streams, files Mandatory AVC H.264 upto HP@L5.1 up to 4Kx2K@30fps Broadcast streams, IP streams, files Mandatory HEVC H.265 upto MP-10@L5.1 up to 4Kx2K@60fps Broadcast streams, IP streams, files Mandatory VP9 upto Profile 2-10 up to 4Kx2K@60fps YouTube, WebM, files Mandatory AV1 upto MP-10@L5.1 up to 4Kx2K@60fps YouTube, WebM, files Mandatory"},{"location":"halif/video_decoder/current/video_decoder/#encrypted-video-playback","title":"Encrypted Video Playback","text":"<p>Encrypted video is copied into a non-secure buffer by the application and then decrypted into a secure buffer. The secure buffer is then decoded by a video decoder accessed through the\u00a0<code>IVideoDecoderController</code>\u00a0interface.</p>"},{"location":"halif/video_decoder/current/video_decoder/#secure-video-processing","title":"Secure Video Processing","text":"<p>Secure video processing (SVP) is a requirement for RDK-E. Video decoder instances shall declare themselves as secure or non-secure by setting\u00a0<code>Capabilities.supportsSecure</code> appropriately.</p> <p>A secure video decoder shall be able to handle secure AV buffers and decoded video frames output from the decoder shall be either contained in secure AV buffers or securely tunnelled in the vendor layer.</p> <p>If any video decoder supports SVP in non-tunnelled mode then the Video Sink HAL must also support SVP to be able to process secure AV buffers of decoded video frames.</p> <p>Markdown Output:</p>"},{"location":"halif/video_decoder/current/video_decoder/#operational-modes","title":"Operational Modes","text":"<p>There are 3 modes that video decoders can operate in.\u00a0 The\u00a0<code>IVideoDecoderManager.getSupportedOperationalModes()</code>\u00a0function must return all operational modes supported by the video decoders in the system.</p> <p>This set of advertised operational modes must operate on all video decoder instances.</p> <p>Tunnelled and non-tunnelled modes cannot operate at the same time.\u00a0 It is optional for video decoders to support both modes as options, but at least one of them must be supported.</p> <p>If both are supported then there shall never be a dynamic switch between the 2 modes while STARTED.</p> <p>The\u00a0<code>OPERATIONAL_MODE</code> property controls the operational mode the video decoder shall use.</p> <p>The enum\u00a0<code>OperationalMode</code>\u00a0provides the constants used to specify operational modes and allows for bitwise-or of multiple values.</p> <p>The video decoder may switch operational modes at any time while in a READY or STARTED\u00a0state.</p> <p>In all modes, AV buffers containing compressed video are passed into the video decoder through calls to <code>decodeBuffer()</code>.</p> Operational Mode Description <code>TUNNELLED</code> Decoded video frames are passed directly to the linked video sink and video plane for rendering. The vendor layer is responsible for AV sync where audio and video streams are linked in the same pipeline. Decoded video frames are never received back in frame buffers over <code>IVideoDecoderControllerListener.onFrameOutput()</code>, but the <code>FrameMetadata</code>\u00a0must still be returned in the usual way. All calls to <code>onFrameOutput()</code> shall have the <code>frameBufferHandle</code> set to -1 to indicate no video frame buffer handle is being passed back. It is optional for video decoders to support tunnelled operational mode. If supported, tunnelled mode may be dynamically enabled or disabled while the video decoder is <code>READY</code> or <code>STARTED</code>\u00a0and may run concurrently with graphics texture mode. Tunnelled mode cannot be used at the same time as non-tunnelled mode. <code>NON_TUNNELLED</code> Decoded video frames are received back in video frame buffers over <code>IVideoDecoderListener.onFrameOutput()</code>. Frames must be received in presentation order. It is optional for video decoders to support non-tunnelled operational mode. If supported, non-tunnelled mode may be dynamically enabled or disabled while the video decoder is <code>READY</code> or <code>STARTED</code>\u00a0and may run concurrently with graphics texture mode. Non-tunnelled mode cannot be used at the same time as tunnelled mode. <code>GRAPHICS_TEXTURE</code> Video frames are converted to NV12 textures. It is optional for video decoders to support graphics texture operational mode. If supported, graphics texture mode may be dynamically enabled or disabled while the video decoder is <code>READY</code> or <code>STARTED</code>\u00a0and may run concurrently with tunnelled or non-tunnelled mode."},{"location":"halif/video_decoder/current/video_decoder/#frame-metadata","title":"Frame Metadata","text":"<p>As video frames are decoded, the metadata which related to the frames must be passed to the client over\u00a0<code>IVideoDecoderControllerListener.onFrameOutput()</code>.</p> <p>In non-tunnelled operating mode, the frame buffer handle and metadata related to the frame must be passed in the same <code>onFrameOutput()</code>\u00a0call.</p> <p>To conserve CPU load, the frame metadata is only passed with the first decoded frame after a\u00a0<code>start()</code>, the first decoded frame after a\u00a0<code>flush()</code>\u00a0or if the frame\u00a0metadata changes.</p> <p>If the frame metadata does not need to be passed, then the\u00a0<code>@nullable FrameMetadata metadata</code>\u00a0parameter should be passed as null in <code>onFrameOutput()</code>.</p> <p>The same rules for frame metadata apply to all operational modes.</p> <p>When operating exclusively in tunnelled mode, if there is no frame metadata to be passed, then no call to <code>onFrameOutput()</code>\u00a0should be made because there is no frame buffer handle or frame metadata to return to the client.</p>"},{"location":"halif/video_decoder/current/video_decoder/#low-latency-mode","title":"Low Latency Mode","text":"<p>A media pipeline is operating in low latency mode when the video decoder and audio decoder (if present) are set with a\u00a0<code>LOW_LATENCY_MODE</code>\u00a0property to 1 (enabled).</p>"},{"location":"halif/video_decoder/current/video_decoder/#video-stream-discontinuities","title":"Video Stream Discontinuities","text":"<p>Where the client has knowledge of PTS discontinuities in the video stream, it shall call\u00a0<code>IVideoDecoderController.signalDiscontinuity()</code> between the AV buffers passed to\u00a0<code>decodeBuffer()</code>.</p> <p>For the first input AV Buffer video frame passed in for decode after the discontinuity, it shall indicate the discontinuity in its next output\u00a0<code>FrameMetadata</code>.</p>"},{"location":"halif/video_decoder/current/video_decoder/#end-of-stream-signalling","title":"End of Stream Signalling","text":"<p>When the client knows it has delivered the final video frame buffer to a decoder it shall then call\u00a0<code>IVideoDecoderController.signalEOS()</code>.</p> <p>The Video Decoder shall continue to decode all buffers previously passed for decode, but no further video buffers should be expected unless the video decoder is first stopped and restarted or is flushed.</p> <p>The Video Decoder shall emit a <code>FrameMetadata</code>\u00a0with\u00a0<code>endOfStream=true</code>\u00a0after all video frames have been output from the decoder.</p>"},{"location":"halif/video_decoder/current/video_decoder/#decoded-video-frame-buffers","title":"Decoded Video Frame Buffers","text":"<p>Decoded video frame buffers are only passed from the video decoder to the client when operating in the non-tunnelled operational mode.</p> <p>If the input AV Buffer that contained the coded video frame was passed in a secure buffer, then the corresponding decoded video frame must be output in a secure video frame buffer.</p> <p>Video frame buffers are passed back as handles in the\u00a0<code>IVideoDecoderControllerListener.onFrameOutput()</code>\u00a0function\u00a0<code>frameBufferHandle</code>\u00a0parameter.\u00a0 If no frame buffer handle is available to pass but the call needs to be made to provide updated FrameMetadata then <code>-1</code> shall be passed as the handle value.</p> <p>The format of the data in the decoded video frame buffer is determined by the vendor driver implementation and does not need to be understood by the RDK middleware.</p> <p>The frame buffer handle is later passed to the Video Sink for queuing before presentation and is then freed.</p> <p>The vendor layer is expected to manage the pool of decoded frame buffers privately and report its size in the <code>OUTPUT_FRAME_POOL_SIZE</code>\u00a0property.</p> <p>If the frame buffer pool is empty then the video decoder cannot output the next decoded frame until a new frame buffer becomes available.\u00a0 While frame output is blocked, it is reasonable for the video decoder service to either buffer additional coded input buffers or to reject new calls to <code>decodeBuffer()</code>\u00a0with a false\u00a0return value.</p>"},{"location":"halif/video_decoder/current/video_decoder/#presentation-time-for-video-frames","title":"Presentation Time for Video Frames","text":"<p>The presentation time base units for video frames is nanoseconds and passed in an int64 (long in AIDL definition) variable type. Audio buffers shared the same time base units of nanoseconds.</p> <p>When coded video frames are passed in through AV Buffer handles to\u00a0<code>IVideoDecoderController.decodeBuffer()</code> the <code>nsPresentationTime</code>\u00a0parameter represents the video frame presentation time.</p> <p>Calls to\u00a0<code>IVideoDecoderControllerListener.onFrameOutput()</code>\u00a0with frame buffer handles (non-tunnelled mode) and/or frame metadata shall use the same\u00a0<code>nsPresentationTime</code>.</p> <p>The video decoder shall output frames in presentation order regardless of the order of input frames which is ordered by the encoder.</p>"},{"location":"halif/video_decoder/current/video_decoder/#video-decoder-states","title":"Video Decoder States","text":"<p>The Video Decoder HAL follows the standard Session State Management paradigm.</p> <p>When an Video Decoder session enters a FLUSHING or STOPPING transitory state it shall free any AV buffers it is holding.</p> <p>The sequence diagram below shows the behaviour of the callbacks.</p> <pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK Video Decoder\n        participant Client as RDK Client\n        participant IVideoDecoderEventListener\n        participant IVideoDecoderControllerListener\n    end\n    box rgb(249,168,37) Video Decoder Server\n        participant ADC as IVideoDecoder\n        participant Controller as IVideoDecoderController\n    end\n    box rgb(67,160,71) Video AV Buffer\n        participant IAVBuffer as IAVBuffer\n    end\n\n    Client-&gt;&gt;ADC: registerEventListener(IVideoDecoderEventListener)\n\n    Note over ADC: open() transitions from CLOSED -&gt; OPENING -&gt; READY\n\n    Client-&gt;&gt;ADC: open(IVideoDecoderControllerListener)\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(CLOSED -&gt; OPENING)\n    ADC-&gt;&gt;Controller: new\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(OPENING -&gt; READY)\n    ADC--&gt;&gt;Client: IVideoDecoderController\n\n    Note over ADC: start() transitions from READY -&gt; STARTING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: start()\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(READY -&gt; STARTING)\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(STARTING -&gt; STARTED)\n\n    Note over Client: Client can now&lt;br&gt;send AV buffers\n\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=1)\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=2)\n    Controller--&gt;&gt;IVideoDecoderControllerListener: onFrameOutput(pts, frameBufferHandle=1000, metadata)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1)\n\n    Note over ADC: flush() transitions from STARTED -&gt; FLUSHING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: flush()\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(STARTED -&gt; FLUSHING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=2)\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(FLUSHING -&gt; STARTED)\n\n    Client-&gt;&gt;Controller: decodeBuffer(pts, bufferHandle=3)\n\n    Note over ADC: stop() transitions from STARTED -&gt; STOPPING -&gt; READY\n\n    Client-&gt;&gt;Controller: stop()\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(STARTED -&gt; STOPPING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=3)\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(STOPPING -&gt; READY)\n\n    Note over ADC: close() transitions from READY -&gt; CLOSING -&gt; CLOSED\n\n    Client-&gt;&gt;ADC: close()\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(READY -&gt; CLOSING)\n    ADC-&gt;&gt;Controller: delete\n    ADC--&gt;&gt;IVideoDecoderEventListener: onStateChanged(CLOSING -&gt; CLOSED)\n\n    Client-&gt;&gt;ADC: unregisterEventListener(IVideoDecoderEventListener)</code></pre>"},{"location":"halif/video_sink/current/video_sink/","title":"Video Sink","text":"<p>The <code>Video Sink</code> HAL service manages the video frame queue and ensures timely delivery of video frames to a video plane, synchronized with the vendor\u2019s AV timing.</p> <p>In non-tunneled video modes, it facilitates the transfer of decoded video frame buffers to the video frame queue for processing.</p> <p>The RDK middleware\u2019s GStreamer pipeline includes a dedicated RDK Video Sink element, specifically designed to integrate seamlessly with the Video Sink HAL interface.</p>"},{"location":"halif/video_sink/current/video_sink/#references","title":"References","text":"<p>Info</p> Interface Definition video_sink/current API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-video_sink.service VTS Tests TBC Reference Implementation - vComponent https://github.com/rdkcentral/rdk-halif-aidl/tree/main/videosink/current"},{"location":"halif/video_sink/current/video_sink/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Video Decoder</li> <li>AV Buffer</li> <li>AV Clock</li> <li>Session State Management</li> </ul>"},{"location":"halif/video_sink/current/video_sink/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.VIDEOSINK.1 Shall manage a queue of video frames delivered from the client and held ready for presentation, often requiring AV lip sync. HAL.VIDEOSINK.2 Shall support flushing of the internal queue of video frames and notify the client when a flush operation has completed. HAL.VIDEOSINK.3 Shall internally manage the release of video frame handles back to the internal pool after they have finished being presented or during a flush. HAL.VIDEOSINK.4 Shall notify the client when the first frame is presented in the session once opened or after a flush operation. HAL.VIDEOSINK.5 Shall notify the client when a video underflow occurs. A video underflow condition is met if an expected frame is not queued in time for display. HAL.VIDEOSINK.6 Shall provide an API to expose the video sink resources for the client to discover. HAL.VIDEOSINK.7 HAL.VIDEOSINK.8 Video frames decoupled from video planes (destination plane -1) shall continue to be delivered and remain in sync with audio.\u00a0 When coupled to a video plane they shall immediately become visible and be in lip sync. To ensure if/when a video sink source is assigned to a video plane it appears in sync with audio. HAL.VIDEOSINK.9 If a client process exits, the Video Sink server shall automatically stop and close any <code>IVideoSink</code> instance controlled by that client."},{"location":"halif/video_sink/current/video_sink/#interface-definition","title":"Interface Definition","text":"Interface Definition File Description <code>IVideoSinkManager.aidl</code> Video Sink Manager HAL which provides access to\u00a0<code>IVideoSink</code>\u00a0resource instances. <code>IVideoSink.aidl</code> <code>IVideoSink</code> interface for a single video sink resource instance. <code>IVideoSinkController.aidl</code> Controller interface for an\u00a0<code>IVideoSink</code>\u00a0resource instance. <code>IVideoSinkControllerListener.aidl</code> Listener callbacks interface to clients from an\u00a0<code>IVideoSinkController</code>. <code>IVideoSinkEventListener.aidl</code> Listener callbacks interface to clients from an\u00a0<code>IVideoSink</code>. <code>Capabilities.aidl</code> Parcelable describing the capabilities of an\u00a0<code>IVideoSink</code>\u00a0resource instance. <code>Property.aidl</code> Enum list of video sink properties."},{"location":"halif/video_sink/current/video_sink/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-video_sink_manager.service</code> unit file is provided by the vendor layer to start the service and should include\u00a0Wants or Requires directives to start any platform driver services it depends upon.</p> <p>The Video Sink Manager service depends on the Service Manager to register itself as a service.</p> <p>Upon starting, the service shall register the\u00a0<code>IVideoSinkManager</code>\u00a0interface with the Service Manager\u00a0using the String <code>IVideoSinkManager.serviceName</code> and immediately become operational.</p>"},{"location":"halif/video_sink/current/video_sink/#product-customization","title":"Product Customization","text":"<p>The\u00a0<code>IVideoSinkManager.getVideoSinkIds()</code>\u00a0should return an array of\u00a0<code>IVideoSink.Id</code> parcelables to uniquely represent all of the video sink resources supported by the vendor layer.\u00a0 Typically, the ID value starts at 0 for the first video sink and increments by 1 for each additional video sink.</p> <p>The\u00a0<code>Capabilities</code>\u00a0parcelable returned by the\u00a0<code>IVideoSink.getCapabilities()</code> function lists all capabilities supported by this video sink instance.</p> <p>A video sink instance can only operate on one video stream in an open session.\u00a0 Concurrent video streams requires multiple video sink instances to be opened.</p>"},{"location":"halif/video_sink/current/video_sink/#system-context","title":"System Context","text":"<p>The Video Sink HAL can provide functionality to multiple clients.</p> <p>Typically an RDK middleware GStreamer video sink element will work with a single\u00a0<code>IVideoSink</code>\u00a0instance and pass it video frame buffers with associated metadata for display.</p> <p>The RDK middleware resource management system will examine the number of video sink resources and their capabilities, so they can be allocated to streaming sessions.</p> <pre><code>flowchart TD\n    RDKClientComponent(\"RDKClientComponent\")\n    subgraph Listeners[\"Listeners\"]\n        IVideoSinkEventListener(\"IVideoSinkEventListener\")\n        IVideoSinkControllerListener(\"IVideoSinkControllerListener\")\n    end\n    subgraph IVideoSinkHAL[\"Video Sink HAL\"]\n        IVideoSinkManager(\"IVideoSinkManager &lt;br&gt;(Service)\")\n        IVideoSink(\"IVideoSink &lt;br&gt;(Instance)\")\n        IVideoSinkController(\"IVideoSinkController &lt;br&gt;(Instance)\")\n    end\n    subgraph OutputComponents[\"Output\"]\n        VideoPresentation[\"Video Presentation\"]\n    end\n    VideoFramePool(\"Video Frame Pool\")\n    RDKClientComponent -- createVideoPool() &lt;br&gt; alloc() &lt;br&gt; free() &lt;br&gt; destroyPool() --&gt; IAVBuffer\n    RDKClientComponent -- getVideoSinkIds() &lt;br&gt; getVideoSink() getSupportedOperationModes()--&gt; IVideoSinkManager\n    RDKClientComponent -- getCapabilities() &lt;br&gt; getProperty() &lt;br&gt; getState() &lt;br&gt; open() &lt;br&gt; close() &lt;br&gt; registerEventListener() &lt;br&gt; unregisterEventListener()--&gt; IVideoSink\n    RDKClientComponent -- registerEventListener() &lt;br&gt; unregisterEventListener() --&gt; IVideoSink\n    RDKClientComponent -- setVideoDecoder() &lt;br&gt; getVideoDecoder() &lt;br&gt; start() &lt;br&gt; stop() &lt;br&gt; queueVideoFrame() &lt;br&gt; flush() &lt;br&gt; discardFramesUntil() --&gt; IVideoSinkController\n    IVideoSinkManager --&gt; IVideoSink --&gt; IVideoSinkController\n    IVideoSink -- onStateChanged() &lt;br&gt; onFistFrameRendered() &lt;br&gt; onEndOfStream() &lt;br&gt; onVideoUnderflow() &lt;br&gt; onVideoResumed() &lt;br&gt; onFlushComplete() --&gt; IVideoSinkEventListener\n    IVideoSinkEventListener --&gt; RDKClientComponent\n    IVideoSinkControllerListener --&gt; RDKClientComponent\n    IVideoSinkController -- onFrameOutput() --&gt; IVideoSinkControllerListener\n    IVideoSinkController -- onUserDataOutput() --&gt; IVideoSinkControllerListener\n    IVideoSinkController -- free() --&gt; VideoFramePool\n    IAVBuffer -- free() --&gt; VideoFramePool\n    IVideoSinkManager -- free() --&gt; IAVBuffer\n    IVideoSinkController -- tunneled Video --&gt; VideoPresentation\n\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef blue fill:#1565C0,stroke:#E0E0E0,stroke-width:2px,color:#E0E0E0;\n    classDef lightGrey fill:#616161,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef wheat fill:#FFB74D,stroke:#424242,stroke-width:2px,color:#000000;\n    classDef green fill:#4CAF50,stroke:#E0E0E0,stroke-width:2px,color:#FFFFFF;\n    classDef default fill:#1E1E1E,stroke:#E0E0E0,stroke-width:1px,color:#E0E0E0;\n\n    RDKClientComponent:::blue\n    IVideoSinkManager:::wheat\n    IVideoSinkController:::wheat\n    IVideoSink:::wheat\n    IAVBuffer:::green\n    IVideoSinkControllerListener:::wheat\n    IVideoSinkEventListener:::wheat\n    VideoPresentation:::green\n    VideoFramePool:::green</code></pre>"},{"location":"halif/video_sink/current/video_sink/#resource-management","title":"Resource Management","text":"<p>The\u00a0<code>IVideoSinkManager</code>\u00a0provides access to one or more\u00a0<code>IVideoSink</code>\u00a0sub-interfaces which each represent a video sink resource instance offered by the platform.</p> <p>Each\u00a0<code>IVideoSink</code>\u00a0resource instance is assigned a unique integer ID, which is used in the\u00a0<code>IVideoSink.Id.value</code>\u00a0and can be read from\u00a0<code>RESOURCE_ID</code>\u00a0using the\u00a0<code>IVideoSink.getProperty()</code>\u00a0function.</p> <p>To use an\u00a0<code>IVideoSink</code>\u00a0resource instance it must be opened by a client, which returns an\u00a0<code>IVideoSinkController</code>\u00a0sub-interface to access buffer queuing and additional state controls.</p> <p>Any number of clients can access the\u00a0<code>IVideoSinkManager</code>\u00a0service and get access to the\u00a0<code>IVideoSink</code>\u00a0sub-interfaces, but only 1 client can\u00a0<code>open()</code>\u00a0an\u00a0<code>IVideoSink</code>\u00a0and access its\u00a0<code>IVideoSinkController</code>\u00a0sub-interface.</p> <p>The diagram below shows the relationship between the interfaces and resource instances.</p> <pre><code>graph LR\n\n    %% --- Encapsulating Everything Inside \"Audio Decoder HAL\" ---\n    IVideoSinkManager(\"IVideoSinkManager\")\n\n    %% --- Audio Decoder Manager Service Spawns Instances ---\n    IVideoSinkManager --&gt; ADI1(\"IVideoSink &lt;br&gt; ID = 0\")\n    IVideoSinkManager --&gt; ADI2(\"IVideoSink &lt;br&gt; ID = 1\")\n    IVideoSinkManager --&gt; ADI3(\"IVideoSink &lt;br&gt; ID = 2\")\n\n    %% --- Each Instance Has a Controller ---\n    ADI1 --&gt; ADIC1(\"IVideoSinkController\")\n    ADI2 --&gt; ADIC2(\"IVideoSinkController\")\n    ADI3 --&gt; ADIC3(\"IVideoSinkController\")\n\n    %% --- High Contrast Styling (Rounded Box Simulation) ---\n    classDef background fill:#121212,stroke:none,color:#E0E0E0;\n    classDef manager fill:#388E3C,stroke:#1B5E20,stroke-width:2px,color:#FFFFFF;\n    classDef instance1 fill:#FFC107,stroke:#FF8F00,stroke-width:2px,color:#000000;\n    classDef instance2 fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#000000;\n    classDef instance3 fill:#F44336,stroke:#B71C1C,stroke-width:2px,color:#FFFFFF;\n    classDef controller fill:#00ACC1,stroke:#006064,stroke-width:2px,color:#000000;\n\n\n    %% --- Apply Colors ---\n    class IVideoSinkManager manager;\n    class ADI1 instance1;\n    class ADI2 instance2;\n    class ADI3 instance3;\n    class ADIC1 instance1;\n    class ADIC2 instance2;\n    class ADIC3 instance3;\n\n    %% --- Consistent Link Colors Per Instance ---\n    %% Yellow for Instance 0\n    linkStyle 0,3 stroke:#AA8800,stroke-width:2px;\n    %% Orange for Instance 1\n    linkStyle 1,4 stroke:#CC5500,stroke-width:2px;\n    %% Red for Instance 2\n    linkStyle 2,5 stroke:#CC2200,stroke-width:2px;</code></pre>"},{"location":"halif/video_sink/current/video_sink/#video-buffers","title":"Video Buffers","text":"<p>Video frame buffers only pass through the Video Sink while a video decoder is operating in non-tunnelled mode.</p> <p>Video frame buffers entering the Video Sink shall be delivered as\u00a0AV Buffer\u00a0handles with a presentation timestamp and metadata describing the video frame through the\u00a0<code>IVideoSinkController.queueVideoFrame()</code>\u00a0function.</p> <p>The video frame data in the buffer is vendor specific and is not decoded or understood by the RDK middleware.</p> <p>Once the data in a video frame buffer has been presented or upon a flush request, the Video Sink shall free handles by calling <code>IAVBuffer.free()</code>.</p>"},{"location":"halif/video_sink/current/video_sink/#secure-video-processing","title":"Secure Video Processing","text":"<p>Secure video processing (SVP) is a requirement for RDK-E.</p> <p>If any video decoder supports SVP in non-tunnelled mode then the Video Sink HAL must also support SVP to be able to process secure AV buffers of decoded video frames.</p>"},{"location":"halif/video_sink/current/video_sink/#end-of-stream-signalling","title":"End of Stream Signalling","text":"<p>The Video Decoder shall emit a\u00a0<code>FrameMetadata</code>\u00a0with\u00a0<code>endOfStream=true</code> after all video frames have been output from the decoder.</p> <p>For non-tunnelled video, the Video Sink shall be passed this metadata with the final video frame buffer or after the last video frame buffer has been queued by the RDK middleware client.</p> <p>All video frame buffers queued up in the Video Sink are expected to continue to be displayed in the usual way, but the Video Sink is not expecting any further video buffers to be queued.</p>"},{"location":"halif/video_sink/current/video_sink/#video-plane-mapping","title":"Video Plane Mapping","text":"<p>The display of decoded video frames are made on the video plane that has been mapped by a <code>SourceType::VIDEO_SINK</code> and index matching the Video Sink resource instance ID which was specified in the ID when <code>IVideoSinkManager.getVideoSink()</code>\u00a0was called and can also be read back in the <code>RESOURCE_ID</code>\u00a0property of the Video Sink.</p> <p>Setting and changing the mapping requires a call to <code>IPlaneControl.setVideoSourceDestinationPlaneMapping()</code>.</p> <p>Full details are covered in the Plane Control HAL.</p>"},{"location":"halif/video_sink/current/video_sink/#video-sink-states","title":"Video Sink States","text":"<p>The Video Sink HAL follows the standard\u00a0Session State Management\u00a0paradigm.</p> <p>When an Video Sink session enters a <code>FLUSHING</code> or <code>STOPPING</code> transitory state it shall free any AV buffers it is holding.</p> <p>The sequence diagram below shows the behavior of the callbacks.</p> <pre><code>sequenceDiagram\n    box rgb(30,136,229) RDK Video Sink\n        participant Client as RDK Client\n        participant IVideoSinkEventListener\n        participant IVideoSinkControllerListener\n    end\n\n    box rgb(249,168,37) Video Sink Server\n        participant ADC as IVideoSink\n        participant Controller as IVideoSinkController\n    end\n\n    box rgb(67,160,71) Video AV Buffer\n        participant IAVBuffer as IAVBuffer\n    end\n\n    Client-&gt;&gt;ADC: registerEventListener(IVideoSinkEventListener)\n\n    Note over Client,ADC: open() transitions&lt;br/&gt;from CLOSED -&gt; OPENING -&gt; READY\n\n    Client-&gt;&gt;ADC: open(IVideoSinkControllerListener)\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(CLOSED -&gt; OPENING)\n    ADC-&gt;&gt;Controller: new\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(OPENING -&gt; READY)\n    ADC--&gt;&gt;Client: IVideoSinkController\n    Client-&gt;&gt;Controller: setVideoDecoder(0)\n\n    Note over Client,ADC: start() transitions&lt;br/&gt;from READY -&gt; STARTING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: start()\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(READY -&gt; STARTING)\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(STARTING -&gt; STARTED)\n\n    Note over Client: Client can now queue&lt;br/&gt;Video frame buffers\n\n    Client-&gt;&gt;Controller: queueVideoFrame(pts, bufferHandle=1000, metadata)\n    Client-&gt;&gt;Controller: queueVideoFrame(pts, bufferHandle=1001, metadata)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1000)\n\n    Note over Client,ADC: flush() transitions&lt;br/&gt;from STARTED -&gt; FLUSHING -&gt; STARTED\n\n    Client-&gt;&gt;Controller: flush()\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(STARTED -&gt; FLUSHING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1001)\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(FLUSHING -&gt; STARTED)\n\n    Client-&gt;&gt;Controller: queueVideoFrame(pts, bufferHandle=1002, metadata)\n\n    Note over Client,ADC: stop() transitions&lt;br/&gt;from STARTED -&gt; STOPPING -&gt; READY\n\n    Client-&gt;&gt;Controller: stop()\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(STARTED -&gt; STOPPING)\n    Controller-&gt;&gt;IAVBuffer: free(bufferHandle=1002)\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(STOPPING -&gt; READY)\n\n    Note over Client,ADC: close() transitions&lt;br/&gt;from READY -&gt; CLOSING -&gt; CLOSED\n\n    Client-&gt;&gt;ADC: close()\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(READY -&gt; CLOSING)\n    ADC-&gt;&gt;Controller: delete\n    ADC--&gt;&gt;IVideoSinkEventListener: onStateChanged(CLOSING -&gt; CLOSED)\n\n    Client-&gt;&gt;ADC: unregisterEventListener(IVideoSinkEventListener)</code></pre>"},{"location":"introduction/aidl_and_binder/","title":"AIDL and Binder Overview in RDK HAL Architecture","text":""},{"location":"introduction/aidl_and_binder/#revision-history","title":"Revision History","text":"Version Date Author Changes 1.1 2025-06-17 Gerald Weatherup Updated to include more detail 1.0 2024-08-13 Lucien Kennedy-Lamb Initial version, AIDL + RDK Binder Context"},{"location":"introduction/aidl_and_binder/#purpose","title":"Purpose","text":"<p>This document provides a comprehensive overview of how Android Interface Definition Language (AIDL) is used within the RDK platform to define and implement Hardware Abstraction Layers (HALs) using Binder IPC. It includes motivation from the 2023 RDK HAL study, a system flowchart, and references to upstream documentation and tooling.</p>"},{"location":"introduction/aidl_and_binder/#system-architecture-flow","title":"System Architecture Flow","text":"<pre><code>flowchart LR\n    subgraph Client Side\n        App[\"Client\"]\n        AIDLClient[\"Proxy - AIDL-generated Stub\"]\n    end\n\n    subgraph Binder IPC Layer\n        BinderDriver[\"Binder Kernel Driver\"]\n    end\n\n    subgraph Service Side\n        AIDLStub[\"Stub - AIDL-generated Skeleton\"]\n        Service[\"Service Implementation\"]\n    end\n\n    App --&gt; AIDLClient\n    AIDLClient --&gt;|binder.transact| BinderDriver\n    BinderDriver --&gt;|onTransact| AIDLStub\n    AIDLStub --&gt; Service\n    Service --&gt;|result| AIDLStub\n    AIDLStub --&gt;|writeReply| BinderDriver\n    BinderDriver --&gt; AIDLClient\n    AIDLClient --&gt; App</code></pre>"},{"location":"introduction/aidl_and_binder/#rdk-hal-and-binder-design-goals","title":"RDK HAL and Binder Design Goals","text":"<p>The 2023 RDK HAL study outlined a next-generation HAL strategy built on the following principles:</p>"},{"location":"introduction/aidl_and_binder/#design-goals","title":"Design Goals","text":"<ul> <li>Clean Separation: Middleware and vendor code are modular and clearly separated.</li> <li>Process Isolation: Each HAL runs in its own process, improving stability and testability.</li> <li>Late Binding: Middleware and vendor components are linked only at runtime, not build-time.</li> <li>Versioning: AIDL interfaces support backward/forward compatibility.</li> <li>Performance: Binder provides efficient IPC suitable for real-time AV use cases.</li> <li>Testability: Vendor HALs can be tested in isolation without full stack.</li> <li>Debuggability: Rich tracing and tooling for diagnostics.</li> </ul>"},{"location":"introduction/aidl_and_binder/#binder-in-rdk-hals","title":"Binder in RDK HALs","text":"<p>Binder is a lightweight, low-latency IPC mechanism designed for Android and now adopted in RDK HALs.</p>"},{"location":"introduction/aidl_and_binder/#benefits-for-rdk-hals","title":"Benefits for RDK HALs","text":"<ul> <li>Process &amp; Memory Isolation: HAL crashes are contained, improving robustness.</li> <li>Late Binding: HAL and middleware components can be delivered and updated independently.</li> <li>Security &amp; Debugging: Binder integrates with SELinux and provides kernel-level tracing.</li> </ul> <p>Binder is implemented as a kernel driver and must be enabled at kernel configuration time.</p>"},{"location":"introduction/aidl_and_binder/#aidl-interface-definition-and-contract","title":"AIDL: Interface Definition and Contract","text":"<p>AIDL (Android Interface Definition Language) is the mechanism used to define HAL interfaces in RDK.</p>"},{"location":"introduction/aidl_and_binder/#why-aidl","title":"Why AIDL?","text":"<ul> <li>Contract Definition: Precise and language-agnostic description of available APIs.</li> <li>Tooling: Generates proxy and stub C++ classes that reduce boilerplate and human error.</li> <li>Binder Integration: Seamlessly marshals and unmarshals calls across process boundaries.</li> <li>Stable AIDL: Allows interface evolution with runtime version negotiation.</li> </ul>"},{"location":"introduction/aidl_and_binder/#key-concepts-and-benefits","title":"Key Concepts and Benefits","text":"Concept Description Interface Definition <code>.aidl</code> files describe the HAL\u2019s public API contract Code Generation AIDL compiler emits client and server glue code Proxy Client-side object that wraps Binder calls Stub Server-side object that receives and dispatches Binder transactions Versioning Stable AIDL supports version negotiation and compatibility Process Isolation Middleware and HALs run in separate processes Late Binding Middleware doesn't link directly to vendor libraries"},{"location":"introduction/aidl_and_binder/#hal-development-flow","title":"HAL Development Flow","text":"<ol> <li>Define an interface in <code>.aidl</code> (e.g. <code>IAudioSink.aidl</code>).</li> <li>Use the AIDL compiler to generate proxy/stub code.</li> <li>Implement the server-side service in the vendor HAL.</li> <li>Bind the service using a <code>ServiceManager</code>.</li> <li>Middleware connects via the AIDL proxy.</li> </ol>"},{"location":"introduction/aidl_and_binder/#example-audio-sink-aidl","title":"Example: Audio Sink AIDL","text":"<pre><code>interface IAudioSink {\n    void play();\n    void stop();\n    int getLatencyMs();\n}\n</code></pre> <p>Generates:</p> <ul> <li><code>BpAudioSink</code> (Proxy)</li> <li><code>BnAudioSink</code> (Stub)</li> <li><code>IAudioSink.h</code> (Interface definition)</li> </ul>"},{"location":"introduction/aidl_and_binder/#component-directory-structure-and-interface-versioning","title":"Component Directory Structure and Interface Versioning","text":"<p>Each RDK HAL component is maintained as a self-contained module. The working version of each component lives under a <code>current/</code> subdirectory, which includes AIDL interfaces, build configuration, and metadata. Interface versioning is not embedded in the directory structure during development; instead, it is applied during the release process.</p>"},{"location":"introduction/aidl_and_binder/#example-audiosink-component-layout","title":"Example: <code>audiosink</code> Component Layout","text":"<pre><code>audiosink/\n\u2514\u2500\u2500 current/\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 com/\n    \u2502   \u2514\u2500\u2500 rdk/\n    \u2502       \u2514\u2500\u2500 hal/\n    \u2502           \u2514\u2500\u2500 audiosink/\n    \u2502               \u251c\u2500\u2500 Capabilities.aidl\n    \u2502               \u251c\u2500\u2500 ContentType.aidl\n    \u2502               \u251c\u2500\u2500 ErrorCode.aidl\n    \u2502               \u251c\u2500\u2500 IAudioSink.aidl\n    \u2502               \u251c\u2500\u2500 IAudioSinkController.aidl\n    \u2502               \u251c\u2500\u2500 IAudioSinkControllerListener.aidl\n    \u2502               \u251c\u2500\u2500 IAudioSinkEventListener.aidl\n    \u2502               \u251c\u2500\u2500 IAudioSinkManager.aidl\n    \u2502               \u251c\u2500\u2500 PlatformCapabilities.aidl\n    \u2502               \u251c\u2500\u2500 Property.aidl\n    \u2502               \u251c\u2500\u2500 Volume.aidl\n    \u2502               \u2514\u2500\u2500 VolumeRamp.aidl\n    \u2514\u2500\u2500 hfp-audiosink.yaml\n</code></pre>"},{"location":"introduction/aidl_and_binder/#breakdown-of-key-elements","title":"Breakdown of Key Elements","text":"<ul> <li> <p><code>current/</code>:   The active development version of the component. This is the authoritative source for both the AIDL definitions and the associated HAL feature metadata.</p> </li> <li> <p><code>com/rdk/hal/audiosink/*.aidl</code>:   The AIDL files define the complete Binder IPC interface set for the <code>audiosink</code> HAL. Each file represents a distinct part of the interface, such as data types, error codes, control interfaces, and listener callbacks.</p> </li> <li> <p><code>CMakeLists.txt</code>:   Defines how to build the AIDL-generated C++ sources and any associated HAL service or unit test binaries.</p> </li> <li> <p><code>hfp-audiosink.yaml</code>:   The HAL Feature Pack (HFP) descriptor. This file maps interface implementations to service names, identifies required capabilities, and may include metadata for integration and deployment.</p> </li> </ul>"},{"location":"introduction/aidl_and_binder/#interface-versioning-via-release-process","title":"Interface Versioning via Release Process","text":"<ul> <li>The <code>current/</code> directory is unversioned during development.</li> <li>During the formal release process, the <code>current/</code> tree is:<ul> <li>Validated for stability using AIDL tooling.</li> <li>Snapshotted or copied to a versioned directory (e.g., <code>1/</code>, <code>2/</code>)</li> <li>Used to generate bindings against specific interface versions.</li> </ul> </li> </ul> <p>This approach allows:</p> <ul> <li>Concurrent development of future features in <code>current/</code> without affecting released versions.</li> <li>Stable integration points for validation systems.</li> <li>Backwards compatibility enforcement through version-aware AIDL and runtime checks.</li> </ul> <p>Stable AIDL requires a <code>version</code> declaration and enforces compatibility rules during build and test, ensuring that client/server pairs remain interoperable across versions.</p>"},{"location":"introduction/aidl_and_binder/#resources","title":"Resources","text":""},{"location":"introduction/aidl_and_binder/#rdk-hal-aidl","title":"RDK HAL &amp; AIDL","text":"<ul> <li>RDK HAL AIDL Repository</li> </ul>"},{"location":"introduction/aidl_and_binder/#android-aidl-documentation","title":"Android AIDL Documentation","text":"<ul> <li>AIDL Overview</li> <li>AIDL Language Reference</li> <li>Stable AIDL</li> </ul>"},{"location":"introduction/aidl_and_binder/#binder-internals","title":"Binder Internals","text":"<ul> <li>Binder Kernel Driver (v5.15)</li> <li>Binder Tracing Tools</li> <li>Binder Explorer</li> </ul>"},{"location":"introduction/build_binder_tools/","title":"Building and Using Binder Tools","text":""},{"location":"introduction/build_binder_tools/#overview","title":"Overview","text":"<p>This document provides step-by-step instructions on how to clone, build, and use the Binder tools from the Android source repository.</p>"},{"location":"introduction/build_binder_tools/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure that you have the following dependencies installed on your Linux system:</p> <pre><code>sudo apt update &amp;&amp; sudo apt install -y git build-essential clang cmake\n</code></pre>"},{"location":"introduction/build_binder_tools/#cloning-the-repository","title":"Cloning the Repository","text":"<p>To get the source code for the Binder tools, use the following command:</p> <pre><code>git clone https://android.googlesource.com/platform/prebuilts/build-tools\ncd build-tools\n</code></pre>"},{"location":"introduction/build_binder_tools/#using-prebuilt-binder-tools","title":"Using Prebuilt Binder Tools","text":"<p>If you prefer to use the prebuilt Binder tools instead of building them from source, follow these steps:</p> <ol> <li>Ensure you have the necessary permissions to execute the prebuilt binaries.</li> <li>Navigate to the directory containing the prebuilt tools:</li> </ol> <pre><code>cd build-tools/prebuilt/linux-x86_64/bin\n</code></pre> <ol> <li>Add the directory to your system <code>PATH</code> to use the tools globally:</li> </ol> <pre><code>export PATH=$(pwd):$PATH\n</code></pre> <ol> <li>Verify the installation by checking the available commands:</li> </ol> <pre><code>binder --help\n</code></pre>"},{"location":"introduction/build_binder_tools/#building-the-binder-tools","title":"Building the Binder Tools","text":"<ol> <li>Navigate to the <code>build-tools</code> directory:</li> </ol> <pre><code>cd build-tools\n</code></pre> <ol> <li>If the repository includes a <code>CMakeLists.txt</code> file, use CMake to build:</li> </ol> <pre><code>mkdir -p build &amp;&amp; cd build\ncmake ..\nmake -j$(nproc)\n</code></pre> <ol> <li>Alternatively, if a standard <code>Makefile</code> is present, simply run:</li> </ol> <pre><code>make -j$(nproc)\n</code></pre>"},{"location":"introduction/build_binder_tools/#installing-the-built-tools","title":"Installing the Built Tools","text":"<p>Once the build is complete, install the tools system-wide (if required):</p> <pre><code>sudo make install\n</code></pre>"},{"location":"introduction/build_binder_tools/#using-binder-tools","title":"Using Binder Tools","text":"<p>After installation, you can use the tools directly. Some commonly used commands include:</p> <pre><code>binder --help   # Display help menu\nbinder &lt;options&gt;  # Run the tool with required options\n</code></pre> <p>If the tool is not found in the system path, you can run it from the build directory:</p> <pre><code>./binder &lt;options&gt;\n</code></pre>"},{"location":"introduction/build_binder_tools/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the build fails due to missing dependencies, install them using:</li> </ul> <pre><code>sudo apt install -y additional-dependency\n</code></pre> <ul> <li>If the command is not found, ensure the binary is in your <code>PATH</code>:</li> </ul> <pre><code>export PATH=$(pwd)/build:$PATH\n</code></pre> <p>For more details, refer to the official Android source documentation.</p>"},{"location":"introduction/documentation_getting_started/","title":"Documentation - Getting Started","text":"<p>This guide outlines the process for contributing to and maintaining the documentation. All documentation resides within the <code>docs</code> directory of the GitHub repository. We leverage ReadTheDocs (https://readthedocs.org/) for documentation generation and the Material for MkDocs theme (https://squidfunk.github.io/mkdocs-material/) for a polished and consistent user experience.</p>"},{"location":"introduction/documentation_getting_started/#setting-up-your-local-environment","title":"Setting Up Your Local Environment","text":"<p>To work on the documentation locally:</p>"},{"location":"introduction/documentation_getting_started/#install-python","title":"Install Python","text":"<p>Ensure Python 3 is installed and accessible on your system. Verify by running:</p> <pre><code>python3 --version\n</code></pre>"},{"location":"introduction/documentation_getting_started/#building-and-serving-documentation","title":"Building and Serving Documentation","text":"<p>To simplify working with documentation, the <code>docs/build_docs.sh</code> script provides several subcommands:</p> <ul> <li>serve: builds the documentation and starts a local server  </li> <li>build (default if no subcommand is given): builds the documentation without serving  </li> <li>deploy: builds the documentation and deploys it to GitHub Pages  </li> <li>help: displays usage information</li> </ul> <p>This follows the documentation in git approach See :- documentation in git</p>"},{"location":"introduction/documentation_getting_started/#serve-the-documentation-locally","title":"Serve the Documentation Locally","text":"<p>To generate and serve the documentation on <code>localhost:8000</code>, run:</p> <pre><code>./build_docs.sh serve\n</code></pre> <p>Once the server is running, you can view the docs at:</p> <p>http://localhost:8000/rdkcentral/rdk-halif-aidl/</p> <p>Any changes to the Markdown files in the <code>docs</code> directory will automatically reload in the browser.</p>"},{"location":"introduction/documentation_getting_started/#building-without-serving","title":"Building Without Serving","text":"<p>If you just want to build the static files (without starting a local server), run:</p> <pre><code>./build_docs.sh build\n</code></pre> <p>This generates the site into the <code>site</code> directory.</p>"},{"location":"introduction/documentation_getting_started/#structuring-the-documentation","title":"Structuring the Documentation","text":"<p>The file <code>mkdocs.yml</code>, located at the root of the repository, defines how your documentation is structured and navigated. Any additions, removals, or reorganizations of documentation pages require corresponding updates to <code>mkdocs.yml</code> to keep the site navigation current.</p> <p>For more information on naming conventions used, see Key Concepts and Naming Conventions.</p>"},{"location":"introduction/documentation_getting_started/#deploying-documentation","title":"Deploying Documentation","text":"<p>If you have the necessary permissions to deploy, follow these steps:</p> <p>Build the documentation and deploy to the <code>gh-pages</code> branch:</p> <pre><code>./build_docs.sh build\n./build_docs.sh deploy\n</code></pre> <p>The site will be published at: https://rdkcentral.github.io/rdk-halif-aidl/ </p> <p>Note: The published site\u2019s resides in the <code>gh-pages</code> branch of this repository.</p>"},{"location":"introduction/documentation_getting_started/#getting-help","title":"Getting Help","text":"<p>At any time, you can see a list of available subcommands and usage information by running:</p> <pre><code>./build_docs.sh\n</code></pre> <p>or</p> <pre><code>./build_docs.sh help\n</code></pre>"},{"location":"introduction/documentation_getting_started/#writing-style-and-guidelines","title":"Writing Style and Guidelines","text":"<p>When contributing to the documentation, please adhere to the following guidelines:</p> <ul> <li>Accuracy and Clarity: Ensure all information is accurate, up-to-date, and easy to understand. Use clear and concise language.</li> <li>Proofreading: Thoroughly proofread all content for spelling, grammar, and punctuation errors before submitting changes.</li> <li>Admonitions for Emphasis: Use admonitions to highlight key information, warnings, notes, or tips. Material for MkDocs provides various admonition styles: https://squidfunk.github.io/mkdocs-material/reference/admonitions/</li> </ul> <p>Note</p> <p>This is an example of a note admonition.</p> <p>Info</p> <p>This is an example of a info admonition.</p> <p>Tip</p> <p>This is an example of a tip admonition.</p> <p>Example</p> <p>This is an example</p> <p>Warning</p> <p>This is a warning!</p> <ul> <li>Code Blocks with Syntax Highlighting: Always use code blocks for code examples and specify the language for syntax highlighting:</li> </ul> <pre><code>def example_function():\n    print(\"Hello, world!\")\n</code></pre> <pre><code>function exampleFunction() \n{\n    console.log(\"Hello, world!\");\n}\n</code></pre> <ul> <li> <p>MkDocs-Material Reference: Refer to the official Material for MkDocs documentation for advanced features and customization options: https://squidfunk.github.io/mkdocs-material/reference/</p> </li> <li> <p>Mermaid Diagrams (Preferred): Use Mermaid (https://mermaid.js.org/) for creating diagrams whenever possible. Mermaid diagrams offer better accessibility, performance, and scalability compared to embedded images.</p> </li> </ul> <pre><code>graph LR\n    A[Start] --&gt; B{Is there an Error?};\n    B -- Yes --&gt; C[Debug];\n    C --&gt; D[Test];\n    D --&gt; B;\n    B -- No --&gt; E[Success!];</code></pre> <p>This guide ensures consistency, accuracy, and usability across all documentation contributions.</p>"},{"location":"introduction/interface_generation/","title":"HAL Interface Generation","text":"<p>This document describes how to generate Hardware Abstraction Layer (HAL) interface definitions using the Android Interface Definition Language (AIDL).</p>"},{"location":"introduction/interface_generation/#prerequisites","title":"Prerequisites","text":"<p>Building this repository requires the AIDL compiler (<code>aidl</code>).  This can be obtained by building the <code>linux_binder_idl</code> project, available on GitHub: github.com/rdkcentral/linux_binder_idl.git. Alternatively, you can use a Docker image that includes <code>aidl</code>, such as <code>rdk-dunfell</code> or the recommended <code>rdk-kirkstone</code>.</p>"},{"location":"introduction/interface_generation/#building-aidl-from-linux_binder_idl","title":"Building <code>aidl</code> from <code>linux_binder_idl</code>","text":"<p>Minimum Required GCC Version: 9.4.0</p> <p>Using the <code>rdk-kirkstone</code> Docker image is highly recommended.</p> <p>Clone the <code>linux_binder_idl</code> repository:</p> <pre><code>git clone git@github.com:rdkcentral/linux_binder_idl.git\ncd linux_binder_idl\n</code></pre> <p>Build <code>aidl</code>:</p> <pre><code># Optional: Run inside the Docker container\nsc docker run rdk-kirkstone /bin/bash\n</code></pre> <p>Then build the aidl tool.</p> <pre><code>./build-aidl-generator-tool.sh\n</code></pre> <p>Locate the <code>aidl</code> binary:</p> <p>The compiled <code>aidl</code> binary will be located in the <code>local/bin</code> directory within the <code>linux_binder_idl</code> project.  The full path might resemble:</p> <pre><code>linux_binder_idl/local/bin/aidl\n</code></pre> <p>For more detailed information, refer to the github.com/rdkcentral/linux_binder_idl.git repository.</p>"},{"location":"introduction/interface_generation/#generating-aidl-proxy-and-native-interfaces","title":"Generating AIDL Proxy and Native Interfaces","text":"<p>Clone the <code>hal</code> repository:</p> <pre><code>git clone git@github.com:rdkcentral/rdk-halif-aidl.git\n</code></pre> <p>Generate the AIDL proxy and native interfaces:</p> <p>The following example demonstrates generating interfaces for the <code>audiodecoder</code> module. Adapt the <code>AIDL_TARGET</code> CMake variable for other modules.</p> <pre><code>cd hal\n\n# Optional: Run inside the Docker container\nsc docker run rdk-kirkstone /bin/bash\n\n# Optional: Set AIDL binary path if not in system PATH.  Replace with the actual path from the previous step.\nexport PATH=$PATH:/path/to/linux_binder_idl/local/bin\n\ncmake -DAIDL_TARGET=audiodecoder .\n</code></pre> <p>Warning</p> <p>CMake must be run from the root directory of the <code>hal</code> repository, not within a specific module directory.</p> <p>Locate the generated files:</p> <p>The generated proxy and interface files will be placed under <code>audiodecoder/gen/&lt;version&gt;</code>.  For example:</p> <pre><code>hal/audiodecoder/gen/current/cpp/com/rdk/hal/audiodecoder/...  (C++ files)\nhal/audiodecoder/gen/current/h/com/rdk/hal/audiodecoder/...   (Header files)\nhal/audiodecoder/current/com/rdk/hal/audiodecoder/...        (AIDL files)\n</code></pre>"},{"location":"introduction/interface_generation/#example-cmake-commands","title":"Example CMake Commands","text":"<pre><code># Use a custom path to the `aidl` binary\ncmake -DAIDL_TARGET=audiodecoder -DAIDL_BIN=/home/example/bin/aidl .\n\n# Specify a specific AIDL interface version (e.g., version 2)\ncmake -DAIDL_TARGET=audiodecoder -DAIDL_SRC_VERSION=2 .\n\n# Specify a custom output directory for generated files\ncmake -DAIDL_TARGET=audiodecoder -DAIDL_GEN_DIR=/home/example/example_out .\n</code></pre>"},{"location":"introduction/interface_generation/#cmake-variables","title":"CMake Variables","text":"Variable Description <code>AIDL_BIN</code> Optional. Path to the <code>aidl</code> executable. If not set, CMake will attempt to locate it. <code>AIDL_GEN_DIR</code> Optional. Output directory for generated files. Default: <code>&lt;module&gt;/gen/&lt;version&gt;</code>. <code>AIDL_SRC_VERSION</code> Optional. Version of the AIDL interface to generate. Default: <code>current</code>. <code>AIDL_TARGET</code> Mandatory. Name of the module for which to generate interfaces."},{"location":"introduction/interface_generation/#notes","title":"Notes","text":"<p>The <code>Broadcast</code> module is currently disabled because its <code>demux</code> submodule depends on the Android framework.</p>"},{"location":"introduction/the_software_stack/","title":"The Software Stack","text":"<p>It is important to distinguish the different layers within the software stack:</p> <ul> <li>Application Layer: The software that directly interacts with end users (for example, an Electronic Programme Guide or streaming applications).</li> <li>Middleware Layer: Provides core services and functionality to the Application Layer\u2014such as multimedia frameworks, network communication, and security.</li> <li>Vendor Layer: Interacts directly with the hardware. It includes drivers and other components that translate hardware-specific requirements into a format consumable by the Middleware and Application layers.</li> </ul> <pre><code>block-beta\n    block: modules\n        columns 2\n        appl(\"Application Layer\"):2\n        mwl(\"Middleware Layer\"):2\n        vendor(\"Hardware Porting Kit (HPK)\"):2\n        vhal(\"Vendor Hal Interface(API)\")\n        vsi(\"Vendor System Interface - (VSI)\")\n        vc(\"Vendor Drivers\")\n        sl(\"Vendor System Libraries\")\n        osl(\"Vendor Open Source Libraries (VOSS)\"):2\n        ub(\"Kernel\"):2\n        hw(\"Hardware\"):2\n    end\n\n    %% Set background to white for better contrast\n    style modules fill:#FFFFFF,stroke:#424242,stroke-width:2px;\n\n    %% Fix Contrast - Application &amp; Middleware Layers\n    style appl fill:#E3F2FD,stroke:#1E88E5,color:#0D47A1,font-weight:bold;\n    style mwl fill:#E3F2FD,stroke:#1E88E5,color:#0D47A1,font-weight:bold;\n\n    %% Better Blue Contrast for Vendor Components\n    style vendor fill:#2196F3,stroke:#0D47A1,color:#FFFFFF,font-weight:bold;\n    style vhal fill:#2196F3,stroke:#0D47A1,color:#FFFFFF,font-weight:bold;\n    style vsi fill:#2196F3,stroke:#0D47A1,color:#FFFFFF,font-weight:bold;\n\n    %% Better Orange Contrast for System Components\n    style vc fill:#FF7043,stroke:#BF360C,color:#FFFFFF,font-weight:bold;\n    style sl fill:#FF7043,stroke:#BF360C,color:#FFFFFF,font-weight:bold;\n    style osl fill:#FF5722,stroke:#D84315,color:#FFFFFF,font-weight:bold;\n    style ub fill:#E64A19,stroke:#BF360C,color:#FFFFFF,font-weight:bold;\n    style hw fill:#D84315,stroke:#A62808,color:#FFFFFF,font-weight:bold;</code></pre>"},{"location":"introduction/the_software_stack/#platform-independence","title":"Platform Independence","text":"<p>A key principle is platform independence. The Application and Middleware layers are designed to run on any platform without modification, relying on a discovery interface to identify hardware capabilities at runtime. All platform-specific details are handled by the Vendor Layer, ensuring the Application and Middleware remain portable. Each layer can also be released or updated at its own cadence, thanks to process separation\u2014meaning updates to the Vendor Layer do not impact the stability of the upper layers.</p> <p>Additionally, each interface introduces a dedicated <code>capabilities</code> mechanism, allowing the system to identify both the hardware\u2019s capabilities and any associated constraints. Through these interface and the service manager it's possible to determine whether major features are supported on a given platform, further preserving the flexibility of the Application and Middleware layers.</p>"},{"location":"introduction/the_software_stack/#component-stability-and-versioning","title":"Component Stability and Versioning","text":"<p>Every component within the stack moves to a fixed version consumption model, where both interfaces and implementations follow a strict versioning scheme defining the contracts between components.</p> <p>All non-HAL components within the stack follows the Semantic Versioning (SemVer) with a <code>major.minor.bugfix/doc</code> format:</p> <ul> <li>Major \u2013 Incremented for incompatible API changes.  </li> <li>Minor \u2013 Incremented when adding functionality in a backwards-compatible manner.  </li> <li>Bugfix/Doc \u2013 Incremented for backwards-compatible bug fixes or documentation updates (treating documentation as part of the semantic contract).</li> </ul> <p>For more information, see SemVer.</p>"},{"location":"introduction/the_software_stack/#hal-service-interfaces-architecture","title":"HAL Service Interfaces Architecture","text":"<p>Most of the HAL interfaces are implemented as services in a client\u2013server architecture. These services maintain process separation and are backward compatible with older API versions. Interface definitions in AIDL files produce C++ code for both client and server, with HAL calls transmitted via Binder IPC.</p> <p>These interfaces use a stable interface paradigm with incremental versioning to guarantee full ABI backwards compatibility:</p> <ul> <li>Binary Compatibility: Newly introduced features do not break or alter existing interfaces, so older clients do not need recompilation.  </li> <li>Compatibility-Breaking Changes: If a change cannot maintain backward compatibility, then a brand-new component (rather than altering an existing one) will be created. And the previous component will become obsolete and be deprecated over time.</li> <li>Validation &amp; Compliance: Hash checks and validation scripts ensure that all interface updates remain backward compatible, enforcing the stable interface requirement.  </li> <li>Opt-In for New Features: Existing clients can continue using older interfaces seamlessly, unless they choose to adopt the new features (in which case rebuilding against the updated AIDL definitions is required).</li> </ul>"},{"location":"introduction/the_software_stack/#vendor-system-interfaces-in-process-hals","title":"Vendor System Interfaces (In-Process HALs)","text":"<p>A smaller subset of HALs function as in-process libraries, collectively referred to as the Vendor System Interface (VSI). They are dynamically linked to the RDK Middleware, commonly used for:</p> <ul> <li>Graphics \u2013 EGL, OpenGL ES, Vulkan</li> <li>Wi-Fi \u2013 wpa_supplicant</li> <li>Bluetooth \u2013 BlueZ</li> </ul> <p>Because these libraries run in the same process, introducing a new VSI version typically requires a rebuild of the upper layers. Consequently, VSI changes are expected to occur infrequently\u2014only when there is a substantial need\u2014so that their release cadence remains low.</p>"},{"location":"python_venv/lib/python3.12/site-packages/Markdown-3.7.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib/python3.12/site-packages/idna-3.10.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib/python3.12/site-packages/mkdocs_get_deps-0.2.0.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2023 Oleh Prypin oleh@pryp.in</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.12/site-packages/mkdocs_material_extensions-1.3.1.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2021 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/","title":"License","text":""},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#pymdown-extensions","title":"PyMdown Extensions","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2014 - 2024 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#superfences","title":"SuperFences","text":"<p><code>superfences.py</code> is derived from Python Markdown's fenced_code extension.</p> <pre><code>Fenced Code Extension for Python Markdown\n =========================================\nThis extension adds Fenced Code Blocks to Python-Markdown.\nSee &lt;https://python-markdown.github.io/extensions/fenced_code_blocks/&gt;\nfor documentation.\nOriginal code Copyright 2007-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#highlight","title":"Highlight","text":"<p><code>highlight.py</code> is derived from Python Markdown's CodeHilite extension.</p> <pre><code>CodeHilite Extension for Python-Markdown\n ========================================\nAdds code/syntax highlighting to standard Python-Markdown code blocks.\nSee &lt;https://python-markdown.github.io/extensions/code_hilite/&gt;\nfor documentation.\nOriginal code Copyright 2006-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#fancylists","title":"FancyLists","text":"<p><code>fancylists.py</code> is derived from Python Markdown's list handler.</p> <pre><code>Started by Manfred Stienstra (http://www.dwerg.net/).\nMaintained for a few years by Yuri Takhteyev (http://www.freewisdom.org).\nCurrently maintained by Waylan Limberg (https://github.com/waylan),\nDmitry Shachnev (https://github.com/mitya57) and Isaac Muse (https://github.com/facelessuser).\n\nCopyright 2007-2023 The Python Markdown Project (v. 1.7 and later)\nCopyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b)\nCopyright 2004 Manfred Stienstra (the original version)\n\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#gemoji-index","title":"Gemoji Index","text":"<p><code>gemoji_db.py</code> is generated from Gemoji's source code: @github/gemoji.</p> <pre><code>Copyright (c) 2013 GitHub, Inc.\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"python_venv/lib/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#emojione-index","title":"EmojiOne Index","text":"<p><code>emoji1_db.py</code> is generated from EmojiOne's source code: @Ranks/emojione</p> <pre><code>EmojiOne Non-Artwork\n\nApplies to the JavaScript, JSON, PHP, CSS, HTML files, and everything else not covered under the artwork license above.\nLicense: MIT\nComplete Legal Terms: http://opensource.org/licenses/MIT\n</code></pre>"},{"location":"python_venv/lib64/python3.12/site-packages/Markdown-3.7.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib64/python3.12/site-packages/idna-3.10.dist-info/LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"python_venv/lib64/python3.12/site-packages/mkdocs_get_deps-0.2.0.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2023 Oleh Prypin oleh@pryp.in</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.12/site-packages/mkdocs_material_extensions-1.3.1.dist-info/licenses/LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2021 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/","title":"License","text":""},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#pymdown-extensions","title":"PyMdown Extensions","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2014 - 2024 Isaac Muse</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#superfences","title":"SuperFences","text":"<p><code>superfences.py</code> is derived from Python Markdown's fenced_code extension.</p> <pre><code>Fenced Code Extension for Python Markdown\n =========================================\nThis extension adds Fenced Code Blocks to Python-Markdown.\nSee &lt;https://python-markdown.github.io/extensions/fenced_code_blocks/&gt;\nfor documentation.\nOriginal code Copyright 2007-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#highlight","title":"Highlight","text":"<p><code>highlight.py</code> is derived from Python Markdown's CodeHilite extension.</p> <pre><code>CodeHilite Extension for Python-Markdown\n ========================================\nAdds code/syntax highlighting to standard Python-Markdown code blocks.\nSee &lt;https://python-markdown.github.io/extensions/code_hilite/&gt;\nfor documentation.\nOriginal code Copyright 2006-2008 [Waylan Limberg](http://achinghead.com/).\nAll changes Copyright 2008-2014 The Python Markdown Project\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#fancylists","title":"FancyLists","text":"<p><code>fancylists.py</code> is derived from Python Markdown's list handler.</p> <pre><code>Started by Manfred Stienstra (http://www.dwerg.net/).\nMaintained for a few years by Yuri Takhteyev (http://www.freewisdom.org).\nCurrently maintained by Waylan Limberg (https://github.com/waylan),\nDmitry Shachnev (https://github.com/mitya57) and Isaac Muse (https://github.com/facelessuser).\n\nCopyright 2007-2023 The Python Markdown Project (v. 1.7 and later)\nCopyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b)\nCopyright 2004 Manfred Stienstra (the original version)\n\nLicense: [BSD](http://www.opensource.org/licenses/bsd-license.php)\n</code></pre>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#gemoji-index","title":"Gemoji Index","text":"<p><code>gemoji_db.py</code> is generated from Gemoji's source code: @github/gemoji.</p> <pre><code>Copyright (c) 2013 GitHub, Inc.\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"python_venv/lib64/python3.12/site-packages/pymdown_extensions-10.14.3.dist-info/licenses/LICENSE/#emojione-index","title":"EmojiOne Index","text":"<p><code>emoji1_db.py</code> is generated from EmojiOne's source code: @Ranks/emojione</p> <pre><code>EmojiOne Non-Artwork\n\nApplies to the JavaScript, JSON, PHP, CSS, HTML files, and everything else not covered under the artwork license above.\nLicense: MIT\nComplete Legal Terms: http://opensource.org/licenses/MIT\n</code></pre>"},{"location":"references/references/","title":"References","text":""},{"location":"references/references/#unit-testing-core-framework","title":"Unit Testing Core Framework","text":"<ul> <li>Repository: ut-core </li> <li>Description: A core framework for unit testing, providing essential tools and utilities to streamline test development and execution.</li> </ul>"},{"location":"references/references/#uinit-testing-control","title":"Uinit Testing Control","text":"<ul> <li>Repository: ut-control</li> <li>Description: Modules that support functionality for message handling, key-value pair (KVP) data parsing, and logging. Used for testing and also vDevice.</li> </ul>"},{"location":"references/references/#python-raft","title":"Python Raft","text":"<ul> <li>Repository: python-raft </li> <li>Description: Python-based engineering testing framework for validating embedded device.</li> </ul>"},{"location":"references/references/#unit-testing-raft","title":"Unit Testing RAFT","text":"<ul> <li>Repository: ut-raft</li> <li>Description: The ut-raft repository is part of the RAFT (Rapid Application For Test Framework) and profiles classes to support L3-L4 testing.</li> </ul>"},{"location":"src_link/CHANGELOG/","title":"ChangeLog","text":""},{"location":"src_link/CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file. Dates are displayed in UTC.</p> <p>Generated by <code>auto-changelog</code>.</p>"},{"location":"src_link/CHANGELOG/#0100","title":"0.10.0","text":"<ul> <li>PR: 73 bug av clock interface description is unclear <code>#74</code></li> <li>Feature/133 task add documentation version support <code>#134</code></li> <li>updated #106 - Template for documentation - baselined <code>#107</code></li> <li>Updated #35 Current Status <code>d5e84bd</code></li> <li>removed current #35 - added all subpages <code>600c90d</code></li> <li>updated #88 directory &amp; requirements <code>6cb49ae</code></li> </ul>"},{"location":"src_link/CHANGELOG/#081","title":"0.8.1","text":"<p>15 May 2025</p> <ul> <li>Updated #76 blackduck updated base on feedback <code>#77</code></li> <li>fixed #76 blackduck review <code>#76</code></li> <li>Updated #76 updated base on feedback <code>cae2728</code></li> <li>added #76 - RDK (c) messages <code>2afef74</code></li> <li>bumped changelog <code>37ca52f</code></li> </ul>"},{"location":"src_link/CHANGELOG/#080","title":"0.8.0","text":"<p>14 April 2025</p> <ul> <li>PR: Feature/gh43 hdmi input output definitions <code>#44</code></li> <li>gh #50 CSDVideoFormat.aidl: Fix syntax error <code>#51</code></li> <li>gh#45 Move source code generating logic into CMake module <code>#40</code></li> <li>HDMIInput, HDMIOutput <code>ebc7bea</code></li> <li>Several coding fixes and updated comments. <code>2a583a2</code></li> <li>added rdk copyright messages #35 <code>f21d7e4</code></li> </ul>"},{"location":"src_link/CHANGELOG/#072","title":"0.7.2","text":"<p>12 June 2025</p> <ul> <li>updated #95 pure virtual helper <code>281a85a</code></li> </ul>"},{"location":"src_link/CHANGELOG/#071","title":"0.7.1","text":"<p>29 April 2025</p> <ul> <li>Compiling issue with the 0.7.0 release <code>#79</code></li> <li>bumped changelog <code>18c7757</code></li> <li>Fix incorrect function prototype parseCodecSpecificData during file cleanup <code>2bdaebc</code></li> <li>gh#50 CSDVideoFormat.aidl: Fix syntax error <code>9efb721</code></li> </ul>"},{"location":"src_link/CHANGELOG/#070","title":"0.7.0","text":"<p>26 February 2025</p> <ul> <li>Feature/19 task migrate current documentation to markdown <code>#41</code></li> <li>gh#12 Fix compilation error in videodecoder due to missing com/rdk/hal/State.h <code>#13</code></li> <li>Merge gh7 DeviceInfo from main to develop <code>#11</code></li> <li>Feature/gh7 add deviceinfo interface <code>#8</code></li> <li>Initial commit of Flash HAL and new boot ResetType enums. <code>#6</code></li> <li>Feature/gh3 Add HFP YAML files <code>#4</code></li> <li>feature #3: added PQ parameter capabilities <code>fd1c5a1</code></li> <li>updated #19 audio, video, service manager, av, clock <code>d4014e7</code></li> <li>Upgrade 19 to support baseline checking docs <code>29c7cfc</code></li> </ul>"},{"location":"src_link/CHANGELOG/#v06","title":"v0.6","text":"<p>24 September 2024</p> <ul> <li>Initial HAL files commit. <code>7894d6f</code></li> <li>Initial commit <code>6ed4d8d</code></li> </ul>"},{"location":"src_link/cdm/readme/","title":"Content Decryption Module Support","text":""},{"location":"standards/direct_branching/","title":"Core Development Guide: Branching for Direct Contributions","text":""},{"location":"standards/direct_branching/#overview-of-contributions","title":"Overview of Contributions","text":"<p>We welcome contributions from all community members, including both Core Development Teams (direct access) and Fork-Based Contribution Teams (forked workflow). Your participation is vital to the project's success. Here's how you can get involved:</p> <ul> <li>Code Contributions: Whether you're proposing new features or fixing bugs, please follow the detailed steps below to ensure your contributions align with our standards.</li> <li>Issue Reporting: If you discover bugs or have suggestions for improvement, open a GitHub issue. These reports drive continuous enhancement.</li> <li>Discussions and Ideas: We encourage open discussions on technical ideas, design proposals, and development challenges. Your insights shape the evolution of the platform.</li> </ul>"},{"location":"standards/direct_branching/#access-levels-and-workflows","title":"Access Levels and Workflows","text":"<ul> <li> <p>Core Development Teams (Direct Access):   These contributors have write access to the main repository. They follow a structured Git Flow branching model and are responsible for maintaining shared platform components. See the Core Development Team Registration Process</p> </li> <li> <p>Fork-Based Contribution Teams (External Workflow):   These contributors do not have direct access. They develop via forks of the repository and submit their work through pull requests. This model supports deployment-specific customization and community-driven innovation. See the Fork-Based Contribution Guide for detailed instructions</p> </li> </ul>"},{"location":"standards/direct_branching/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Before any code can be merged, you must sign the RDK Contributor License Agreement (CLA). This ensures legal clarity and freedom for the community to use your contributions. First-time contributors must complete this step before any merges can occur.</p>"},{"location":"standards/direct_branching/#getting-started-with-git-collaboration","title":"Getting Started with Git Collaboration","text":""},{"location":"standards/direct_branching/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/rdkcentral/ut-core.git\n</code></pre>"},{"location":"standards/direct_branching/#2-set-up-git-flow","title":"2. Set Up Git Flow","text":"<p>We use Git Flow to structure development:</p> <pre><code>git flow init -d\n</code></pre>"},{"location":"standards/direct_branching/#3-create-a-feature-branch","title":"3. Create a Feature Branch","text":"<p>Start from <code>develop</code> and name your branch as <code>feature/gh&lt;issue-number&gt;_&lt;description&gt;</code>:</p> <pre><code>git flow feature start 123_add-logging-enhancements\n</code></pre> <p>Compliance Notice: All branches must align with naming conventions and be traceable to a GitHub issue. Non-compliant branches are subject to removal if not corrected within 30 days.</p>"},{"location":"standards/direct_branching/#4-implement-changes","title":"4. Implement Changes","text":"<p>Follow coding standards and document your changes thoroughly.</p>"},{"location":"standards/direct_branching/#5-commit-your-changes","title":"5. Commit Your Changes","text":"<p>Use the 50/72 rule:</p> <pre><code>Fix #123: Update error handling in authentication module\n\nThis commit enhances error detection and adds comprehensive logging to address frequent issues reported by users.\n</code></pre>"},{"location":"standards/direct_branching/#6-push-changes","title":"6. Push Changes","text":"<pre><code>git push origin feature/gh123_add-logging-enhancements\n</code></pre>"},{"location":"standards/direct_branching/#7-open-a-pull-request","title":"7. Open a Pull Request","text":"<p>Create a PR to the <code>develop</code> branch. Review will be auto-assigned via <code>CODEOWNERS</code>.</p>"},{"location":"standards/direct_branching/#8-merge-the-pull-request","title":"8. Merge the Pull Request","text":"<p>After approval:</p> <pre><code>git flow feature finish gh123_add-logging-enhancements\n</code></pre>"},{"location":"standards/direct_branching/#9-code-ownership-and-releases","title":"9. Code Ownership and Releases","text":"<p><code>CODEOWNERS</code> ensure quality and manage release tagging:</p> <pre><code>*       @rdkcentral/ut-core_codeowner\n</code></pre>"},{"location":"standards/direct_branching/#requirements-for-contributions","title":"Requirements for Contributions","text":"<ul> <li>Use Git Flow correctly.</li> <li>Write clear commit messages.</li> <li>Undergo and complete peer reviews.</li> <li>Participate in open discussions.</li> </ul> <p>By following these practices, you contribute to a robust and transparent open-source platform. We appreciate your involvement in building a high-quality, maintainable codebase.</p>"},{"location":"standards/forked_based_branching/","title":"Fork-Based Contribution Guide: Forking for External Contributions","text":""},{"location":"standards/forked_based_branching/#introduction","title":"Introduction","text":"<p>Welcome to the Fork-Based Contribution Guide! This guide is designed for engineers, integrators, and third-party developers who contribute to the project without having direct write access to the main repository. Forking enables you to build, test, and propose enhancements in a safe and controlled manner, consistent with RDK Central\u2019s collaborative development model.</p>"},{"location":"standards/forked_based_branching/#what-is-forking","title":"What is Forking?","text":"<p>Forking creates a personal copy of the main repository under your GitHub account. This isolated copy allows you to make changes independently, experiment freely, and prepare contributions without affecting the core codebase.</p>"},{"location":"standards/forked_based_branching/#why-fork","title":"Why Fork?","text":"<ul> <li>Safe Experimentation: Work on new features or fixes without risk to the core repository.</li> <li>Clear Contribution Pathway: Submit your work through pull requests to be reviewed and potentially merged into the main project.</li> <li>Decentralized Collaboration: Forking supports scalable open-source workflows where multiple organizations contribute independently.</li> </ul>"},{"location":"standards/forked_based_branching/#step-by-step-forking-workflow","title":"Step-by-Step Forking Workflow","text":"<ol> <li>Find the Repository: Navigate to the official project repository on GitHub.</li> <li>Click \u201cFork\u201d: Located in the upper-right of the repository page.</li> <li>Choose Your Account: Select your GitHub account to host the fork.</li> <li>Clone Your Fork Locally:</li> </ol> <pre><code>git clone https://github.com/&lt;your-username&gt;/&lt;repository-name&gt;.git\n</code></pre> <ol> <li>Create a Branch: (Highly recommended) Create a topic branch for your changes:</li> </ol> <pre><code>git checkout -b feature/my-new-feature\n</code></pre> <ol> <li>Make Your Changes: Modify files to add features, fix bugs, or update documentation.</li> <li>Commit Your Changes: Write meaningful and descriptive commit messages:</li> </ol> <pre><code>git commit -m \"Add feature: &lt;short description&gt;\"\n</code></pre> <ol> <li>Push to Your Fork:</li> </ol> <pre><code>git push origin feature/my-new-feature\n</code></pre> <ol> <li>Open a Pull Request: Go to the original repository and submit a pull request from your fork. Include a clear explanation of your changes and their purpose.</li> <li>Review &amp; Feedback: Core Development Team members will review your pull request. Feedback may be provided to align your contribution with project standards before it is accepted.</li> </ol>"},{"location":"standards/forked_based_branching/#important-considerations","title":"Important Considerations","text":"<ul> <li>Stay Synced: Regularly update your fork from the upstream repository to avoid merge conflicts.</li> <li>Communicate Clearly: Explain the scope, motivation, and impact of your contribution in the pull request.</li> <li>Be Patient and Collaborative: Reviews take time. Be receptive to feedback and willing to revise.</li> <li>Follow Standards: Adhere to the project's coding, testing, and documentation practices.</li> </ul> <p>For more detailed information, refer to the RDK Central Contribution Guide</p>"},{"location":"standards/interface_template/","title":"HAL Interface Name","text":""},{"location":"standards/interface_template/#overview","title":"Overview","text":"<p>Describe the role of this HAL service. Outline its responsibilities, how it abstracts platform-specific functionality, and its interaction with higher-level RDK components. Mention any excluded modes or operations.</p>"},{"location":"standards/interface_template/#references","title":"References","text":"<p>Info</p> Interface Definition path-to-aidl-version API Documentation TBD HAL Interface Type AIDL and Binder Initialization Unit systemd service VTS Tests TBD Reference Implementation TBD"},{"location":"standards/interface_template/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>HAL Feature Profile</li> <li>HAL Interface Overview</li> <li>Other HALs or Framework Components</li> </ul>"},{"location":"standards/interface_template/#functional-overview","title":"Functional Overview","text":"<p>Explain the main responsibilities of this interface, such as managing resources, processing buffers, handling events, or controlling hardware. Clarify its positioning in the system architecture.</p>"},{"location":"standards/interface_template/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL..1 The service shall... Notes or rationale"},{"location":"standards/interface_template/#interface-definitions","title":"Interface Definitions","text":"AIDL File Description I.aidl Main resource control interface IManager.aidl Interface for service discovery and resource enumeration Capabilities.aidl Parcelable describing feature set ErrorCode.aidl Enum of failure conditions"},{"location":"standards/interface_template/#initialization","title":"Initialization","text":"<p>Describe startup behaviour, service registration, dependencies, and order of operation (e.g., Service Manager registration).</p>"},{"location":"standards/interface_template/#product-customization","title":"Product Customization","text":"<p>Explain:</p> <ul> <li>How resources are uniquely identified and enumerated</li> <li>What <code>Capabilities</code> or properties clients can query</li> <li>If the platform can offer multiple simultaneous instances</li> </ul>"},{"location":"standards/interface_template/#system-context","title":"System Context","text":"<p>Include a Mermaid flowchart or textual description showing:</p> <ul> <li>Client-side interface use</li> <li>Resource control paths</li> <li>Event listener connections</li> <li>Any shared data buffer interaction</li> </ul>"},{"location":"standards/interface_template/#resource-management","title":"Resource Management","text":"<p>Detail the lifecycle:</p> <ul> <li>How clients <code>open()</code> or <code>acquire()</code> resource handles</li> <li>Restrictions (e.g., single controller vs. multiple listeners)</li> <li>Cleanup behavior when a client exits</li> </ul>"},{"location":"standards/interface_template/#operation-and-data-flow","title":"Operation and Data Flow","text":"<p>General description of:</p> <ul> <li>How input/output flows through the HAL</li> <li>Handling of any buffer queues, frame handles, or metadata</li> <li>Conditions for back pressure or resource stalls</li> </ul>"},{"location":"standards/interface_template/#modes-of-operation","title":"Modes of Operation","text":"<p>Describe configurable or runtime modes and how they affect client interaction or output.</p>"},{"location":"standards/interface_template/#event-handling","title":"Event Handling","text":"<p>Document:</p> <ul> <li>Events emitted (e.g., <code>onStateChanged</code>, <code>onError</code>, <code>onResourceAvailable</code>)</li> <li>Listener types</li> <li>Timing guarantees or event ordering rules</li> </ul>"},{"location":"standards/interface_template/#state-machine-lifecycle","title":"State Machine / Lifecycle","text":"<p>Describe the typical session flow:</p> <ul> <li>States like <code>CLOSED</code>, <code>READY</code>, <code>STARTED</code>, <code>FLUSHING</code></li> <li>Sequence diagrams or state transition tables</li> <li>Expected order of calls and callbacks</li> </ul>"},{"location":"standards/interface_template/#data-format-protocol-support-if-applicable","title":"Data Format / Protocol Support (if applicable)","text":"Format Use Case Support Level FormatX Application data Optional"},{"location":"standards/interface_template/#platform-capabilities","title":"Platform Capabilities","text":"<p>Outline expected feature support\u2014parameter ranges, configuration values, or mode toggles exposed through <code>PlatformCapabilities</code>.</p>"},{"location":"standards/interface_template/#end-of-stream-and-error-handling","title":"End-of-Stream and Error Handling","text":"<p>Explain how the interface handles:</p> <ul> <li>Completion signals</li> <li>Error propagation and recovery</li> <li>Discontinuities or out-of-band resets</li> </ul>"},{"location":"standards/interface_template/#open-issues-todos","title":"Open Issues / TODOs","text":"<p>Track:</p> <ul> <li>Unspecified behaviour</li> <li>Items pending AIDL changes or implementation</li> <li>Gaps in validation/test coverage</li> </ul>"},{"location":"standards/rdk_central_signup/","title":"Sign Up for RDK Central Core Development Access","text":"<p>To access private repositories hosted by RDK Central, you must be added to the appropriate GitHub teams. This requires linking your GitHub public account to your RDK Central LDAP profile.</p> <p>Follow the steps below to ensure uninterrupted access to migrated repositories:</p>"},{"location":"standards/rdk_central_signup/#steps-to-register-and-gain-access","title":"Steps to Register and Gain Access","text":"<ol> <li> <p>Check if you already have an RDK Central account:</p> </li> <li> <p>If yes, skip to Step 4.</p> </li> <li> <p>If not, proceed to Step 2.</p> </li> <li> <p>Create an RDK Central account:</p> </li> <li> <p>Sign up at: https://wiki.rdkcentral.com/signup.action</p> </li> <li> <p>Wait 15 minutes after account creation to allow for LDAP propagation.</p> </li> <li> <p>Check if you already have a personal (public) GitHub account:</p> </li> <li> <p>If yes, skip to Step 6.</p> </li> <li> <p>If not, proceed to Step 5.</p> </li> <li> <p>Create a personal GitHub account:</p> </li> <li> <p>Go to https://github.com/ and click Sign up.</p> </li> <li>\u26a0\ufe0f Ensure you are logged out of any GitHub Enterprise Cloud accounts before proceeding.</li> <li> <p>Follow the on-screen instructions to complete account setup.</p> </li> <li> <p>Link your GitHub account to your RDK Central profile:</p> </li> <li> <p>Follow the steps here:      RDK Central GitHub Profile Setup Guide</p> </li> <li> <p>Accept the GitHub team invitation:</p> </li> <li> <p>An invitation will be sent to the email address associated with your GitHub personal account.</p> </li> <li>Accepting this invite will grant you access to the relevant private repositories.</li> </ol>"},{"location":"vsi/bluetooth/current/bluetooth/","title":"Bluetooth","text":""},{"location":"vsi/bluetooth/current/bluetooth/#references","title":"References","text":"<p>Info</p> Initialization - TBC systemd - hal-bluetooth.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"vsi/bluetooth/current/bluetooth/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/bluetooth/current/bluetooth/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/","title":"Directory and Dynamic Linking Specification","text":""},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#document-history","title":"Document History","text":"Date Author Comments 21 May 2025 G.Weatherup Draft Revision"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>HALIF Logging System Design</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#purpose","title":"Purpose","text":"<p>This document defines the file placement and dynamic linking policies. It ensures modularity, maintainability, and reliable integration of vendor and third-party components.</p> <p>Applicable to all vendor-provided modules, libraries, executables, and configuration files delivered in the <code>/vendor</code> partition.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#design-principles","title":"Design Principles","text":"<ul> <li>Self-contained Modules: Each vendor module resides within its own directory under <code>/vendor/&lt;module&gt;/</code>.</li> <li>Mount Isolation: <code>/vendor</code> is treated as an independent mount point, allowing separate updates and integrity checks.</li> <li>No Global Path Pollution: Avoids modifying system-level directories like <code>/etc</code> or <code>/lib</code>, unless explicitly structured.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#directory-layout","title":"Directory Layout","text":"<p>Each vendor module should follow the directory convention:</p> <pre><code>/vendor/&lt;module&gt;/\n\u251c\u2500\u2500 bin/          # Executables specific to the module\n\u251c\u2500\u2500 lib/          # Shared/static libraries used by the module\n\u251c\u2500\u2500 etc/          # Configuration files for the module\n\u251c\u2500\u2500 data/         # Optional runtime or persistent module data\n\u251c\u2500\u2500 app_armor/    # Optional AppArmor profiles for the module\n\u251c\u2500\u2500 systemd/      # Optional systemd service files\n\u251c\u2500\u2500 memory/       # Static guide to resource usage declarations\n\u251c\u2500\u2500 logs/ -&gt; /var/log/vendor/&lt;module&gt;/   # Writable logs symlink\n\u251c\u2500\u2500 ld.so.conf.d/ # Optional linker path configuration for symlink\n\u251c\u2500\u2500 VERSION       # Optional module version information\n</code></pre>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#integration-requirements","title":"Integration Requirements","text":"<ul> <li>Executables must be invoked using absolute paths.</li> <li>Any module requiring dynamic libraries must either:</li> <li>Embed RPATH during linking (<code>-Wl,-rpath,/vendor/&lt;module&gt;/lib</code>), or</li> <li>Rely on linker cache updates (see Section 6).</li> <li>Environment variables (e.g., <code>LD_LIBRARY_PATH</code>) must not be relied upon at runtime.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#dynamic-linking-and-dlopen-support","title":"Dynamic Linking and <code>dlopen()</code> Support","text":"<p>Requirement: Vendor module libraries must be made visible to the system linker via configuration files in <code>/etc/ld.so.conf.d/</code> to support standard dynamic linking and <code>dlopen()</code> usage.</p> <p>Each vendor module must provide a configuration file:</p> <pre><code>/vendor/&lt;module&gt;/ld.so.conf.d/vendor-&lt;module&gt;.conf\n</code></pre> <p>During image creation, a symbolic link must be created:</p> <pre><code>/etc/ld.so.conf.d/vendor-&lt;module&gt;.conf -&gt; /vendor/&lt;module&gt;/ld.so.conf.d/vendor-&lt;module&gt;.conf\n</code></pre> <p>Example content:</p> <pre><code>/vendor/input/lib\n</code></pre> <p>Post-Install Action: The system must execute <code>ldconfig</code> after installation or image build to regenerate the dynamic linker cache.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#apparmor-integration-and-permissions","title":"AppArmor Integration and Permissions","text":"<p>To maintain security boundaries and prevent privilege escalation, each vendor module integrated into the <code>/vendor/&lt;module&gt;/</code> structure must be governed by an AppArmor profile.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#apparmor-profile-structure","title":"AppArmor Profile Structure","text":"<p>Each module will include its AppArmor profile in:</p> <pre><code>/vendor/&lt;module&gt;/app_armor/\n</code></pre> <p>To activate the profile, a symbolic link will be created at install time:</p> <pre><code>/etc/apparmor.d/vendor-&lt;module&gt;.profile -&gt; /vendor/&lt;module&gt;/app_armor/vendor-&lt;module&gt;.profile\n</code></pre>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#enforcement-policy","title":"Enforcement Policy","text":"<ul> <li>Profiles must be in enforced mode to provide real confinement.</li> <li>Profiles are activated via systemd unit or application launcher.</li> <li>Install scripts must create appropriate symlinks into <code>/etc/apparmor.d/</code>.</li> <li>System integrators must validate that all paths used by the module are declared.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#update-and-runtime-policy","title":"Update and Runtime Policy","text":"<ul> <li><code>/vendor</code> is treated as read-only at runtime.</li> <li>Writable runtime data for modules should be stored under <code>/var/vendor/&lt;module&gt;/</code>.</li> <li>Updates to modules must not affect global system directories outside of <code>/etc/ld.so.conf.d/</code> and <code>/etc/apparmor.d/</code> symlinks.</li> <li>AppArmor profiles should be validated against updated module paths post-deployment.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#operational-considerations","title":"Operational Considerations","text":""},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#filesystem-access-policy","title":"Filesystem Access Policy","text":"<ul> <li><code>/vendor</code> is read-only at runtime.</li> <li><code>/vendor/&lt;module&gt;/log</code> is the designated writable path for runtime data, logs, and override configurations, this is a symbolic link from <code>/var/log/vendor/&lt;module&gt;/</code></li> <li>Vendor modules must not write to <code>/etc</code>, <code>/usr</code>, or other immutable parts of the root filesystem.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#memory-footprint-declarations","title":"Memory Footprint Declarations","text":"<ul> <li> <p>Each module must include a <code>memory/usage.conf</code> file declaring expected heap, stack, and static memory usage.</p> </li> <li> <p>Format:</p> </li> </ul> <pre><code>heap=4MB\nstack=512KB\nstatic=1MB\n</code></pre> <ul> <li>This allows the system to pre-allocate or validate resource claims during module startup.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#systemd-service-integration","title":"Systemd Service Integration","text":"<ul> <li>Each module may include its own <code>.service</code> file in <code>/vendor/&lt;module&gt;/systemd/</code>.</li> <li>Post-install, symlinks must be created in <code>/etc/systemd/system/</code>:</li> </ul> <pre><code>/etc/systemd/system/vendor-&lt;module&gt;.service -&gt; /vendor/&lt;module&gt;/systemd/vendor-&lt;module&gt;.service\n</code></pre> <ul> <li>Services must declare dependencies using <code>After=</code>, <code>Requires=</code>, and optionally <code>WatchdogSec=</code> for health monitoring. The vendor layer does not specify modules to be installed <code>After=</code> but milestone points to refer too.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#log-management","title":"Log Management","text":"<ul> <li>Logs must be written to:</li> </ul> <p><code>/vendor/&lt;module&gt;/log/</code></p> <ul> <li>This path must be a symbolic link to:</li> </ul> <p><code>/var/log/vendor/&lt;module&gt;/</code></p> <p>Logs will be written too <code>/vendor/&lt;module&gt;/log/</code>.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#log-file-rotation-integration","title":"Log File Rotation Integration","text":"<p>Each module may provide a standard logrotate config file:</p> <pre><code>/vendor/&lt;module&gt;/etc/logrotation.conf\n</code></pre> <p>This file can be symlinked to or copied too <code>/etc/logrotate.d/&lt;module&gt;</code> from <code>/vendor/&lt;module&gt;/etc/module_logrotate.conf</code> to integrate with the system logrotate process.</p> <pre><code>/vendor/&lt;module&gt;/log/&lt;module&gt;.log { \n  size 100k\n  rotate 5\n  compress\n  delaycompress\n  missingok\n  notifempty\n  copytruncate\n}\n</code></pre> <p>This configuration ensures:</p> <p>Logs are rotated once they exceed 100 KB.</p> <p>Up to 5 old logs are kept.</p> <p>Old logs are compressed to save space.</p> <p>Logging continues uninterrupted via copytruncate.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#log-configuration","title":"Log Configuration","text":"<p>Build-time log level configuration is defined in:</p> <p><code>/vendor/&lt;module&gt;/etc/loglevel.conf</code></p> <p>Format:</p> <p><code>loglevel=error</code></p> <p>The default log level must be set to error.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#startup-configuration-application","title":"Startup Configuration Application:","text":"<p>During system startup, the vendor platform layer is responsible for applying this syslog configuration settings for each of the modules.</p> <p>This is platform-specific and may involve setting log levels in drivers, kernel modules, or components using platform-appropriate mechanisms.</p> <p>The vendor layer team ensures this file is parsed and its value applied according to the SoC\u2019s logging configuration method.</p> <p>At runtime, a copy of the configuration is made to a writable location:</p> <p><code>/vendor/&lt;module&gt;/log/loglevel.conf</code></p> <p>Wrapper modules will read the log level from the runtime configuration file to support dynamic log level adjustments without requiring a reboot or rebuild.</p> <p>Supported log levels (ordered by severity, highest to lowest):</p> <ul> <li>fatal \u2013 Critical errors causing immediate termination.</li> <li>error \u2013 Operational failures requiring attention.</li> <li>warn \u2013 Recoverable anomalies or warnings.</li> <li>info \u2013 General informational messages.</li> <li>debug \u2013 Development-level diagnostics.</li> <li>trace \u2013 Highly granular tracing for deep debugging.</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#logging-mechanism","title":"Logging Mechanism","text":""},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#syslog-usage-","title":"Syslog Usage:-","text":"<p>Vendor modules are expected to use syslog for log message emission wherever platform support allows.</p> <p>This ensures logs are centrally accessible and manageable through standard tools (e.g., logread, journalctl, or remote syslog sinks).</p> <p>Wrapper Requirement:</p> <p>Direct usage of <code>syslog()</code> is not permitted.</p> <p>Vendors are expected to use the logging wrapper APIs provided by the HAL (Hardware Abstraction Layer).</p> <p>These wrappers:</p> <p>Read and cache the active log level (as configured by the platform during startup).</p> <p>Filter messages based on severity.</p> <p>Format and dispatch logs appropriately to syslog or other targets.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#version-declaration-optional","title":"Version Declaration (Optional)","text":"<ul> <li>Each module may include a file <code>/vendor/&lt;module&gt;/VERSION</code> with contents akin to:</li> </ul> <pre><code>version=MAJOR.MINOR.PATCH\nbuild_date=YYYYMMDD\nbuild_sha=sha256:&lt;value&gt;\n</code></pre> <ul> <li>Version should be Semantic Versioning (SemVer).</li> </ul>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#appendix-example-integration-with-alternate-install-root","title":"Appendix: Example Integration with Alternate Install Root","text":"<p>This section provides a concrete example of how a vendor module can integrate with the <code>/vendor/sysint/${sysconfdir}</code> structure in compliance with the directory and dynamic linking policies described above.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#overview","title":"Overview","text":"<p>This module is installed under the path <code>/vendor/sysint</code>, with all configuration, systemd, logging, versioning, and dynamic linker artifacts scoped within this directory. Integration points such as AppArmor and ld.so.conf.d use symbolic links into <code>/etc/</code> to preserve system-wide access.</p>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#directory-structure","title":"Directory Structure","text":"<pre><code>/vendor/sysint/\n\u251c\u2500\u2500 etc/\n\u2502   \u251c\u2500\u2500 partners_defaults_device.json\n\u2502   \u251c\u2500\u2500 device-vendor.properties\n\u2502   \u251c\u2500\u2500 rfcdefaults/\n\u2502   \u2514\u2500\u2500 logrotation.conf\n\u251c\u2500\u2500 lib/rdk/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 systemd/\n\u2502   \u2514\u2500\u2500 start-up-scripts.service\n\u251c\u2500\u2500 app_armor/\n\u2502   \u2514\u2500\u2500 vendor-sysint.profile\n\u251c\u2500\u2500 ld.so.conf.d/\n\u2502   \u2514\u2500\u2500 vendor-sysint.conf\n\u2514\u2500\u2500 VERSION\n</code></pre>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#installation-snippet-yocto-style-do_install","title":"Installation Snippet (Yocto-style <code>do_install()</code>)","text":"<pre><code>INSTALL_ROOT=\"/vendor/sysint\"\ninstall -d ${D}${INSTALL_ROOT}${sysconfdir}\ninstall -d ${D}${INSTALL_ROOT}${sysconfdir}/rfcdefaults\ninstall -d ${D}${INSTALL_ROOT}${base_libdir}/rdk\ninstall -d ${D}${INSTALL_ROOT}${systemd_unitdir}/system\ninstall -d ${D}/etc/ld.so.conf.d\ninstall -d ${D}/etc/apparmor.d\ninstall -d ${D}/etc/systemd/system\ninstall -d ${D}/etc/logrotate.d\n\n# Config and Binary Placement\ninstall -m 0644 ${S}/etc/partners_defaults_device.json ${D}${INSTALL_ROOT}${sysconfdir}\ninstall -m 0755 ${S}/etc/device-vendor.properties ${D}${INSTALL_ROOT}${sysconfdir}\ninstall -m 0755 ${S}/lib/rdk/* ${D}${INSTALL_ROOT}${base_libdir}/rdk\ninstall -m 0644 ${S}/systemd_units/start-up-scripts.service ${D}${INSTALL_ROOT}${systemd_unitdir}/system\n\n# Clean Up Pre-existing Keys\nfor key in MODEL_NUM FW_VERSION_TAG1 FW_VERSION_TAG2 MANUFACTURE FRIENDLY_ID USB_POWER_GPIO_NUMBER USB_A_POWER_GPIO_NUMBER MFG_NAME; do\n  sed -i \"/$key/d\" ${D}${INSTALL_ROOT}${sysconfdir}/device-vendor.properties\n  echo \"$key=&lt;default_or_variable_value&gt;\" &gt;&gt; ${D}${INSTALL_ROOT}${sysconfdir}/device-vendor.properties\ndone\n\n# AppArmor\ninstall -d ${D}${INSTALL_ROOT}/app_armor\ninstall -m 0644 ${S}/etc/apparmor/vendor-sysint.profile ${D}${INSTALL_ROOT}/app_armor/\nln -sf ${INSTALL_ROOT}/app_armor/vendor-sysint.profile ${D}/etc/apparmor.d/vendor-sysint.profile\n\n# Dynamic Linker Configuration\ninstall -d ${D}${INSTALL_ROOT}/ld.so.conf.d\necho \"${INSTALL_ROOT}/lib\" &gt; ${D}${INSTALL_ROOT}/ld.so.conf.d/vendor-sysint.conf\nln -sf ${INSTALL_ROOT}/ld.so.conf.d/vendor-sysint.conf ${D}/etc/ld.so.conf.d/vendor-sysint.conf\n\n# Logrotate\ninstall -m 0644 ${S}/etc/module_logrotate.conf ${D}${INSTALL_ROOT}${sysconfdir}/logrotation.conf\nln -sf ${INSTALL_ROOT}${sysconfdir}/logrotation.conf ${D}/etc/logrotate.d/sysint\n\n# Systemd\nln -sf ${INSTALL_ROOT}${systemd_unitdir}/system/start-up-scripts.service ${D}/etc/systemd/system/vendor-sysint.service\n\n# Version Metadata\nmkdir -p ${D}${INSTALL_ROOT}\necho \"src_version=$(cd ${S} &amp;&amp; git describe --tags --always || echo unknown)\" &gt; ${D}${INSTALL_ROOT}/VERSION\necho \"build_date=$(date '+%Y-%m-%d %H:%M:%S %Z')\" &gt;&gt; ${D}${INSTALL_ROOT}/VERSION\n\n# This version reflects the git-describe version of the recipe itself (.bb file)\necho \"recipe_version=$(cd $(dirname ${BBPATH})/../.. &amp;&amp; git describe --tags --always 2&gt;/dev/null || echo unknown)\" &gt;&gt; ${D}${INSTALL_ROOT}/VERSION\n\n# If other includes are referenced (e.g., sysint-oem.inc), optionally record their version too:\necho \"sysint-oem.inc_version=$(cd ${LAYERDIR}/recipes-extended/sysint &amp;&amp; git describe --tags --always sysint-oem.inc 2&gt;/dev/null || echo unknown)\" &gt;&gt; ${D}${INSTALL_ROOT}/VERSION\n</code></pre>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#example-version-file","title":"Example <code>VERSION</code> File","text":"<pre><code>src_version=2.5.0-123-gabcde12\nbuild_date=2025-06-20 14:45:30 UTC\nrecipe_version=2.5.0-123-gabcde12\nsysint-oem.inc_version=sysint-oem-1.3.2-45-gabcdef1\n</code></pre>"},{"location":"vsi/filesystem/current/directory_and_dynamic_linking_specification/#compliance-notes","title":"Compliance Notes","text":"<ul> <li>All artifacts are scoped to the module directory under <code>/vendor/sysint</code>.</li> <li>Global system directories are only modified via symlinks into expected locations.</li> <li>The <code>VERSION</code> file provides build provenance including Git tag of the recipe and any referenced include.</li> <li>This supports modular updates and ensures the system remains maintainable, verifiable, and secure.</li> </ul>"},{"location":"vsi/filesystem/current/file_system/","title":"File System","text":""},{"location":"vsi/filesystem/current/file_system/#references","title":"References","text":"<p>Info</p> VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"vsi/filesystem/current/file_system/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/filesystem/current/file_system/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/","title":"HALIF Logging System Design","text":"<p>This document defines the architecture and API design for the HALIF logging system. It provides a modular, per-instance logging framework aligned with syslog semantics, and supports runtime configuration and status code interpretation.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#document-history","title":"Document History","text":"Date Author Comments 04 June 2025 G.Weatherup Draft Revision"},{"location":"vsi/filesystem/current/halif_logging_system_design/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>Directory And Dynamic Linking Specification</li> </ul>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#1-overview","title":"1. Overview","text":"<p>The HALIF logging system is intended for use within vendor modules. It abstracts syslog interaction, enforces log level filtering, supports dynamic configuration via a specified config file, and allows structured status reporting using module-specific lookup tables.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#2-logging-handle-structure","title":"2. Logging Handle Structure","text":"<p>Each component that needs to log must initialize a <code>halif_log_handle_t</code>. This handle encapsulates the logging tag (typically the module name), current log level, and optional status code lookup table.</p> <p>Internally, this struct includes:</p> <ul> <li><code>const char* tag</code>: Module identifier used in log prefixes.</li> <li><code>halif_log_level_t level</code>: Current effective log level.</li> <li><code>halif_status_lookup_t* status_table</code>: Optional pointer to user-defined status strings.</li> <li><code>const char* config_path</code>: Path to the module's loglevel config file.</li> <li>Timestamp or flag for monitoring config reload.</li> </ul>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#3-log-levels","title":"3. Log Levels","text":"<p>Log levels are aligned with syslog constants to support integration with the platform logging system:</p> <ul> <li><code>HALIF_LOG_FATAL</code>   = LOG_CRIT</li> <li><code>HALIF_LOG_ERROR</code>   = LOG_ERR</li> <li><code>HALIF_LOG_WARN</code>    = LOG_WARNING</li> <li><code>HALIF_LOG_INFO</code>    = LOG_INFO</li> <li><code>HALIF_LOG_DEBUG</code>   = LOG_DEBUG</li> </ul>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#4-core-api","title":"4. Core API","text":""},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_open","title":"halif_log_open","text":"<p>Initializes a log handle for a given module.</p> <pre><code>halif_log_handle_t* halif_log_open(const char* logShortPrefix, const char* configPath);\n</code></pre> <p>Loads the initial log level from the config file and prepares the handle for use.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_close","title":"halif_log_close","text":"<p>Releases any resources held by the logging handle.</p> <pre><code>void halif_log_close(halif_log_handle_t* handle);\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_write","title":"halif_log_write","text":"<p>Logs a formatted message at a given severity level. Filtering is handled internally by the logging system.</p> <pre><code>void halif_log_write(halif_log_handle_t* handle, halif_log_level_t level, const char* fmt, ...);\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#5-logging-macros","title":"5. Logging Macros","text":"<p>To simplify use, macros are provided for each log level. These macros delegate directly to <code>halif_log_write()</code> and automatically include the function name and line number:</p> <ul> <li><code>#define HALIF_LOG_FATAL(log_instance, fmt, ...) halif_log_write(log_instance, HALIF_LOG_FATAL, \"[%s:%d] \" fmt, __func__, __LINE__, ##__VA_ARGS__)</code></li> <li><code>#define HALIF_LOG_ERROR(log_instance, fmt, ...) halif_log_write(log_instance, HALIF_LOG_ERROR, \"[%s:%d] \" fmt, __func__, __LINE__, ##__VA_ARGS__)</code></li> <li><code>#define HALIF_LOG_WARN(log_instance, fmt, ...) halif_log_write(log_instance, HALIF_LOG_WARN, \"[%s:%d] \" fmt, __func__, __LINE__, ##__VA_ARGS__)</code></li> <li><code>#define HALIF_LOG_INFO(log_instance, fmt, ...) halif_log_write(log_instance, HALIF_LOG_INFO, \"[%s:%d] \" fmt, __func__, __LINE__, ##__VA_ARGS__)</code></li> <li><code>#define HALIF_LOG_DEBUG(log_instance, fmt, ...) halif_log_write(log_instance, HALIF_LOG_DEBUG, \"[%s:%d] \" fmt, __func__, __LINE__, ##__VA_ARGS__)</code></li> </ul>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#6-runtime-configuration","title":"6. Runtime Configuration","text":"<p>Each handle loads its log level from a config file, typically located at:</p> <pre><code>/vendor/&lt;module&gt;/log/loglevel.conf\n</code></pre> <p>The format of the file is:</p> <pre><code>loglevel=error\n</code></pre> <p>The HALIF system may monitor this file using <code>inotify</code> or polling to support runtime log level updates.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_set_level","title":"halif_log_set_level","text":"<p>Allows the caller to override the current log level manually at runtime.</p> <pre><code>void halif_log_set_level(halif_log_handle_t* handle, halif_log_level_t level);\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#7-status-code-logging","title":"7. Status Code Logging","text":""},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_set_status_table","title":"halif_log_set_status_table","text":"<p>Registers a lookup table of numeric status codes to human-readable strings with a logging handle.</p> <pre><code>void halif_log_set_status_table(halif_log_handle_t* handle, const halif_status_lookup_t* lookup);\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_status","title":"halif_log_status","text":"<p>Logs a function return code using the registered status table. If the code is recognized, it is logged by name and value; otherwise, it logs the numeric value with an \"unknown\" label.</p> <pre><code>void halif_log_status(halif_log_handle_t* handle, const char* function, uint32_t status_code);\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_log_status-macro","title":"HALIF_LOG_STATUS Macro","text":"<pre><code>#define HALIF_LOG_STATUS(handle, status_code) \\\n    halif_log_status(handle, __func__, status_code)\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#8-example-usage","title":"8. Example Usage","text":"<pre><code>const const char *module_status_strs[] =\n{\n    \"STATUS_OK\",\n    \"STATUS_INVALID_INSTANCE\",\n    \"STATUS_INVALID_PARAM\",\n    \"STATUS_NOT_FOUND\",\n    \"STATUS_MAX\"\n};\n\nhalif_log_handle_t *module_log_instance = halif_log_open(\"MODULE\", \"/vendor/module/log/loglevel.conf\");\nconst char *resultString;\n\nhalif_log_set_status_table(module_log_instance, module_status_strs);\n\nHALIF_LOG_RESULT(module_log_instance, &amp;resultString, STATUS_NOT_FOUND);\nHALIF_LOG_INFO(module_log_instance, \"Initialization complete Status: [%s]\", resultString);\n</code></pre> <ul> <li>Example Output</li> </ul> <pre><code>Jun  4 15:35:01:MODULE[PID]:[some_function_name:123]:Initialization complete Status: [STATUS_NOT_FOUND (3)]\n</code></pre>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#9-legacy-printf-fallback-support","title":"9. Legacy Printf Fallback Support","text":"<p>To support incremental migration from legacy <code>printf()</code>-based logging, the HALIF system provides a fallback mechanism.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#static-handle","title":"Static Handle","text":"<p>Each module implicitly declares:</p> <pre><code>static halif_log_handle_t* log_instance;\n</code></pre> <p>This handle is automatically scoped to the module, ensuring no cross-module conflicts.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#printf-macro-override","title":"Printf Macro Override","text":"<p>To convert <code>printf</code> to HALIF log module, users should add a macro such as:</p> <pre><code>static halif_log_handle_t* printfLogHandle;\n#define printf(fmt, ...) \\\n    do { \\\n        if (printfLogHandle) \\\n            halif_log_write(printfLogHandle, HALIF_LOG_INFO, fmt, ##__VA_ARGS__); \\\n    } while (0)\n...\n    printfLogHandle = halif_log_open(\"MODULE\", \"/vendor/module/log/loglevel.conf\");\n</code></pre> <p>This allows existing <code>printf()</code> calls to be captured and routed through HALIF without requiring immediate code changes.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#migration-path","title":"Migration Path","text":"<ol> <li>Each module includes <code>halif_log.h</code>.</li> <li>The static <code>log_instance</code> is initialized via <code>halif_log_open()</code>.</li> <li>Legacy <code>printf()</code> calls automatically use HALIF.</li> <li>Developers incrementally replace <code>printf()</code> with <code>HALIF_LOG_*</code> macros.</li> <li>Once fully migrated, the <code>printf</code> macro override can be removed.</li> </ol>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#example","title":"Example","text":"<pre><code>#include \"halif_log.h\"\n\nvoid module_init() \n{\n    printfLogHandle = halif_log_open(\"MODULE\", \"/vendor/module/log/loglevel.conf\");\n    printf(\"Initializing module...\\n\"); // Routed through HALIF\n}\n\nvoid module_deinit() \n{\n    halif_log_close(printfLogHandle);\n    printfLogHandle = NULL;\n}\n</code></pre> <p>This fallback strategy enables a controlled and reversible transition to structured logging.</p>"},{"location":"vsi/filesystem/current/halif_logging_system_design/#10-utility-macros","title":"10. Utility Macros","text":""},{"location":"vsi/filesystem/current/halif_logging_system_design/#halif_module_config_path","title":"HALIF_MODULE_CONFIG_PATH","text":"<p>Optional macro to create a module config path:</p> <pre><code>#define HALIF_MODULE_CONFIG_PATH(module) \"/vendor/\" module \"/log/loglevel.conf\"\n</code></pre> <p>Usage:</p> <pre><code>halif_log_handle_t* log_instance;\n\n    log_instance = halif_log_open(\"MOD\", HALIF_MODULE_CONFIG_PATH(\"module\"));\n</code></pre>"},{"location":"vsi/graphics/current/graphics/","title":"Graphics","text":""},{"location":"vsi/graphics/current/graphics/#references","title":"References","text":"<p>Info</p> Initialization - TBC systemd - hal-graphics.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"vsi/graphics/current/graphics/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/graphics/current/graphics/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/kernel/current/kernel/","title":"Kernel","text":""},{"location":"vsi/kernel/current/kernel/#references","title":"References","text":"<p>Info</p> VTS Tests TBC"},{"location":"vsi/kernel/current/kernel/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/kernel/current/kernel/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/linux_input/current/linux_input/","title":"Linux Input","text":""},{"location":"vsi/linux_input/current/linux_input/#references","title":"References","text":"<p>Info</p> VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"vsi/linux_input/current/linux_input/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/linux_input/current/linux_input/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/service_manager/current/service_manager/","title":"Service Manager","text":"<p>The Service Manager is a crucial Binder service included in the vendor layer. It is launched early in system initialization and serves as a registry for Binder service interfaces.</p> <ul> <li>As each HAL service starts, it registers its public Binder interface with the Service Manager.</li> <li>Registered interfaces are added to the Service Manager\u2019s list, making them discoverable by clients.</li> <li>Clients can retrieve a registered service interface by calling <code>getService()</code> with the corresponding service name.</li> </ul>"},{"location":"vsi/service_manager/current/service_manager/#references","title":"References","text":"<p>Info</p> Interface Definition IServiceManager API Documentation TBD - Doxygen HAL Interface Type AIDL and Binder Initialization - TBC systemd - hal-service_manager.service VTS Tests TBC"},{"location":"vsi/service_manager/current/service_manager/#implementation-requirements","title":"Implementation Requirements","text":"# Requirement Comments HAL.SERVICEMAN.1 Service Manager shall initialise and run early boot time to allow HAL servers to register their binder service interfaces as they start up. HAL.SERVICEMAN.2 The list of registered services shall be listable for developers and testers to list on the device. HAL.SERVICEMAN.3 HAL services shall be able to register their public HAL interfaces with Service Manager using the string name defined in the AIDL file. HAL.SERVICEMAN.4 Clients shall obtain a public HAL interface using a string name from Service Manager."},{"location":"vsi/service_manager/current/service_manager/#interface-definition","title":"Interface Definition","text":"<p>Client code accesses the Service Manager by including C++ <code>IServiceManager.h</code> header and using the <code>getService()</code> function to access registered binder service interfaces.</p> <p>See https://android.googlesource.com/platform/frameworks/native/+/android-13.0.0_r74/libs/binder/include/binder/IServiceManager.h</p> <p>HAL binder services register an interface by calling the <code>publishAndJoinThreadPool()</code> static method on their interface class.</p> <p>See https://android.googlesource.com/platform/frameworks/native/+/android-13.0.0_r74/libs/binder/include/binder/BinderService.h</p>"},{"location":"vsi/service_manager/current/service_manager/#initialization","title":"Initialization","text":"<p>The systemd <code>hal-service_manager.service</code> unit file is provided by the vendor layer to start the service.</p> <p>The Service Manager depends on the kernel binder driver.</p>"},{"location":"vsi/service_manager/current/service_manager/#product-customization","title":"Product Customization","text":"<p>The Service Manager is universal code that must be compiled and delivered as part of the vendor layer.</p>"},{"location":"vsi/service_manager/current/service_manager/#system-context","title":"System Context","text":"<p>The Service Manager handles service registration from HAL binder services and provides clients access to registered binder interfaces.</p> <p>The list of registered binder interfaces builds up during boot.</p> <p></p>"},{"location":"vsi/service_manager/current/service_manager/#building","title":"Building","text":"<p>To build the Service Manager from source, use the links to the source repository and patch repository below. The patch is required to build it for RDK.</p> <p>For details on building the executable, see https://github.com/rdkcentral/linux_binder_idl/tree/main?tab=readme-ov-file#additional-build-options.</p> Description Repository Service Manager TODO: Review Required: https://android.googlesource.com/platform/frameworks/native/+/refs/tags/android-13.0.0_r74/cmds/servicemanager/ RDK patch https://github.com/rdkcentral/linux_binder_idl/blob/main/patches/native.patch)"},{"location":"vsi/service_manager/current/service_manager/#client-access-to-service-manager","title":"Client Access to Service Manager","text":"<p>For sample code, see https://github.com/rdkcentral/linux_binder_idl/tree/main/example.</p> <p>The <code>IServiceManager.h</code> file can be found here: https://android.googlesource.com/platform/frameworks/native/+/android-13.0.0_r74/libs/binder/include/binder/IServiceManager.h</p> <pre><code>sp&lt;IFWManager&gt; fwManagerService;\nstatus_t status;\n\n// Get the binder interface for the service.\nstatus = getService(String16(\"FWManagerService\"), &amp;fwManagerService);\nif (status != OK) {\n    printf(\"\\nFWManagerTestApp : Failed to Get FWManagerService handle from ServiceManager : [%s]\\n\", Status::fromStatusT(status).toString8().c_str());\n    return -1;\n}\n\n// Use the interface to make a call.\nFirmwareStatus fwStatus;\nStatus binderStatus;\nbinderStatus = fwManagerService-&gt;getFirmwareUpdateState(&amp;fwStatus);\n</code></pre>"},{"location":"vsi/service_manager/current/service_manager/#clients-waiting-for-services","title":"Clients Waiting for Services","text":"<p>A client can call the <code>waitForService()</code> function to block until a HAL binder service becomes initialized and registered.</p> <p>This may happen if the client is allowed to execute before or while the HAL service is initializing, but then needs to synchronize with the HAL service registration before it can proceed.</p> <p>See <code>waitForService()</code> in https://android.googlesource.com/platform/frameworks/native/+/android-13.0.0_r74/libs/binder/include/binder/IServiceManager.h</p>"},{"location":"vsi/systemd/current/systemd/","title":"SystemD","text":""},{"location":"vsi/systemd/current/systemd/#references","title":"References","text":"<p>Info</p> VTS Tests TBC"},{"location":"vsi/systemd/current/systemd/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/systemd/current/systemd/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"vsi/wifi/current/wifi/","title":"WiFi","text":""},{"location":"vsi/wifi/current/wifi/#references","title":"References","text":"<p>Info</p> Initialization - TBC systemd - hal-wifi.service VTS Tests TBC Reference Implementation - vComponent TBD"},{"location":"vsi/wifi/current/wifi/#related-pages","title":"Related Pages","text":"<p>Tip</p> <ul> <li>TBC</li> </ul>"},{"location":"vsi/wifi/current/wifi/#document-under-construction","title":"\ud83d\udea7 Document Under Construction","text":"<p>This document serves as a placeholder.</p> <p>The content is not yet released and is currently under construction.</p> <p>Please check back later for updates.</p>"},{"location":"whitepapers/branching_strategies/","title":"White Paper: Branching Strategies for Modern Software Delivery","text":""},{"location":"whitepapers/branching_strategies/#executive-summary","title":"Executive Summary","text":"<p>In today\u2019s fast-paced software landscape, release cadences are accelerating, and codebases must adapt to continuous integration and delivery. To keep up, development teams need a robust and well-defined branching strategy. By choosing and tailoring the right approach be it Git Flow, GitHub Flow, Scaled Trunk-Based Development, or a sprint-based model teams can reduce merge complexity, maintain high code quality, and ensure seamless releases. This white paper explores the most common branching strategies, outlines their strengths and weaknesses, and offers guidance on selecting and implementing the best approach for your organisation.</p>"},{"location":"whitepapers/branching_strategies/#introduction","title":"Introduction","text":"<p>Version control is the cornerstone of modern software development, enabling collaborative workflows and repeatable deployments. However, simply storing code in a repository is insufficient for teams that need to manage parallel development, address hotfixes, or support multiple releases. Branching strategies define how code is organised and merged, determining how quickly features are delivered and how often releases can be confidently pushed to production.</p>"},{"location":"whitepapers/branching_strategies/#purpose-and-scope","title":"Purpose and Scope","text":"<p>This white paper provides an overview of prominent branching methodologies, comparing their suitability for different team sizes, product types, and release demands. It aims to help technical leaders, architects, and DevOps practitioners understand the trade-offs of each strategy and make informed decisions when establishing or refining their workflow.</p>"},{"location":"whitepapers/branching_strategies/#the-landscape-of-branching-strategies","title":"The Landscape of Branching Strategies","text":""},{"location":"whitepapers/branching_strategies/#1-git-flow","title":"1. Git Flow","text":"<p>Developed by Vincent Driessen, Git Flow introduces dedicated branches for feature, release, and hotfix work, all branching off from a central development branch (often called \u201cdevelop\u201d) and eventually merging back into main (or \u201cmaster\u201d) when ready to release.  </p> <p>Strengths:</p> <ul> <li>Clear structure for teams that manage multiple versions.  </li> <li>Separates ongoing development from stable releases, reducing risk in production.  </li> </ul> <p>Weaknesses:</p> <ul> <li>More complex; the overhead of creating and merging branches can slow continuous integration (CI).  </li> <li>Unsuitable for very fast-paced environments that require continuous deployment (CD).  </li> </ul> <p>Use Cases:</p> <ul> <li>Teams that need prolonged support of past releases.  </li> <li>Organisations with moderate to large teams and well-defined release cycles.</li> </ul>"},{"location":"whitepapers/branching_strategies/#2-github-flow","title":"2. GitHub Flow","text":"<p>GitHub Flow is a simpler model that typically uses only two main branch types: main and short-lived feature branches. Developers open pull requests against main, and after review and testing, changes are merged and deployed.  </p> <p>Strengths:</p> <ul> <li>Lightweight, minimal overhead.  </li> <li>Works well for small teams focused on a single production version.  </li> </ul> <p>Weaknesses:</p> <ul> <li>Less suited to environments that must simultaneously support multiple versions or long-term releases.  </li> <li>Requires disciplined merging to avoid feature branches lingering and creating merge conflicts.  </li> </ul> <p>Use Cases:</p> <ul> <li>Small or startup teams where rapid iteration is a priority.  </li> <li>Web applications often updated multiple times a day.</li> </ul>"},{"location":"whitepapers/branching_strategies/#3-scaled-trunk-based-development","title":"3. Scaled Trunk-Based Development","text":"<p>Trunk-Based Development (TBD) encourages merging all work directly into a single \u201ctrunk\u201d (or main), using very short-lived branches (hours or days, not weeks). This strategy can scale by using ephemeral feature branches, but the principle remains: keep the main branch always in a shippable state.  </p> <p>Strengths:  </p> <ul> <li>Minimises integration overhead and merge conflicts; ideal for continuous integration (CI).  </li> <li>Faster iteration cycles, since developers integrate changes more frequently.  </li> </ul> <p>Weaknesses:  </p> <ul> <li>Requires robust automated testing and team discipline to ensure stability.  </li> <li>Features or bug fixes can be partially exposed if toggles or stubs are not in place.  </li> </ul> <p>Use Cases:  </p> <ul> <li>Teams practicing DevOps or CI/CD pipelines who value immediate feedback.  </li> <li>Organisations aiming for extremely frequent, \u201calways deployable\u201d releases.</li> </ul>"},{"location":"whitepapers/branching_strategies/#4-sprintstable-model","title":"4. Sprint/Stable Model","text":"<p>Some organisations adopt a sprint-based approach, branching off each component at the beginning of a sprint. After testing and validation, only selected changes merge into a \u201cstable\u201d branch (e.g. <code>stable2</code>).  </p> <p>Strengths:</p> <ul> <li>Aligns with fixed development sprints and short-term planning.  </li> <li>Provides a controlled environment for iterative testing before merging to stable.  </li> </ul> <p>Weaknesses:</p> <ul> <li>Frequent branching can become cumbersome if not tracked carefully.  </li> <li>Requires additional overhead in cherry-picking or merges back to stable.  </li> </ul> <p>Use Cases:</p> <ul> <li>Companies with a legacy release process and large codebases that rely on sprint-based planning.  </li> <li>Teams that want clear, time-boxed development cycles and sign-off periods.</li> </ul>"},{"location":"whitepapers/branching_strategies/#key-considerations","title":"Key Considerations","text":"<p>1. Team Size and Collaboration:</p> <ul> <li>Small teams often benefit from minimal branching overhead (e.g. GitHub Flow).  </li> <li>Large teams may prefer structures like Git Flow or trunk-based with special gating to control parallel work streams.</li> </ul> <p>2. Release Cadence:</p> <ul> <li>Fast, continuous deployment: Trunk-Based Development or a lightweight model like GitHub Flow.  </li> <li>Long-lived releases: Git Flow or a stable release branching approach.</li> </ul> <p>3. Maintenance and Support:</p> <ul> <li>Multiple versions in production typically require dedicated release branches (Git Flow or a custom approach).  </li> <li>Minimising support overhead may lead to trunk-based strategies with feature toggles rather than parallel release branches.</li> </ul> <p>4. Tooling and Automation:</p> <ul> <li>Automated testing pipelines are critical for quick merges and continuous feedback.  </li> <li>Feature flags or toggles are essential for trunk-based or GitHub Flow to prevent partial features from affecting users.</li> </ul> <p>5. Organisational Culture:</p> <ul> <li>Strategies requiring frequent merges and shipping code (e.g. trunk-based) work best in cultures that encourage collaboration, continuous learning, and quality.  </li> <li>More traditional enterprises with strict sign-off processes can find comfort in a well-defined release branching strategy (e.g. Git Flow).</li> </ul>"},{"location":"whitepapers/branching_strategies/#recommendations-by-product-type","title":"Recommendations by Product Type","text":"Product Type Team Size Release Frequency Recommended Strategy SaaS platforms with near-constant deployments Small Frequent Scaled Trunk-Based Web apps or services with single production version Middle Frequent GitHub Flow or Scaled Trunk-Based Mobile apps needing periodic, staged releases Middle Periodic/Slow Git Flow or Scaled TBD Complex products requiring multiple versions, extended support (e.g. embedded devices, set-top boxes) Medium-Large Periodic/Slow Git Flow Organisations with sprint-based cycles and centralised approvals (e.g. some enterprise environments) Medium-Large Variable Sprint/Stable Model or Modified Git Flow"},{"location":"whitepapers/branching_strategies/#implementation-and-best-practices","title":"Implementation and Best Practices","text":"<p>Adopt Meaningful Versioning:</p> <ul> <li>Use Semantic Versioning (SemVer) or incremental versioning to clarify the impact of changes for downstream teams and customers.  </li> <li>Keep documentation aligned with each release to reduce confusion. See White Paper: Documentation in Git</li> </ul> <p>Invest in Automation:</p> <ul> <li>Local Testing First: Each engineer is responsible for running local tests (unit, integration, or smoke tests) before opening a Pull Request (PR). This ensures that immediate issues are caught and resolved early.</li> <li>CI Pipelines for Scale: Once a PR is created, Continuous Integration (CI) pipelines perform out-of-bounds or multi-platform checks, static analysis, and other automated verifications that may be impractical to run locally. This approach catches environment-specific regressions and ensures consistent code quality.</li> </ul> <p>Enforce Quality Gates:</p> <ul> <li>Use pull requests with mandatory reviews, ensuring code quality and fostering knowledge sharing.  </li> <li>Require green builds and pass all tests before merging to main or release branches.</li> </ul> <p>Monitor Branch Lifespans:</p> <ul> <li>Keep feature branches short-lived. Frequent merges reduce merge conflicts and isolate issues quickly.  </li> <li>Carefully manage release branches, merging back fixes to main/develop as soon as possible.</li> </ul> <p>Evolve Strategically:</p> <ul> <li>Branching strategies aren\u2019t static. Teams may start with Git Flow and gradually transition to trunk-based as their CI/CD maturity grows.  </li> <li>Run retrospectives after each release or major feature to assess merging pain points and refine workflows.</li> </ul>"},{"location":"whitepapers/branching_strategies/#conclusion","title":"Conclusion","text":"<p>Choosing the right branching strategy is less about following a rigid template and more about aligning with your organisation\u2019s goals, release cadences, team size, and product needs. Git Flow, GitHub Flow, Scaled Trunk-Based Development, and sprint-based models each have distinct advantages. By understanding their respective trade-offs and applying them thoughtfully supported by robust automation, clear versioning, and streamlined processes development teams can reduce integration friction, improve reliability, and accelerate their path to market.</p>"},{"location":"whitepapers/branching_strategies/#references-and-further-reading","title":"References and Further Reading","text":"<ul> <li>GitHub flow vs. trunk-based Medium: GitHub Flow vs. Trunk-Based Development </li> <li>Multiple branching strategies AB Tasty: Git Branching Strategies </li> <li>Git Flow vs. Trunk-Based Development LanchDarkly: Branching Strategies vs Trunk Based Development GitVersion: GitFlow Examples </li> <li>Trunk-Based Development vs. Feature-Based Mergify: Trunk-Based Development vs. Feature-Based Development </li> </ul> <p>Author: Gerald Weatherup Date: 03 March 2025</p> <p>For questions or suggestions on implementing branching strategies, please contact the Architecture team.</p>"},{"location":"whitepapers/documentation_in_git/","title":"White Paper: Documentation in Git","text":""},{"location":"whitepapers/documentation_in_git/#executive-summary","title":"Executive Summary","text":"<p>Modern software development requires a dependable system for managing both source code and its accompanying documentation. When code and documentation reside in separate repositories or locations, they can quickly fall out of sync, leading to confusion and technical debt. By co-locating design and specification documents alongside the code itself using Doxygen-based comments and Markdown-based documentation (compiled by tools like MkDocs) teams can:</p> <ul> <li>Maintain Consistency: All interfaces, testing suites, and documentation evolve together, eliminating discrepancies.  </li> <li>Enable Full Control &amp; Versioning: Every change is tracked through Git\u2019s history, ensuring a transparent record of updates for code and docs alike.  </li> <li>Enforce Peer-Reviewed Quality: Documentation changes are reviewed just as rigorously as code changes.  </li> <li>Streamline Releases: A tag-based publishing process ensures that released documentation accurately matches stable code.</li> </ul> <p>This white paper outlines an approach to achieving a \u201csingle source of truth\u201d for software projects, leveraging Git-based workflows whether in private, enterprise, or open-source settings.</p>"},{"location":"whitepapers/documentation_in_git/#1-purpose-of-this-white-paper","title":"1. Purpose of This White Paper","text":"<p>This document details how to organise and maintain design, specification, and testing documentation within the same repository as the source code. By doing so, teams ensure:</p> <ul> <li>Synchronisation of all technical details with implementation and test suites.  </li> <li>Traceability and transparency of updates through Git commit history.  </li> <li>Easy Automation of documentation generation and publishing processes.  </li> </ul>"},{"location":"whitepapers/documentation_in_git/#intended-audience","title":"Intended Audience","text":"<ul> <li>Engineering Teams &amp; Architects: Responsible for code, interface definitions, and system design.  </li> <li>Technical Writers: Creating, maintaining, and publishing comprehensive documentation.  </li> <li>DevOps/CI Specialists: Implementing controlled release processes for both code and docs.  </li> <li>Product Stakeholders: Requiring reliable, up-to-date release information.</li> </ul> <p>Although written with internal teams in mind, these practices translate seamlessly to open source projects, promoting a collaborative and transparent environment.</p>"},{"location":"whitepapers/documentation_in_git/#2-documentation-strategy","title":"2. Documentation Strategy","text":""},{"location":"whitepapers/documentation_in_git/#why-a-single-source-of-truth","title":"Why a Single Source of Truth?","text":"<p>Best practices recommend treating documentation with the same discipline as source code often called \u201cdocumentation as code.\u201d By placing:</p> <ul> <li>Interfaces (e.g., HAL or API specs)  </li> <li>Test Suites validating these interfaces  </li> <li>Documentation (architecture overviews, usage guides, etc.)</li> </ul> <p>in the same repository, you gain:</p> <ul> <li>Version Control: Code, tests, and docs share the same commit history, simplifying rollbacks and issue tracking.  </li> <li>Discoverability: Developers and reviewers find all relevant information in one place.  </li> <li>Consistency: Docs remain updated alongside code changes.  </li> <li>Collaboration: Contributions to both code and documentation occur through a unified workflow.  </li> <li>Automation: Tools such as Doxygen, Sphinx, and MkDocs can automatically generate documentation from in-code comments and Markdown.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#where-to-store-documentation","title":"Where to Store Documentation","text":"<ul> <li>Within the Same Repo: Primary approach for coupling code and docs.  </li> <li>Separate Repos: If code or testing suites are maintained in their own repositories, then the associated documentation must also reside within those repositories. This approach ensures each codebase or test suite remains a single source of truth, preserving consistency and discoverability across the project.</li> </ul> <p>This integrated approach ensures that interface definitions, test coverage, and user-facing documentation evolve in tandem.</p>"},{"location":"whitepapers/documentation_in_git/#3-version-control-documentation-generation-and-component-stability","title":"3. Version Control, Documentation Generation, and Component Stability","text":"<p>This section outlines the necessary tools and processes for a robust, code-and-docs-aligned strategy.</p>"},{"location":"whitepapers/documentation_in_git/#tools-and-workflow","title":"Tools and Workflow","text":"<ul> <li>Git: Handles version control for both code and documentation.  </li> <li>MkDocs: Builds human-readable docs from Markdown sources.  </li> <li>Doxygen: Generates reference API documentation directly from annotated code comments.  </li> <li>CI Pipelines: Automate generation and deployment whenever relevant changes are made.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#branching-and-versioning-strategy","title":"Branching and Versioning Strategy","text":"<p>Any standard branching workflow Git Flow, Trunk-Based Development, GitHub Flow, etc. can support documentation as code (See White Paper: Branching Strategies for Modern Software Delivery) . The key is ensuring that documentation updates are committed and merged alongside code changes. Automated builds or merges can trigger:</p> <ul> <li>Preview Deployments: So reviewers can see updated docs before they merge.  </li> <li>Semantic Versioning (SemVer): <code>major.minor.bugfix/doc</code> increments for each release, including doc-only updates.  </li> <li>Release Tagging: Ensures published documentation always matches a stable code tag.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#component-versioning","title":"Component Versioning","text":"<p>Each component or interface/implementation follows a fixed version consumption model, adhering to strict Semantic Versioning (SemVer):</p> <ul> <li>Major \u2013 Incremented for incompatible changes.  </li> <li>Minor \u2013 Incremented when adding functionality in a backwards-compatible manner.  </li> <li>Bugfix/Doc \u2013 Incremented for backwards-compatible fixes or documentation enhancements.</li> </ul> <p>This ensures code and documentation remain aligned at every release milestone.</p>"},{"location":"whitepapers/documentation_in_git/#exception-aidl-interfaces","title":"Exception \u2013 AIDL Interfaces","text":"<p>AIDL interfaces are incrementally versioned for all changes. By design, these interfaces are fully backwards compatible, allowing older clients to continue functioning without recompilation unless they explicitly opt into newer features. If a truly incompatible change becomes necessary, a separate interface component is introduced rather than modifying the existing one.</p>"},{"location":"whitepapers/documentation_in_git/#applicability-internal-vs-open-source","title":"Applicability: Internal vs. Open Source","text":"<ul> <li>Internal Projects: Keep all docs, code, and tests in private repositories; stable releases or tags still govern which doc versions are published.  </li> <li>Open Source Projects: Follow the same process publicly, allowing external contributors to benefit from accurate, versioned docs.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#4-proposed-solution-overview","title":"4. Proposed Solution Overview","text":""},{"location":"whitepapers/documentation_in_git/#centralised-documentation","title":"Centralised Documentation","text":""},{"location":"whitepapers/documentation_in_git/#1-store-documentation-alongside-source-code","title":"1. Store Documentation Alongside Source Code","text":"<ul> <li>Maintain architecture, interface definitions, and specs in a <code>docs/</code> folder.  </li> <li>Annotate code with Doxygen to generate reference-level documentation automatically.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#2-mandatory-documentation-peer-reviews","title":"2. Mandatory Documentation Peer Reviews","text":"<ul> <li>Treat doc changes as a critical part of each pull request or merge request.  </li> <li>Maintain consistent style and completeness.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#3-use-mkdocs-for-aggregated-documentation","title":"3. Use MkDocs for Aggregated Documentation","text":"<ul> <li>Write explanatory docs in Markdown, generate a static site.  </li> <li>Embed or link Doxygen API docs for deeper technical references.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#publishing-to-github-pages-or-equivalent","title":"Publishing to GitHub Pages (or Equivalent)","text":"<ul> <li>Automated Build Scripts: Build scripts to setup all requirements and trigger builds see build_docs.sh to compile MkDocs, run Doxygen, and deploy to <code>gh-pages</code>.  </li> <li>Hosting Configuration: For both open source and internal github pages can be used.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#script-driven-documentation-releases","title":"Script-Driven Documentation Releases","text":"<ul> <li>Tag-Based Process: Once code is tagged (e.g., <code>v1.2.0</code>), a CI job builds and publishes docs tied exactly to that tag.  </li> <li>Manual or Automatic: Teams may manually trigger the script or let CI handle it upon new tags.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#5-detailed-workflow","title":"5. Detailed Workflow","text":""},{"location":"whitepapers/documentation_in_git/#repository-structure","title":"Repository Structure","text":"<pre><code>myproject/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 architecture.md\n\u2502   \u251c\u2500\u2500 api_docs.md\n\u2502   \u251c\u2500\u2500 build_docs.sh\n\u2502   \u2514\u2500\u2500 ...\n\u2502   \n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 interfaces/\n\u2502   \u2502   \u2514\u2500\u2500 hal_xyz.cpp\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u2514\u2500\u2500 test_hal_xyz.cpp\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 Doxyfile\n\u251c\u2500\u2500 mkdocs.yml\n</code></pre>"},{"location":"whitepapers/documentation_in_git/#generating-api-documentation-doxygen","title":"Generating API Documentation (Doxygen)","text":"<ul> <li>Doxyfile Configuration: Point <code>INPUT</code> to source directories (e.g. <code>./src</code>) and <code>OUTPUT_DIRECTORY</code> to <code>./docs/doxygen</code>.  </li> <li>In-Source Comments: Use robust style guidelines to ensure clarity and completeness.  </li> </ul>"},{"location":"whitepapers/documentation_in_git/#53-building-the-mkdocs-site","title":"5.3 Building the MkDocs Site","text":"<ul> <li>mkdocs.yml: Defines the site structure (navigation, themes, plugins).  </li> <li>Mermaid Diagrams: Add visual clarity with Markdown-based sequence or flow diagrams.  </li> <li>Embedding Doxygen Outputs: Link or embed the generated HTML to unify all doc types.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#6-incorporating-external-markdown","title":"6. Incorporating External Markdown","text":"<p>If some aspects of the product exist in separate modules or repositories, a custom script can:</p> <ul> <li>Clone or pull relevant markdown files.  </li> <li>Merge them into the main <code>docs/external_content</code> folder.  </li> <li>Build a consolidated site, ensuring completeness across all components.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#7-best-practices","title":"7. Best Practices","text":""},{"location":"whitepapers/documentation_in_git/#1-co-locate-everything","title":"1. Co-locate Everything","text":"<ul> <li>Keep code, interfaces, tests, and docs in one place for easy discovery and consistent versioning.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#2-enforce-documentation-reviews","title":"2. Enforce Documentation Reviews","text":"<ul> <li>Build quality docs by reviewing them alongside code changes.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#3-use-a-shared-style-guide","title":"3. Use a Shared Style Guide","text":"<ul> <li>Maintain consistent Doxygen annotations and Markdown formatting.</li> <li>See White paper: Doxygen Code Documentation</li> </ul>"},{"location":"whitepapers/documentation_in_git/#4-version-docs-with-releases","title":"4. Version Docs with Releases","text":"<ul> <li>Ensure stable doc sets exist for each official code tag.</li> <li>Tools like \u201cmike\u201d can help preserve older versions for historical reference.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#5-automate-where-possible","title":"5. Automate Where Possible","text":"<ul> <li>Scripts and CI pipelines reduce manual effort and prevent oversights.</li> </ul>"},{"location":"whitepapers/documentation_in_git/#6-adapt-to-your-branching-model","title":"6. Adapt to Your Branching Model","text":"<ul> <li>Whether Git Flow, trunk-based, or otherwise ensure doc updates follow the same workflow as code.</li> <li>See White Paper: Branching Strategies for Modern Software Delivery</li> </ul>"},{"location":"whitepapers/documentation_in_git/#8-conclusion","title":"8. Conclusion","text":"<p>Treating documentation as code is essential for maintaining accuracy, consistency, and traceability throughout the software lifecycle. By co-locating source code, interface specifications, tests, and Markdown-based documentation in a single repository and automating the build and release processes organisations can:</p> <ul> <li>Streamline Collaboration: Both code and documentation become peer-reviewed deliverables.  </li> <li>Ensure Synchronisation: Changes to functionality are always reflected in the docs.  </li> <li>Reduce Fragmentation: A single source of truth eliminates confusion and duplication.  </li> <li>Support Varied Release Models: Regardless of branching strategy or open/closed sourcing, a unified approach to version control ensures reliable documentation.</li> </ul> <p>This white paper provides a guiding framework for introducing or refining a documentation-in-Git approach, fitting teams of varying sizes, complexities, and deployment requirements. By adopting these practices, engineering and documentation teams can deliver high-quality, up-to-date references that align perfectly with the code they describe.</p> <p>Author: Gerald Weatherup Date: 03 March 2025</p> <p>For questions or suggestions on implementing branching strategies, please contact the Architecture team.</p>"},{"location":"whitepapers/doxygen_code_documentation/","title":"White Paper: Doxygen Code Documentation","text":""},{"location":"whitepapers/doxygen_code_documentation/#executive-summary","title":"Executive Summary","text":"<p>In a fast-paced software development environment, high-quality documentation is often a critical but overlooked factor for success. Doxygen provides a powerful way to generate clear references and inline documentation directly from source code comments. However, simply using Doxygen isn\u2019t enough; teams must follow coherent guidelines to ensure that resulting documentation is comprehensive, consistent, and easy to maintain.</p> <p>This white paper presents best practices for leveraging Doxygen to produce readable, concise, and accurate documentation. By following these recommendations, engineering teams can align on a single set of documentation standards, foster improved collaboration, and enhance long-term project maintainability.</p>"},{"location":"whitepapers/doxygen_code_documentation/#1-introduction","title":"1. Introduction","text":"<p>Doxygen is a widely adopted tool for turning annotated source code into structured documentation. It parses specially formatted comments and generates detailed references, making it easier for developers and sometimes external integrators to understand code functionality, parameters, return values, and side effects.</p>"},{"location":"whitepapers/doxygen_code_documentation/#purpose-of-this-document","title":"Purpose of This Document","text":"<p>This white paper acts as a governance manual to guide teams in crafting excellent Doxygen-based documentation. It establishes:</p> <ul> <li>Core principles of clarity, conciseness, consistency, completeness, and accuracy.  </li> <li>Best practices for using Doxygen tags and annotations in C++ or similar languages.  </li> <li>Examples illustrating how to document functions, parameters, and error handling thoroughly yet succinctly.</li> </ul> <p>The goal is to ensure a uniform style and level of quality across the entire codebase, allowing both new and experienced contributors to ramp up quickly and collaborate effectively.</p>"},{"location":"whitepapers/doxygen_code_documentation/#2-core-principles","title":"2. Core Principles","text":"<p>These five pillars form the foundation of all high-quality Doxygen documentation:</p> <p>Clarity:</p> <ul> <li>Write comments in plain, accessible language.  </li> <li>Avoid obscure jargon unless absolutely necessary.</li> </ul> <p>Conciseness:</p> <ul> <li>Get straight to the point and remove unnecessary words or details.  </li> <li>Keep sentences short and direct.</li> </ul> <p>Consistency:</p> <ul> <li>Adhere to a standard formatting, spacing, and tag usage convention.  </li> <li>Use the same tone and style throughout your codebase.</li> </ul> <p>Completeness:</p> <ul> <li>Include essential details purpose, parameters, returns, errors, and side effects so the documentation is immediately usable.  </li> <li>Avoid partial or skeletal comments that provide no real insight.</li> </ul> <p>Accuracy:</p> <ul> <li>Continuously update comments to reflect the latest code behavior.  </li> <li>Double-check any technical claims or references for correctness.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#3-best-practices","title":"3. Best Practices","text":""},{"location":"whitepapers/doxygen_code_documentation/#31-single-line-vs-multi-line-comments","title":"3.1 Single-Line vs. Multi-Line Comments","text":"<p>Single-Line <code>/*! ... */</code>:</p> <ul> <li>Ideal for brief descriptions that don\u2019t require <code>@brief</code>.  </li> <li>Clean and easy to parse, ensuring minimal clutter.</li> </ul> <pre><code>/*! Retrieves the current Ethernet WAN interface name. */\n</code></pre> <p>Multi-Line <code>/** ... */</code> </p> <ul> <li>Use when describing parameters, return values, or additional context.  </li> <li>Improves readability for more complex functions.</li> </ul> <pre><code>/**\n   * @brief Initiates a firmware update and factory reset.\n   *\n   * This function updates the device's firmware (optionally from a specified URL)\n   * and then performs a factory reset.\n   *\n   * Additional details or notes...\n   */\nvoid updateFirmwareAndFactoryReset();\n</code></pre>"},{"location":"whitepapers/doxygen_code_documentation/#32-focused-brief-tags","title":"3.2 Focused <code>@brief</code> Tags","text":"<ul> <li>While the <code>@brief</code> tag is helpful for providing a concise summary, it is optional. Doxygen can automatically derive a short description from the first sentence in a multi-line comment.  </li> <li>If you do use <code>@brief</code>, keep the summary concise and action-oriented.  </li> <li>Aim for one or two lines at most, capturing the \u201cwhy\u201d or \u201cwhat\u201d at a high level.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#33-informative-param-and-returns","title":"3.3 Informative <code>@param</code> and <code>@returns</code>","text":"<ul> <li><code>@param</code>: Indicate expected types, constraints, and usage.</li> </ul> <pre><code>/**\n * @brief Computes a hash value for the input buffer.\n *\n * @param[in] buffer Pointer to the input data.\n * @param[in] size   The size of the input buffer, in bytes.\n * @returns The 32-bit hash computed from the provided data.\n */\nuint32_t computeHash(const char* buffer, size_t size);\n</code></pre> <ul> <li><code>@returns</code>: Provide a general statement about the function\u2019s return value(s).</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#34-detailed-retval","title":"3.4 Detailed <code>@retval</code>","text":"<p>When a function has specific return codes:</p> <pre><code>/**\n * @returns Operation status:\n * @retval RETURN_OK   Successful operation.\n * @retval RETURN_ERR  Operation failed (e.g., invalid parameter).\n */\n</code></pre>"},{"location":"whitepapers/doxygen_code_documentation/#35-use-additional-tags","title":"3.5 Use Additional Tags","text":"<ul> <li><code>@note</code>: For extra commentary on usage or implementation details.  </li> <li><code>@warning</code>: To draw attention to potential pitfalls.  </li> <li><code>@see</code>: Linking related functions or classes.  </li> <li><code>@deprecated</code>: Indicating functionality that will be removed in future versions.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#36-error-handling","title":"3.6 Error Handling","text":"<ul> <li>Avoid Generic <code>RETURN_ERR</code>: Employ an <code>enum</code> or typed error codes for clarity.  </li> <li>Document Known Failure Cases: List scenarios in which errors occur, and provide guidance for handling them.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#4-example-well-documented-function","title":"4. Example: Well-Documented Function","text":"<pre><code>/*!\n * @brief Retrieves the current DOCSIS registration status.\n *\n * This function populates a provided `CMMGMT_CM_DOCSIS_INFO` structure \n * with DOCSIS registration details.\n *\n * @param[out] pinfo - Pointer to a pre-allocated `CMMGMT_CM_DOCSIS_INFO` structure.\n *\n * @returns Status of the operation:\n * @retval RETURN_OK  - On success.\n * @retval RETURN_ERR - On failure (e.g., retrieval error, invalid input).\n *\n * @note The caller is responsible for providing the `PCMMGMT_CM_DOCSIS_INFO` structure.\n */\nINT docsis_GetDOCSISInfo(PCMMGMT_CM_DOCSIS_INFO pinfo);\n</code></pre> <p>In this example, the function is thoroughly explained:</p> <ul> <li>Purpose: \u201cRetrieves the current DOCSIS registration status.\u201d  </li> <li>Parameter: <code>pinfo</code> is clearly designated as an out-parameter.  </li> <li>Return Details: Sufficient coverage of success/failure scenarios.  </li> <li>Additional Note: Clarifies the caller\u2019s responsibility.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#5-common-pitfalls-to-avoid","title":"5. Common Pitfalls to Avoid","text":"<p>Repetition:</p> <ul> <li>Don\u2019t restate obvious information (e.g., \u201cint param is an integer\u201d).</li> <li>Eliminate redundant phrases that only echo the function name.</li> </ul> <p>Vague Language:</p> <ul> <li>Avoid placeholders like \u201cdoes stuff\u201d; always specify exact actions or impacts.</li> </ul> <p>Incorrect Information:</p> <ul> <li>Keep comments current; stale docs can be worse than no docs at all.</li> </ul> <p>Overly Long Comments:</p> <ul> <li>Long-winded paragraphs obscure the primary purpose; break content into bullet points or concise sentences.</li> <li>Make judicious use of inline markers like <code>TODO</code>, <code>FIXME</code>, or <code>BUG</code> to highlight pending upgrades or known issues.</li> <li>If the interface is deprecated or slated for removal, clearly label it (e.g., <code>@deprecated</code>) to inform downstream consumers.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#6-implementation-maintenance","title":"6. Implementation &amp; Maintenance","text":""},{"location":"whitepapers/doxygen_code_documentation/#61-integrating-doxygen-with-the-release-process","title":"6.1 Integrating Doxygen with the release process","text":"<ul> <li>Maintain a <code>Doxyfile</code> in the repository with standard configurations (e.g., input directories, output formats).  </li> <li>Automate generating and publishing documentation on every merge to <code>main</code> or during releases.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#62-team-alignment","title":"6.2 Team Alignment","text":"<ul> <li>Host training sessions or share style guides to ensure everyone understands the tagging structure.  </li> <li>Conduct documentation reviews as part of code reviews treat doc updates as essential as logic changes.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#63-evolving-guidelines","title":"6.3 Evolving Guidelines","text":"<ul> <li>Plan regular check-ups to address any discovered inconsistencies or incomplete docs.  </li> <li>Update your approach as the codebase and team grows, ensuring guidelines remain realistic and relevant.</li> </ul>"},{"location":"whitepapers/doxygen_code_documentation/#7-conclusion","title":"7. Conclusion","text":"<p>This governance manual underscores the importance of thorough, consistent, and accurate documentation using Doxygen. By standardizing the way comments are written covering everything from function purpose to error handling teams can drastically enhance collaboration, reduce onboarding time, and boost overall code maintainability. Developers, QA engineers, and even stakeholders benefit from a robust, automated system that keeps code and documentation aligned.</p> <p>Author: Gerald Weatherup Date: 03 March 2025</p> <p>For questions or suggestions on implementing branching strategies, please contact the Architecture team.</p>"},{"location":"whitepapers/engineering_goals/","title":"White Paper: Achieving Engineering Goals and Defining Requirements for Features and Tasks","text":""},{"location":"whitepapers/engineering_goals/#executive-summary","title":"Executive Summary","text":"<p>Effective goal setting and requirements definition are crucial for delivering high-quality, scalable, and maintainable software in an open-source community-driven development model. This white paper presents a structured methodology for defining features, tasks, and issues using GitHub, while ensuring visibility and alignment with long-term engineering objectives. While internal tracking tools such as JIRA may be used for high-level business goals, compliance, and reporting, the core development efforts remain transparent and community-accessible.</p>"},{"location":"whitepapers/engineering_goals/#introduction","title":"Introduction","text":"<p>Community-driven software development, such as the one fostered within RDK Central, requires clear goal-setting mechanisms that ensure transparency, accountability, and effective collaboration among multiple contributing companies. The RDK Central development ecosystem is structured around Core Development Teams and Fork-Based Contribution Teams, each with defined roles and contribution processes based on how they interact with the codebase:</p> <ul> <li> <p>Core Development Teams \u2013 These teams are responsible for core platform contributions and have direct commit access to shared repositories. They work collaboratively across multiple companies to define, develop, and maintain foundational components. Their contributions follow structured branching workflows. For more details, refer to the Core Development Guide: Branching for Direct Contributions.</p> </li> <li> <p>Fork-Based Contribution Teams \u2013 These contributors focus on feature development, customization, and deployment-specific enhancements. They operate via forks of the core repositories, submitting changes through pull requests. Their work builds on or extends the core platform while ensuring alignment through review and merge processes. For more details, refer to the Fork-Based Contribution Guide.</p> </li> </ul>"},{"location":"whitepapers/engineering_goals/#why-this-approach-matters","title":"Why This Approach Matters","text":"<p>While this paper focuses primarily on the \"what\" and \"how\" of engineering work, it is underpinned by a clear \"why\": to create a scalable, transparent, and sustainable development process that empowers both internal and external teams. By aligning open-source collaboration with structured engineering practices, we ensure that every contribution supports long-term platform stability, shared innovation, and collective technical advancement.</p>"},{"location":"whitepapers/engineering_goals/#on-terminology-product-vs-program-management","title":"On Terminology: Product vs. Program Management","text":"<p>This document uses \u201cProgram Management\u201d as a practical label for cross-functional coordination of development work. However, we recognize that the definition of \u201cwhat\u201d and \u201cwhy\u201d typically aligns with Product Management responsibilities in many organizations. Here, the term \u201cProgram Management\u201d is used to reflect the planning and coordination mechanisms in JIRA, though the responsibilities may encompass what some consider product-level strategy.</p> <p>This paper outlines a standardized process for tracking engineering work, documenting requirements, and structuring project management workflows using GitHub Issues, Milestones, and JIRA for high-level business tracking. These practices are actively in use within RDK Central to maintain visibility and collaboration across all development teams.</p>"},{"location":"whitepapers/engineering_goals/#engineering-oriented-goal-setting","title":"Engineering-Oriented Goal Setting","text":"<p>Drawing inspiration from Management in 10 Words, this methodology reframes business goals into engineering-centric principles:</p> <ol> <li>Trust \u2013 Enable transparency and accountability in development.</li> <li>Truth \u2013 Define clear and objective requirements.</li> <li>Clarity \u2013 Ensure well-documented issues, features, and tasks.</li> <li>Balance \u2013 Prioritize sustainable development over short-term fixes.</li> <li>Simplicity \u2013 Minimize complexity and technical debt.</li> <li>Focus \u2013 Align features with long-term platform scalability.</li> <li>Commitment \u2013 Encourage ownership of tasks and quality delivery.</li> <li>Adaptability \u2013 Support evolving requirements with a flexible architecture.</li> <li>Standards \u2013 Follow industry best practices for consistency and compliance.</li> <li>Excellence \u2013 Strive for high reliability and maintainability.</li> </ol>"},{"location":"whitepapers/engineering_goals/#requirements-breakdown","title":"Requirements Breakdown","text":""},{"location":"whitepapers/engineering_goals/#epics-internal-jira-based","title":"Epics (Internal, JIRA-Based)","text":"<p>While most work is driven by business requirements, which in turn generate development work, we also account for engineering-led initiatives such as addressing technical debt.  To manage this effectively, we categorize work into two distinct types.</p> <ol> <li> <p>Program Management Epics (JIRA - Business-Driven)</p> <ul> <li>Define the \"what\" in product development, originating from business requirements.  </li> <li>Comcast and Sky drive business requirements and architectural alignment with third parties to ensure feature development benefits all stakeholders.  </li> <li>A Program Management Epic may require multiple Development Features to be completed before it can be resolved.  </li> </ul> </li> <li> <p>Development Work (GitHub Features - Community-Contributed) </p> <ul> <li>Define the \"how\" in software development, driven by contributions from the development community.  </li> <li>Contain sub-features, tasks, and bugs that contribute to completing the Development Work.  </li> <li>Development is a collaborative effort, where contributors have their own business drivers, but the source code evolves for the benefit of all parties involved.  </li> <li>Tracked in GitHub to facilitate open collaboration and shared progress across multiple contributors.  </li> </ul> </li> </ol> <p>Since development work is community-contributed, tracking is adapted accordingly. Program Management Epics remain internal to JIRA, ensuring alignment with business objectives, while Development Work exist in GitHub as a shared development space where work progresses collectively. This structure ensures that Comcast and Sky provide the necessary guidance and coordination while allowing the development community to contribute effectively.</p> <p>All work is driven by business requirements, which in turn generates development work. Some layers, or even parts of layers, may be internal, with internal tasks optionally tracked in JIRA. However, since all source code is likely to be hosted in GitHub in the future, it is advisable to adopt a common GitHub tracking model for both internal and external work.  </p> <p>Since development work consists of changes to a Git repository, whether it be code, documentation, test results, or any other modifications, all tracking should be done within GitHub.</p> <p>This approach ensures:</p> <ul> <li>Consistency in development tracking across all contributors, whether internal or external, since every change is inherently part of the Git history.  </li> <li>Better visibility and collaboration, eliminating the need for manual synchronization between separate tracking systems.  </li> <li>Unified tracking of all artifacts, including source code, documentation updates, test results, and CI/CD workflows, ensuring full traceability of changes.  </li> <li>Flexibility for internal teams to organize their work using GitHub\u2019s organizational units while still maintaining alignment with broader development efforts.  </li> <li>Automatic generation of documentation and change logs through versioning, ensuring updates are systematically captured within the repository itself.  </li> <li>Direct traceability between tasks, issues, and features, as every commit, pull request, and merge request is linked with URLs and full version history.  </li> </ul> <p>This structure enforces GitHub as the single source of truth for all development tracking, ensuring transparency, efficiency, and seamless collaboration across internal and external teams.  </p>"},{"location":"whitepapers/engineering_goals/#example","title":"Example","text":"<p>Overall Business (Jira Epic): Enable Personalized Bluetooth LE Audio Broadcast</p> <ul> <li>Goal: Deliver a feature enabling users to connect multiple Bluetooth LE Audio headphones with personalized audio streams for an enhanced viewing experience.</li> </ul> <p>Layer Requirements:</p> <ul> <li>Vendor Layer (Internal Github Feature): BlueZ LE Audio Broadcast Support<ul> <li>Goal: Integrate and provide a stable, functional Bluetooth LE Audio Broadcast stack with personalized stream capabilities.</li> <li>Tasks:<ul> <li>Update BlueZ to support LE Audio Broadcast with personalized audio streams.</li> <li>Develop and test necessary APIs and drivers.</li> <li>Provide comprehensive API documentation.</li> </ul> </li> </ul> </li> <li>Middleware Layer (External Github Feature): LE Audio Stream Management<ul> <li>Goal: Provide a robust middleware layer that manages and abstracts the vendor-provided Bluetooth functionality for the application.</li> <li>Tasks:<ul> <li>Integrate with the updated BlueZ APIs.</li> <li>Develop and test APIs for the application layer.</li> <li>Implement stream management logic (creation, configuration, routing).</li> <li>Provide documentation.</li> </ul> </li> </ul> </li> <li>Application Layer (Internal Github Feature): Personalized Audio Stream UI/UX<ul> <li>Goal: Create an intuitive and user-friendly interface for managing personalized Bluetooth audio streams.</li> <li>Tasks:<ul> <li>Design and implement the UI for headphone discovery, connection, and stream management.</li> <li>Develop and test the application logic for controlling audio settings per stream.</li> <li>Implement real-time stream status display.</li> <li>Create UI/UX documentation.</li> </ul> </li> </ul> </li> </ul>"},{"location":"whitepapers/engineering_goals/#feature-requests-bug-reporting-and-task-tracking","title":"Feature Requests, Bug Reporting, and Task Tracking","text":"<p>All feature requests, bug reports, and tasks are tracked in GitHub Issues within the RDK Central open tracking system. This ensures complete visibility of work progress, fosters collaboration among contributors, and aligns with the community-driven development model. These GitHub-based tracking mechanisms are publicly accessible and help maintain transparency across all contributions.</p> <p>Tip</p> <p>The following templates are already enabled in RDK Central</p>"},{"location":"whitepapers/engineering_goals/#features","title":"Features","text":"<p>Feature requests should be well-defined to ensure clarity in their purpose, scope, and impact. The following feature request template is actively used within RDK Central:</p>"},{"location":"whitepapers/engineering_goals/#feature-request-template","title":"Feature Request Template","text":"<ul> <li>Title Format: <code>Feature:&lt;Short summary of the problem&gt;</code></li> <li>Issue Type: Set as <code>FEATURE</code></li> <li>Labels: Apply relevant labels such as <code>Documentation</code>, <code>Enhancement</code>, <code>Bug</code>, etc.</li> <li>Project Field: Assign to an appropriate project. Example project templates can be found here</li> </ul>"},{"location":"whitepapers/engineering_goals/#description","title":"Description","text":"<ul> <li>Problem/Opportunity: Describe the user need or problem this feature solves/improves.</li> <li>Proposed Solution: Explain your idea for the feature and how it addresses the problem/opportunity.</li> </ul>"},{"location":"whitepapers/engineering_goals/#acceptance-criteria-optional","title":"Acceptance Criteria (Optional)","text":"<ul> <li>Specific condition 1</li> <li>Specific condition 2</li> <li>...</li> </ul>"},{"location":"whitepapers/engineering_goals/#additional-notes-optional","title":"Additional Notes (Optional)","text":"<ul> <li>Mockups, sketches, wireframes, etc.</li> </ul>"},{"location":"whitepapers/engineering_goals/#tasks","title":"Tasks","text":"<p>Tasks encompass all actionable work within GitHub Issues, including feature development, improvements, maintenance, and refactoring. To align with RDK Central's best practices, tasks should follow the recommended template, which is already in use within the community:</p>"},{"location":"whitepapers/engineering_goals/#task-template","title":"Task Template","text":"<ul> <li>Title Format: <code>Task:&lt;Short summary of the problem&gt;</code></li> <li>Issue Type: Set as <code>TASK</code></li> <li>Labels: Apply relevant labels, such as <code>documentation</code> or <code>enhancement</code></li> <li>Project Field: Assign to an appropriate project. Example project templates can be found here</li> </ul>"},{"location":"whitepapers/engineering_goals/#description_1","title":"Description","text":"<ul> <li>Clearly state the goal of the task for better understanding and traceability.</li> </ul>"},{"location":"whitepapers/engineering_goals/#notes-optional","title":"Notes (Optional)","text":"<ul> <li>Include any helpful information, such as environment details or relevant links.</li> </ul>"},{"location":"whitepapers/engineering_goals/#bug-reporting","title":"Bug Reporting","text":"<p>Bugs should be reported following a standardized format to ensure clarity, traceability, and reproducibility. The following bug template is actively used within RDK Central:</p>"},{"location":"whitepapers/engineering_goals/#bug-template","title":"Bug Template","text":"<ul> <li>Title Format: <code>Bug:&lt;Short summary of the problem&gt;</code></li> <li>Issue Type: Set as <code>BUG</code></li> <li>Labels: Apply relevant labels, such as <code>Bug</code></li> <li>Project Field: Assign to an appropriate project. Example project templates can be found here</li> </ul>"},{"location":"whitepapers/engineering_goals/#description_2","title":"Description","text":"<ul> <li>Problem: Clearly stating the problem upfront is crucial for understanding the issue.</li> <li>Steps to Reproduce: If applicable, this is essential for bugs, allowing others to replicate the problem and verify solutions.</li> <li>Expected Behaviour: Explain what should happen instead of the current behaviour.</li> <li>Actual Behaviour: Describe what is currently happening, highlighting the discrepancy with the expected behaviour.</li> </ul>"},{"location":"whitepapers/engineering_goals/#notes-optional_1","title":"Notes (Optional)","text":"<ul> <li>Include any helpful information, such as environment details, links, screenshots, error messages, console logs, or relevant code snippets.</li> </ul>"},{"location":"whitepapers/engineering_goals/#why-attach-a-github-project-to-tasks","title":"Why Attach a GitHub Project to Tasks?","text":"<p>Attaching a GitHub Project to tasks provides a structured approach to tracking development progress, status control, and workflow automation. GitHub Projects are used to:</p> <ul> <li>Track the development of features in use in GitHub, ensuring clear visibility of work status.</li> <li>Provide control over task progress by defining statuses (e.g., To Do, In Progress, Completed).</li> <li>Enable tracking configurations for workflow automation and management.</li> <li>Support timeframes, estimates, and planning, ensuring that work is executed within expected delivery schedules.</li> </ul> <p>More information on GitHub Projects can be found here.</p>"},{"location":"whitepapers/engineering_goals/#conclusion","title":"Conclusion","text":"<p>By structuring work in an open, organized, and transparent manner, engineering teams can achieve long-term scalability, reduce maintenance overhead, and manage technical debt effectively. This approach fosters a sustainable development model while maintaining alignment with broader business and compliance goals.</p> <p>This white paper aims to guide community-driven open-source software development efforts, ensuring efficient goal setting, transparent progress tracking, and effective collaboration.</p> <p>Author: Gerald Weatherup Date: 20 March 2025</p>"},{"location":"whitepapers/standardizing_git_commit_messages/","title":"White Paper: Standardizing Git Commit Messages with the 50/72 Rule","text":""},{"location":"whitepapers/standardizing_git_commit_messages/#executive-summary","title":"Executive Summary","text":"<p>In collaborative software development, the quality of version control history directly impacts maintainability, traceability, and communication across teams. This white paper introduces the 50/72 rule \u2014 a proven standard for formatting Git commit messages \u2014 and outlines its importance in automated changelog generation, release documentation, and long-term project governance.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#introduction","title":"Introduction","text":"<p>Git commit messages are the primary medium for recording the history and intent of code changes. Yet in many projects, they are inconsistently written, poorly structured, or devoid of useful context. This impairs collaboration, delays debugging, and undermines transparency.</p> <p>The 50/72 rule addresses this problem by providing a simple, standardized format for commit messages that is both human-readable and machine-parseable. This white paper explains the rule, its rationale, and how to apply it effectively.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#why-message-structure-matters","title":"Why Message Structure Matters","text":"<p>Commit messages form the source of truth for version history. When formatted consistently:</p> <ul> <li>They provide a narrative for every decision made in the codebase.</li> <li>They accelerate onboarding for new developers by making history easier to follow.</li> <li>They enable automated tooling \u2014 such as changelog generators, release note systems, and CI/CD integrations \u2014 to extract structured insights from the commit log.</li> </ul> <p>In RDK and similar development environments, structured commit messages feed into systems that automatically generate:</p> <ul> <li>Changelogs</li> <li>Deployment summaries</li> <li>Auditable histories</li> <li>Issue-linked release notes</li> </ul> <p>Without a consistent standard, this automation becomes unreliable or meaningless.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#the-5072-rule-explained","title":"The 50/72 Rule Explained","text":""},{"location":"whitepapers/standardizing_git_commit_messages/#1-subject-line-50-characters","title":"1. Subject Line (\u2264 50 Characters)","text":"<ul> <li>Use the imperative mood: \"Add\", \"Fix\", \"Update\".</li> <li>Be concise but specific.</li> <li>Use present tense, describing what the commit does now.</li> <li>Avoid filler language (e.g., \u201csome changes\u201d, \u201cmisc tweaks\u201d).</li> </ul> <p>Examples:</p> <pre><code>Add API for Bluetooth device pairing\nFix crash when handling empty config files\nUpdate CI workflow for multi-arch testing\n</code></pre>"},{"location":"whitepapers/standardizing_git_commit_messages/#2-blank-line-separator","title":"2. Blank Line Separator","text":"<p>Always insert a blank line between the subject and body. This is essential for proper parsing by Git tools and changelog scripts.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#3-body-72-characters-per-line-optional","title":"3. Body (\u2264 72 Characters Per Line, Optional)","text":"<p>The body provides context and reasoning:</p> <ul> <li>Explain the motivation behind the change.</li> <li>Describe edge cases, limitations, or downstream impacts.</li> <li>Wrap text at 72 characters per line for readability in terminals and diff tools.</li> </ul> <p>Example:</p> <pre><code>Fix #101: Prevent race condition in device state manager\n\nThe update adds locking logic to avoid state mismatch when multiple\nthreads attempt to modify device power states concurrently.\nThis prevents a rare but reproducible failure in CI pipelines.\n</code></pre>"},{"location":"whitepapers/standardizing_git_commit_messages/#common-verbs-for-commit-subjects","title":"Common Verbs for Commit Subjects","text":"<p>Standardizing verbs helps teams quickly understand the nature of each change. Recommended actions include:</p> <ul> <li><code>Add</code>: Introduce new functionality or files</li> <li><code>Fix</code>: Correct a bug or unintended behavior</li> <li><code>Update</code>: Apply minor improvements or changes</li> <li><code>Remove</code>: Eliminate unused code, files, or dependencies</li> <li><code>Refactor</code>: Restructure code without changing behavior</li> <li><code>Improve</code>: Enhance readability, performance, or documentation</li> <li><code>Test</code>: Add or modify tests</li> <li><code>Clean</code>: Remove extraneous files or temporary artifacts</li> <li><code>Merge</code>: Integrate branches or resolve divergent histories</li> </ul>"},{"location":"whitepapers/standardizing_git_commit_messages/#benefits-of-adopting-the-5072-rule","title":"Benefits of Adopting the 50/72 Rule","text":""},{"location":"whitepapers/standardizing_git_commit_messages/#1-readability","title":"1. Readability","text":"<p>Well-structured commit logs are easier to review, audit, and understand.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#2-maintainability","title":"2. Maintainability","text":"<p>Future developers can trace why a change occurred\u2014not just what changed.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#3-collaboration","title":"3. Collaboration","text":"<p>Peer reviewers, QA teams, and release managers benefit from consistent and meaningful messages.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#4-automation-compatibility","title":"4. Automation Compatibility","text":"<p>Tools can automatically generate changelogs, link to issue trackers, and build documentation from standardized commit messages.</p>"},{"location":"whitepapers/standardizing_git_commit_messages/#best-practices-for-teams","title":"Best Practices for Teams","text":"<ul> <li>Enforce via commit hooks or linting tools.</li> <li>Reference issue numbers when applicable (e.g., <code>Fix #456</code>).</li> <li>Keep commits focused, representing one logical change per commit.</li> <li>Review messages as part of code review \u2014 just like code quality.</li> </ul>"},{"location":"whitepapers/standardizing_git_commit_messages/#example-real-world-message","title":"Example: Real-World Message","text":"<pre><code>Fix #237: Address memory leak in audio service\n\nAdded cleanup logic to release buffers in the audio stream teardown\npath. Leak was triggered by rapid stream restarts during live\nchannel switching. Also added unit test to validate buffer cleanup.\n</code></pre>"},{"location":"whitepapers/standardizing_git_commit_messages/#conclusion","title":"Conclusion","text":"<p>Standardized Git commit messages are more than a formatting preference \u2014 they are a foundational element of software quality, traceability, and automation readiness. The 50/72 rule offers a lightweight, high-impact way to improve every team\u2019s development workflow. By adopting this practice across your engineering organization, you promote clearer communication, smoother collaboration, and more maintainable systems.</p> <p>Author: Gerald Weatherup Date: 19th May 2025</p>"}]}